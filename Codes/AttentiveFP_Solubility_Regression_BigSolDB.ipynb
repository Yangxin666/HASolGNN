{"cells":[{"cell_type":"code","source":["!pip install torch\n","!pip install torch-geometric\n","!pip install pysmiles\n","!pip install rdkit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywbw1oASEjEd","executionInfo":{"status":"ok","timestamp":1729263704419,"user_tz":360,"elapsed":14613,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"d256532e-113a-4ab2-a398-8d4eb1c59e89"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n","Collecting pysmiles\n","  Downloading pysmiles-1.1.2-py2.py3-none-any.whl.metadata (10 kB)\n","Collecting pbr (from pysmiles)\n","  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pysmiles) (3.4)\n","Downloading pysmiles-1.1.2-py2.py3-none-any.whl (22 kB)\n","Downloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pbr, pysmiles\n","Successfully installed pbr-6.1.0 pysmiles-1.1.2\n","Collecting rdkit\n","  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n","Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rdkit\n","Successfully installed rdkit-2024.3.5\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZevvLDjT7rMD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729263783598,"user_tz":360,"elapsed":26734,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"d105e9fb-516b-49ad-d186-78a873461bb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from pysmiles import read_smiles\n","import pandas as pd\n","import logging\n","from tqdm import tqdm\n","import torch\n","from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n","import torch.nn.functional as F\n","from torch_geometric.nn import MessagePassing, GCNConv\n","from torch_geometric.utils import remove_self_loops, add_self_loops, degree\n","from torch_geometric.data import Data\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","logging.getLogger('pysmiles').setLevel(logging.CRITICAL)"]},{"cell_type":"markdown","source":["# Dataset\n","1. AqSolDB (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","2. OChem (https://ochem.eu/login/show.do?render-mode=full)\n","3. BigSolDB (https://zenodo.org/records/6984601)\n","\n"],"metadata":{"id":"OhZwPD4fDh2F"}},{"cell_type":"markdown","source":["# AqSolDB"],"metadata":{"id":"zK8utGmGx0vd"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","df = pd.read_csv('gdrive/My Drive/Base_GNN_Solubility/curated_solubility_dataset.csv') #read dataset (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","X_smiles = list(df['SMILES']) #get smiles strings from file\n","Y = np.asarray(df['Solubility']) #get solubility values from file\n","\n","columns_to_normalize = [\n","    \"MolWt\",\n","    \"MolLogP\",\n","    \"MolMR\",\n","    \"HeavyAtomCount\",\n","    \"NumHAcceptors\",\n","    \"NumHDonors\",\n","    \"NumHeteroatoms\",\n","    \"NumRotatableBonds\"]\n","\n","scaler = MinMaxScaler()\n","df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n","\n","\n","def val_to_class(val):\n","    if val < -3.65: #insoluble\n","        return [1, 0, 0]\n","    elif val < -1.69: #slightly soluble\n","        return [0, 1, 0]\n","    else: #soluble\n","        return [0, 0, 1]"],"metadata":{"id":"PZYEUILQAqa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Solubility'].max()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bASxvan5267-","executionInfo":{"status":"ok","timestamp":1728592015435,"user_tz":360,"elapsed":153,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7896a272-796f-409b-c2c1-0dc3d27fe102"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7213"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["# BigSolDB"],"metadata":{"id":"T3D7t9ODx3dt"}},{"cell_type":"code","source":["# BigSolDB.csv\n","\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","df = pd.read_csv('gdrive/My Drive/Base_GNN_Solubility/BigSolDB.csv')\n","# df = df[df['Solvent']=='water']\n","df['Solubility'] = np.log(df['Solubility'])\n","df = df.reset_index(drop=True)\n","\n","X_smiles = list(df['SMILES']) #get smiles strings from file\n","Y = np.asarray(df['Solubility']) #get solubility values from file\n","\n","# columns_to_normalize = [\n","#     \"MolWt\",\n","#     \"MolLogP\",\n","#     \"MolMR\",\n","#     \"HeavyAtomCount\",\n","#     \"NumHAcceptors\",\n","#     \"NumHDonors\",\n","#     \"NumHeteroatoms\",\n","#     \"NumRotatableBonds\"]\n","\n","columns_to_normalize = [\n","    \"T,K\"]\n","\n","scaler = MinMaxScaler()\n","df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])*100\n","\n","\n","# def val_to_class(val):\n","#     if val < -3.65: #insoluble\n","#         return [1, 0, 0]\n","#     elif val < -1.69: #slightly soluble\n","#         return [0, 1, 0]\n","#     else: #soluble\n","#         return [0, 0, 1]\n","\n"],"metadata":{"id":"YOIAiOYBx3nW","executionInfo":{"status":"ok","timestamp":1729263998125,"user_tz":360,"elapsed":176,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Ocy2rq75H6cB","executionInfo":{"status":"ok","timestamp":1729264019910,"user_tz":360,"elapsed":211,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"55e4c77f-ace6-4b34-ba05-6d0a87a03b7c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               SMILES      T,K  Solubility   Solvent  \\\n","0              ON(Cc1ccccc1)Cc1ccccc1  18.7500   -6.675850  methanol   \n","1              ON(Cc1ccccc1)Cc1ccccc1  22.5000   -6.369509  methanol   \n","2              ON(Cc1ccccc1)Cc1ccccc1  25.1875   -6.168679  methanol   \n","3              ON(Cc1ccccc1)Cc1ccccc1  28.6875   -5.892525  methanol   \n","4              ON(Cc1ccccc1)Cc1ccccc1  31.1875   -5.705684  methanol   \n","...                               ...      ...         ...       ...   \n","54268  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  44.6875   -4.112916       DMS   \n","54269  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  46.8125   -3.967536       DMS   \n","54270  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  48.4375   -3.860855       DMS   \n","54271  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  50.0625   -3.753738       DMS   \n","54272  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  52.0000   -3.616001       DMS   \n","\n","         SMILES_Solvent                       Source  \n","0                    CO     10.1021/acs.jced.9b01028  \n","1                    CO     10.1021/acs.jced.9b01028  \n","2                    CO     10.1021/acs.jced.9b01028  \n","3                    CO     10.1021/acs.jced.9b01028  \n","4                    CO     10.1021/acs.jced.9b01028  \n","...                 ...                          ...  \n","54268  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54269  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54270  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54271  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54272  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","\n","[54273 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-aef1afee-1a78-4536-8680-70a466687821\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMILES</th>\n","      <th>T,K</th>\n","      <th>Solubility</th>\n","      <th>Solvent</th>\n","      <th>SMILES_Solvent</th>\n","      <th>Source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>18.7500</td>\n","      <td>-6.675850</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>22.5000</td>\n","      <td>-6.369509</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>25.1875</td>\n","      <td>-6.168679</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>28.6875</td>\n","      <td>-5.892525</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>31.1875</td>\n","      <td>-5.705684</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54268</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>44.6875</td>\n","      <td>-4.112916</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54269</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>46.8125</td>\n","      <td>-3.967536</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54270</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>48.4375</td>\n","      <td>-3.860855</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54271</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>50.0625</td>\n","      <td>-3.753738</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54272</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>52.0000</td>\n","      <td>-3.616001</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54273 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aef1afee-1a78-4536-8680-70a466687821')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aef1afee-1a78-4536-8680-70a466687821 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aef1afee-1a78-4536-8680-70a466687821');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3dbdddc0-9cfa-487b-824f-4c5129da89e6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dbdddc0-9cfa-487b-824f-4c5129da89e6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3dbdddc0-9cfa-487b-824f-4c5129da89e6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_15f36440-81cc-43f3-ae62-60d76b1f8741\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_15f36440-81cc-43f3-ae62-60d76b1f8741 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 54273,\n  \"fields\": [\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 830,\n        \"samples\": [\n          \"Cc1cc(C)cc(OCC2CNC(=O)O2)c1\",\n          \"O=c1ccc2ccccc2o1\",\n          \"OC[C@H]1O[C@H](O[C@]2(CCl)O[C@H](CCl)[C@@H](O)[C@@H]2O)[C@H](O)[C@@H](O)[C@H]1Cl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T,K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.16168289728885,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2856,\n        \"samples\": [\n          32.69374999999999,\n          31.200000000000006,\n          42.55000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solubility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7575861321573574,\n        \"min\": -23.62368793069608,\n        \"max\": -0.050661914802227995,\n        \"num_unique_values\": 26997,\n        \"samples\": [\n          -3.627445747929844,\n          -8.711445639078157,\n          -6.765388037695215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 138,\n        \"samples\": [\n          \"m-xylene\",\n          \"n-decanol\",\n          \"toluene\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES_Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 129,\n        \"samples\": [\n          \"CCCOCCC\",\n          \"CCCCCCCO\",\n          \"C1COCCO1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 771,\n        \"samples\": [\n          \"10.1021/je7002463\",\n          \"10.1021/je800991v\",\n          \"10.1021/je8002332\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# AttentiveFP (with edge features)"],"metadata":{"id":"-hJQ36Jl3QAd"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        print(x)\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        print(h)\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"UX5bVRU-3QIh","executionInfo":{"status":"ok","timestamp":1729265179350,"user_tz":360,"elapsed":214,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Proposed New Architecture"],"metadata":{"id":"cBBJ1JYJPz2-"}},{"cell_type":"markdown","source":["#replace GAT by SAGEConv"],"metadata":{"id":"Qr2GHwa6SDAo"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GCNConv, GraphConv, SAGEConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = SAGEConv(hidden_channels, hidden_channels)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = SAGEConv(hidden_channels, hidden_channels)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"CLNxaXZ1SB1m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Improved GRU"],"metadata":{"id":"aO_VPlr6erj6"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","# class EnhancedGRUCell(nn.Module):\n","#     def __init__(self, input_size, hidden_size):\n","#         super(EnhancedGRUCell, self).__init__()\n","#         self.gru = nn.GRUCell(input_size, hidden_size)\n","#         self.layer_norm = nn.LayerNorm(hidden_size)\n","\n","#     def reset_parameters(self):\n","#         self.gru.reset_parameters()  # Reset parameters of the underlying GRU\n","\n","#     def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","#         hidden = self.gru(input, hidden)\n","#         return self.layer_norm(hidden)\n","\n","\n","class EnhancedGRUCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EnhancedGRUCell, self).__init__()\n","        self.gru = nn.GRUCell(input_size, hidden_size)\n","        self.layer_norm = nn.LayerNorm(hidden_size)\n","        # self.dropout = nn.Dropout(dropout_rate)\n","\n","    def reset_parameters(self):\n","        self.gru.reset_parameters()\n","\n","    def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","        new_hidden = self.gru(input, hidden)\n","        new_hidden = self.layer_norm(new_hidden + hidden)  # Residual connection\n","        return new_hidden\n","\n","\n","\n","class AttentiveFP(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = nn.Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.atom_convs = nn.ModuleList()\n","        self.atom_grus = nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(EnhancedGRUCell(hidden_channels, hidden_channels))  # Use enhanced GRU\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","        self.mol_gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.lin2 = nn.Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x)  # Use enhanced GRU\n","        x = F.relu(x)\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x)  # Use enhanced GRU\n","            x = F.relu(x)\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out)  # Use enhanced GRU\n","            out = F.relu(out)\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"ruGBrLAiP0Ao"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# replace GRU by LSTM"],"metadata":{"id":"J-c2UcHSeu7n"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import LSTMCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_lstm = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_lstm.append(LSTMCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False\n","        self.mol_lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.lstm.reset_parameters()\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            conv.reset_parameters()\n","            lstm.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_lstm.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","\n","    # def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","    #             batch: Tensor) -> Tensor:\n","    #     \"\"\"\"\"\"  # noqa: D419\n","    #     # Atom Embedding:\n","    #     x = F.leaky_relu_(self.lin1(x))\n","\n","    #     h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","    #     h = F.dropout(h, p=self.dropout, training=self.training)\n","    #     x = self.gru(h, x).relu_()\n","\n","    #     for conv, gru in zip(self.atom_convs, self.atom_grus):\n","    #         h = conv(x, edge_index)\n","    #         h = F.elu(h)\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         x = gru(h, x).relu()\n","\n","    #     # Molecule Embedding:\n","    #     row = torch.arange(batch.size(0), device=batch.device)\n","    #     edge_index = torch.stack([row, batch], dim=0)\n","\n","    #     out = global_add_pool(x, batch).relu_()\n","    #     for t in range(self.num_timesteps):\n","    #         h = F.elu_(self.mol_conv((x, out), edge_index))\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         out = self.mol_gru(h, out).relu_()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Initialize hidden and cell states for the LSTM\n","        # hx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        # cx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        cx = x\n","\n","        # # Using LSTMCell\n","        # hx, cx = self.lstm(h, (hx, cx))  # Update x with LSTM\n","\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x, cx = lstm(h, (x, cx))  # Update x with LSTM\n","            x = x.relu()\n","\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        cx = out\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out, cx = self.mol_lstm(h, (out, cx))  # Update out with LSTM\n","            out = out.relu()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"IYZC0NAJevD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-gdqoE6Zgf5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","from torch_geometric.transforms import GDC\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.graph_transform = GDC()\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, data, edge_attr,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        print(data.x.shape)\n","        print(data.edge_index.shape)\n","        new_data = self.graph_transform(data)\n","        x, edge_index = new_data.x, new_data.edge_index\n","        print(new_data.x.shape)\n","        print(new_data.edge_index.shape)\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"DiLNbRiKrVXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","from torch_geometric.transforms import GDC\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n","        # edge_updater_type: (x: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFPNew(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.graph_transform = myGDC()\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, data,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        # print(data.edge_index.shape)\n","        # new_data = self.graph_transform(data)\n","\n","        # x, edge_index = new_data.x, new_data.edge_index\n","        # x = F.leaky_relu_(self.lin1(x))\n","\n","\n","      # Check if there are edges in the graph\n","        # print(data.edge_index.shape)\n","        if data.edge_index.size(1) == 0:\n","            # print(\"No edges found. Skipping graph diffusion.\")\n","            x, edge_index = data.x, data.edge_index\n","            x = F.leaky_relu_(self.lin1(data.x))  # Apply linear transformation directly\n","\n","        else:\n","            new_data = self.graph_transform(data)\n","            x, edge_index = new_data.x, new_data.edge_index\n","            x = F.leaky_relu_(self.lin1(x))\n","\n","        # if data.edge_index.size(1) == 0:\n","        #     print(\"No edges found. Skipping graph diffusion.\")\n","        #     x = F.leaky_relu_(self.lin1(data.x))\n","        #     return self.lin2(global_add_pool(x, batch))  # Return output directly\n","\n","        # # Proceed with graph diffusion if edges exist\n","        # try:\n","        #     new_data = self.graph_transform(data)\n","        #     x, edge_index = new_data.x, new_data.edge_index\n","        #     # print(\"Transformed edge index shape:\", edge_index.shape)\n","\n","        #     # Apply the first linear transformation\n","        #     x = F.leaky_relu_(self.lin1(x))\n","\n","        # except Exception as e:\n","        #     print(\"Error during graph transformation:\", e)\n","        #     return None  # Handle appropriately\n","\n","\n","\n","        h = F.elu_(self.gate_conv(x, edge_index))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"BBFiDlWNxD-R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Replace GATConv by GINConv"],"metadata":{"id":"UVe6r3kY9Cw0"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GINConv, TransformerConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = TransformerConv(32, 8, heads=4)\n","\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","\n","        self.mol_conv = TransformerConv(32, 8, heads=4)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"RFPXVE1KcM_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"LSOA7hHEa5fY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        alpha = F.softmax(scores, dim=1)  # Compute softmax for attention weights\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features"],"metadata":{"id":"ZDshdGtj40DQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 8)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"xoWeBBtpMI88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 1)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+1, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"-zwebL4oJ0_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        head: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.head = head\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 8)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATv2Conv(hidden_channels, int(hidden_channels/2), heads = head, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATv2Conv(hidden_channels, int(hidden_channels/2), heads = head,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+1, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"8usAGQ65J1Cv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AttentiveMolBERT"],"metadata":{"id":"ZJ43S4bvQPUn"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor, nn\n","from torch.nn import GRUCell, Linear, Parameter\n","from torch_geometric.nn import GATConv, global_add_pool\n","from torch_geometric.utils import softmax\n","from torch_geometric.nn import MessagePassing\n","\n","class GATEConv(MessagePassing):\n","    def __init__(self, in_channels: int, out_channels: int, edge_dim: int, dropout: float = 0.0):\n","        super().__init__(aggr='add', node_dim=0)\n","        self.dropout = dropout\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","        self.bias = Parameter(torch.empty(out_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.att_l)\n","        nn.init.xavier_uniform_(self.att_r)\n","        nn.init.xavier_uniform_(self.lin1.weight)\n","        nn.init.xavier_uniform_(self.lin2.weight)\n","        nn.init.zeros_(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_update(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha) + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor, index: Tensor, ptr: OptTensor, size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = F.leaky_relu_(alpha_j + alpha_i)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        return F.dropout(alpha, p=self.dropout, training=self.training)\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveMolBERT(nn.Module):\n","    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, edge_dim: int, num_layers: int, num_timesteps: int, dropout: float = 0.0):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = nn.ModuleList()\n","        for _ in range(num_layers):\n","            self.atom_convs.append(GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False))\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        for conv in self.atom_convs:\n","            conv.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv in self.atom_convs:\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = h + x  # Residual connection\n","\n","        out = global_add_pool(x, batch).relu_()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"ULOqx-uVJ1FM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ztdA_vd7J1H_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Featurization for AttentiveFP\n"],"metadata":{"id":"OxOL5EldvTzQ"}},{"cell_type":"code","source":["# import os.path as osp\n","# from math import sqrt\n","# import torch\n","# import torch.nn.functional as F\n","# from rdkit import Chem\n","# from torch_geometric.datasets import MoleculeNet\n","# from torch_geometric.loader import DataLoader\n","# from torch_geometric.nn.models import AttentiveFP\n","\n","# class GenFeatures:\n","#     def __init__(self):\n","#         # self.symbols = [\n","#         #     'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","#         #     'Te', 'I', 'At', 'other'\n","#         # ]\n","\n","#         self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","#             'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","#             'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al',\n","#             'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","#             'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","#             'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","#         self.hybridizations = [\n","#             Chem.rdchem.HybridizationType.S,\n","#             Chem.rdchem.HybridizationType.SP,\n","#             Chem.rdchem.HybridizationType.SP2,\n","#             Chem.rdchem.HybridizationType.SP3,\n","#             Chem.rdchem.HybridizationType.SP3D,\n","#             Chem.rdchem.HybridizationType.SP3D2,\n","#             Chem.rdchem.HybridizationType.UNSPECIFIED,\n","#             'other',\n","#         ]\n","\n","\n","\n","#         self.stereos = [\n","#             Chem.rdchem.BondStereo.STEREONONE,\n","#             Chem.rdchem.BondStereo.STEREOANY,\n","#             Chem.rdchem.BondStereo.STEREOZ,\n","#             Chem.rdchem.BondStereo.STEREOE,\n","#         ]\n","\n","#     def __call__(self, smiles, i):\n","#         # Generate AttentiveFP features\n","#         data = Data()\n","#         mol = Chem.MolFromSmiles(smiles)\n","#         mol = Chem.AddHs(mol)\n","\n","#         xs = []\n","\n","#         for atom in mol.GetAtoms():\n","#           # Initialize the symbol vector\n","#           symbol = [0.] * len(self.symbols)\n","\n","#           # Handle atom symbol\n","#           atom_symbol = atom.GetSymbol()\n","#           if atom_symbol in self.symbols:\n","#               symbol[self.symbols.index(atom_symbol)] = 1.\n","#           else:\n","#               print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","#               symbol[-1] = 1.  # Mark as 'other'\n","\n","#           # Degree of the atom\n","#           degree = [0.] * 6  # Degree list can handle degrees 0-5\n","#           atom_degree = atom.GetDegree()\n","#           if atom_degree < len(degree):\n","#               degree[atom_degree] = 1.\n","\n","#           # Formal charge and radical electrons\n","#           formal_charge = atom.GetFormalCharge()\n","#           radical_electrons = atom.GetNumRadicalElectrons()\n","\n","#           # Hybridization handling\n","#           hybridization = [0.] * len(self.hybridizations)\n","#           try:\n","#               hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","#           except ValueError:\n","#               print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","#               hybridization[-1] = 1.  # Default to 'other'\n","\n","#           # Aromaticity\n","#           aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","#           # Hydrogens\n","#           hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","#           total_hydrogens = atom.GetTotalNumHs()\n","#           if total_hydrogens < len(hydrogens):\n","#               hydrogens[total_hydrogens] = 1.\n","#           else:\n","#               hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","#           # Chirality\n","#           chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","#           chirality_type = [0.] * 2\n","#           if atom.HasProp('_CIPCode'):\n","#               cip_code = atom.GetProp('_CIPCode')\n","#               if cip_code in ['R', 'S']:\n","#                   chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","#           # Construct the feature tensor\n","#           x = torch.tensor(symbol + degree + [formal_charge] +\n","#                           [radical_electrons] + hybridization +\n","#                           [aromaticity] + hydrogens + [chirality] +\n","#                           chirality_type)\n","#           xs.append(x)\n","\n","\n","\n","#         data.x = torch.stack(xs, dim=0)\n","#         data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","\n","#         edge_indices = []\n","#         edge_attrs = []\n","#         for bond in mol.GetBonds():\n","#             edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","#             edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","#             bond_type = bond.GetBondType()\n","#             single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","#             double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","#             triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","#             aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","#             conjugation = 1. if bond.GetIsConjugated() else 0.\n","#             ring = 1. if bond.IsInRing() else 0.\n","#             stereo = [0.] * 4\n","#             stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","#             edge_attr = torch.tensor(\n","#                 [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","#             edge_attrs += [edge_attr, edge_attr]\n","\n","#         if len(edge_attrs) == 0:\n","#             data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","#             data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","#         else:\n","#             data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","#             data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","\n","#         return data\n","\n","\n","# pre_transform=GenFeatures()\n","\n","# data = list()\n","\n","# for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","#     try:\n","#         node_edge_featurization = pre_transform(smiles, i)\n","#         data.append(node_edge_featurization)\n","\n","#     except Exception as e:\n","#         print(f\"Error processing {smiles}: {e}\")\n","\n","# random.shuffle(data)\n","# train = data[:int(len(data)*0.6)] #train set\n","# val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","# test = data[int(len(data)*0.8):]"],"metadata":{"id":"VXj2MejQvT9p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Featurization for AttentiveFP + Graph-level Features"],"metadata":{"id":"GtxALBjvQPap"}},{"cell_type":"code","source":["import os.path as osp\n","from math import sqrt\n","import torch\n","import torch.nn.functional as F\n","from rdkit import Chem\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn.models import AttentiveFP\n","\n","class GenFeatures:\n","    def __init__(self):\n","        # self.symbols = [\n","        #     'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","        #     'Te', 'I', 'At', 'other'\n","        # ]\n","\n","        self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","            'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","            'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al',\n","            'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","            'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","            'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","        self.hybridizations = [\n","            Chem.rdchem.HybridizationType.S,\n","            Chem.rdchem.HybridizationType.SP,\n","            Chem.rdchem.HybridizationType.SP2,\n","            Chem.rdchem.HybridizationType.SP3,\n","            Chem.rdchem.HybridizationType.SP3D,\n","            Chem.rdchem.HybridizationType.SP3D2,\n","            Chem.rdchem.HybridizationType.UNSPECIFIED,\n","            'other',\n","        ]\n","\n","\n","\n","        self.stereos = [\n","            Chem.rdchem.BondStereo.STEREONONE,\n","            Chem.rdchem.BondStereo.STEREOANY,\n","            Chem.rdchem.BondStereo.STEREOZ,\n","            Chem.rdchem.BondStereo.STEREOE,\n","        ]\n","\n","    def __call__(self, smiles, i):\n","        # Generate AttentiveFP features\n","        data = Data()\n","        mol = Chem.MolFromSmiles(smiles)\n","        mol = Chem.AddHs(mol)\n","\n","        xs = []\n","\n","        for atom in mol.GetAtoms():\n","          # Initialize the symbol vector\n","          symbol = [0.] * len(self.symbols)\n","\n","          # Handle atom symbol\n","          atom_symbol = atom.GetSymbol()\n","          if atom_symbol in self.symbols:\n","              symbol[self.symbols.index(atom_symbol)] = 1.\n","          else:\n","              print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","              symbol[-1] = 1.  # Mark as 'other'\n","\n","          # Degree of the atom\n","          degree = [0.] * 6  # Degree list can handle degrees 0-5\n","          atom_degree = atom.GetDegree()\n","          if atom_degree < len(degree):\n","              degree[atom_degree] = 1.\n","\n","          # Formal charge and radical electrons\n","          formal_charge = atom.GetFormalCharge()\n","          radical_electrons = atom.GetNumRadicalElectrons()\n","\n","          # Hybridization handling\n","          hybridization = [0.] * len(self.hybridizations)\n","          try:\n","              hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","          except ValueError:\n","              print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","              hybridization[-1] = 1.  # Default to 'other'\n","\n","          # Aromaticity\n","          aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","          # Hydrogens\n","          hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","          total_hydrogens = atom.GetTotalNumHs()\n","          if total_hydrogens < len(hydrogens):\n","              hydrogens[total_hydrogens] = 1.\n","          else:\n","              hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","          # Chirality\n","          chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","          chirality_type = [0.] * 2\n","          if atom.HasProp('_CIPCode'):\n","              cip_code = atom.GetProp('_CIPCode')\n","              if cip_code in ['R', 'S']:\n","                  chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","          # Construct the feature tensor\n","          x = torch.tensor(symbol + degree + [formal_charge] +\n","                          [radical_electrons] + hybridization +\n","                          [aromaticity] + hydrogens + [chirality] +\n","                          chirality_type)\n","          xs.append(x)\n","\n","\n","\n","        data.x = torch.stack(xs, dim=0)\n","        # data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","        data.y = torch.tensor(Y[i], dtype=torch.float)\n","\n","        edge_indices = []\n","        edge_attrs = []\n","        for bond in mol.GetBonds():\n","            edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","            edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","            bond_type = bond.GetBondType()\n","            single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","            double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","            triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","            aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","            conjugation = 1. if bond.GetIsConjugated() else 0.\n","            ring = 1. if bond.IsInRing() else 0.\n","            stereo = [0.] * 4\n","            stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","            edge_attr = torch.tensor(\n","                [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","            edge_attrs += [edge_attr, edge_attr]\n","\n","        if len(edge_attrs) == 0:\n","            data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","            data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","        else:\n","            data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","            data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","        # graph_level_features = pd.to_numeric(df.iloc[i, :][9:], errors='coerce').fillna(0).values\n","\n","  #       graph_level_features = pd.to_numeric(df.iloc[0, :][[\"MolWt\", \"MolLogP\", \"MolMR\", \"HeavyAtomCount\", \"NumHAcceptors\", \"NumHDonors\", \"NumHeteroatoms\",\n","  #  \"NumRotatableBonds\"]], errors='coerce').fillna(0).values\n","        graph_level_features = pd.to_numeric(df.iloc[i, :][[\"T,K\"]], errors='coerce').fillna(0).values\n","        graph_level_features = torch.tensor(graph_level_features, dtype=torch.float)\n","        data.graph_level_features = graph_level_features\n","\n","        return data\n","\n","\n","pre_transform=GenFeatures()\n","\n","data = list()\n","\n","for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i)\n","        data.append(node_edge_featurization)\n","\n","    except Exception as e:\n","        print(f\"Error processing {smiles}: {e}\")\n","\n","random.shuffle(data)\n","train = data[:int(len(data)*0.6)] #train set\n","val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","test = data[int(len(data)*0.8):]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LdVwrBeQPj9","executionInfo":{"status":"ok","timestamp":1728662623986,"user_tz":360,"elapsed":12604,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a7db668c-3dca-4b38-9152-f930f3c91acd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3168/3168 [00:12<00:00, 257.80it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFzZA-Q7EgzS"},"outputs":[],"source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFPNew(in_channels = 71, hidden_channels = 32, out_channels = 3, edge_dim = 0, num_layers = 3, num_timesteps = 3, dropout = 0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFPNew(in_channels = 87, hidden_channels = 32, out_channels = 3, edge_dim = 0, num_layers = 3, num_timesteps = 3, dropout = 0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"-a6flXE9xzGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 87, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"cOVkaMVRQ1Rv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveMolBERT(in_channels = 87, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"pQ9NfNxxQWRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AttentiveFP w/o Edge Features Training"],"metadata":{"id":"tyXhiln4gFQm"}},{"cell_type":"code","source":["# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')  # Optionally save the model here\n","        # torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Optionally, load the best model for evaluation or inference\n","# model.load_state_dict(torch.load('best_model.pth'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DB6eEap3gFbz","executionInfo":{"status":"ok","timestamp":1728333167248,"user_tz":360,"elapsed":1320641,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"fd452813-5dd5-4d4a-e6c2-a94fcc4bda78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:02<00:00, 96.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 000, Average loss: 0.70926, Accuracy: 0.68576\n","Validation Loss: 0.64483, Validation Accuracy: 0.71092\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 101.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average loss: 0.63151, Accuracy: 0.72266\n","Validation Loss: 0.60271, Validation Accuracy: 0.73798\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 101.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average loss: 0.60593, Accuracy: 0.74153\n","Validation Loss: 0.61000, Validation Accuracy: 0.73246\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average loss: 0.58053, Accuracy: 0.75154\n","Validation Loss: 0.67686, Validation Accuracy: 0.69990\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 101.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average loss: 0.56697, Accuracy: 0.76190\n","Validation Loss: 0.63124, Validation Accuracy: 0.73848\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 102.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average loss: 0.55681, Accuracy: 0.76273\n","Validation Loss: 0.58907, Validation Accuracy: 0.74248\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 102.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average loss: 0.54467, Accuracy: 0.77459\n","Validation Loss: 0.56848, Validation Accuracy: 0.76303\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 99.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average loss: 0.53785, Accuracy: 0.77442\n","Validation Loss: 0.65105, Validation Accuracy: 0.70190\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average loss: 0.53822, Accuracy: 0.77158\n","Validation Loss: 0.54278, Validation Accuracy: 0.77756\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 98.71it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average loss: 0.52779, Accuracy: 0.77726\n","Validation Loss: 0.54546, Validation Accuracy: 0.77305\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average loss: 0.52502, Accuracy: 0.78260\n","Validation Loss: 0.54349, Validation Accuracy: 0.77355\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.72it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average loss: 0.51573, Accuracy: 0.78360\n","Validation Loss: 0.54098, Validation Accuracy: 0.77505\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average loss: 0.51238, Accuracy: 0.78477\n","Validation Loss: 0.54578, Validation Accuracy: 0.77505\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average loss: 0.50563, Accuracy: 0.78461\n","Validation Loss: 0.56887, Validation Accuracy: 0.76303\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average loss: 0.50559, Accuracy: 0.78845\n","Validation Loss: 0.55062, Validation Accuracy: 0.77555\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.61it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average loss: 0.49962, Accuracy: 0.79078\n","Validation Loss: 0.57165, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average loss: 0.49323, Accuracy: 0.79195\n","Validation Loss: 0.56314, Validation Accuracy: 0.77004\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.48711, Accuracy: 0.79813\n","Validation Loss: 0.56914, Validation Accuracy: 0.75952\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 98.22it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48451, Accuracy: 0.80063\n","Validation Loss: 0.52357, Validation Accuracy: 0.78858\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47955, Accuracy: 0.80264\n","Validation Loss: 0.55852, Validation Accuracy: 0.76503\n","No improvement.\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JciblYzxs_hh","executionInfo":{"status":"ok","timestamp":1728494238088,"user_tz":360,"elapsed":182,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"37249490-e0cc-470a-fac0-fdff972fb6f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[23, 87], y=[1, 3], edge_index=[2, 48], edge_attr=[48, 10], graph_level_features=[17])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    data = t.to(device)\n","    out =  model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))\n","    if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"UqhNYjW7smfG","executionInfo":{"status":"ok","timestamp":1728333635588,"user_tz":360,"elapsed":9185,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1ae67029-66cb-43aa-f143-27364ef5e743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1997/1997 [00:08<00:00, 229.40it/s]"]},{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.756634952428643\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([756., 631., 610.]),\n"," array([0.        , 0.66666667, 1.33333333, 2.        ]),\n"," <BarContainer object of 3 artists>)"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["data.x.size(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uUbjPnj4oGe","executionInfo":{"status":"ok","timestamp":1728336537495,"user_tz":360,"elapsed":390,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"8c750da3-1552-472e-ad6c-1bf58797cb00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["# AttentiveFP with Edge Features Training"],"metadata":{"id":"rNgrIHg1IdSX"}},{"cell_type":"code","source":["batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device)\n","print(\"Data x device:\", data.x.device)\n","print(\"Data edge_index device:\", data.edge_index.device)\n","print(\"Data edge_attr device:\", data.edge_attr.device)\n","print(\"Batch device:\", batch.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yhcr0y88g0s","executionInfo":{"status":"ok","timestamp":1728488579831,"user_tz":360,"elapsed":244,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"4f125b8e-9a8a-449f-d1a3-4b5b1cc92f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data x device: cuda:0\n","Data edge_index device: cuda:0\n","Data edge_attr device: cuda:0\n","Batch device: cuda:0\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzp3rZ5ZUtmP","executionInfo":{"status":"ok","timestamp":1728663271131,"user_tz":360,"elapsed":610819,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7b5faea3-350e-40a1-df6c-b5d8e684ae6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:36<00:00, 51.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.28627\n","Validation MAE: 2.65858\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.07751\n","Validation MAE: 2.43465\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 1.94892\n","Validation MAE: 2.60339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 1.88381\n","Validation MAE: 2.30491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 1.82329\n","Validation MAE: 2.26684\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 1.72628\n","Validation MAE: 2.25792\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.75493\n","Validation MAE: 2.18063\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.70654\n","Validation MAE: 2.17976\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.62180\n","Validation MAE: 2.06170\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.59089\n","Validation MAE: 2.31470\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.61654\n","Validation MAE: 1.91234\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.58546\n","Validation MAE: 2.20706\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.93259\n","Validation MAE: 2.26918\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.61346\n","Validation MAE: 2.00220\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.67116\n","Validation MAE: 2.28591\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.62723\n","Validation MAE: 1.95602\n","Early stopping triggered.\n","Test MAE: 1.73615\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nz8Q7VhS9ugf","executionInfo":{"status":"ok","timestamp":1728593864090,"user_tz":360,"elapsed":678125,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1c8cfdfe-4d2c-4db1-849b-9a0ba43052a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.58832\n","Validation MAE: 2.23652\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.37303\n","Validation MAE: 1.96590\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.23817\n","Validation MAE: 2.00218\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.10226\n","Validation MAE: 1.77761\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.05996\n","Validation MAE: 1.76992\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.01351\n","Validation MAE: 1.62056\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.90358\n","Validation MAE: 1.73315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.90072\n","Validation MAE: 1.56338\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.92971\n","Validation MAE: 1.60514\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.76356\n","Validation MAE: 1.58469\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.67738\n","Validation MAE: 2.37662\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:36<00:00, 52.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.67745\n","Validation MAE: 1.43579\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 52.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.60871\n","Validation MAE: 1.39462\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.60697\n","Validation MAE: 1.47260\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.50000\n","Validation MAE: 1.48383\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.89802\n","Validation MAE: 2.02080\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.78003\n","Validation MAE: 1.47221\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.51643\n","Validation MAE: 1.46965\n","Early stopping triggered.\n","Test MAE: 1.55539\n"]}]},{"cell_type":"code","source":["test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ziKiX3KG2EZ","executionInfo":{"status":"ok","timestamp":1728591920838,"user_tz":360,"elapsed":5254,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"c9634cf5-129b-4494-cd29-9d40b8efa83c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.02019\n"]}]},{"cell_type":"markdown","source":["# Proposed new architecture"],"metadata":{"id":"7_hmCjEaWeP-"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9g8au03XcOk","executionInfo":{"status":"ok","timestamp":1728664063319,"user_tz":360,"elapsed":90424,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a6cae0d2-951e-4c60-ee92-1eca8e812356"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.42it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 2.31027\n","Validation MAE: 2.75206\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:29<00:00, 63.90it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 2.15914\n","Validation MAE: 2.62723\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:29<00:00, 63.57it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 2.09892\n","Validation MAE: 2.53519\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 63.03it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.97871\n","Validation MAE: 2.47611\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.92471\n","Validation MAE: 2.70069\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.51it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.93344\n","Validation MAE: 2.42635\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.41it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.85625\n","Validation MAE: 2.37505\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.31it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.83917\n","Validation MAE: 2.38450\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.14it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.81451\n","Validation MAE: 2.41327\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.48it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 1.78228\n","Validation MAE: 2.31284\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 61.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 1.74990\n","Validation MAE: 2.33394\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average MAE: 1.69920\n","Validation MAE: 2.22759\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.13it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average MAE: 1.70625\n","Validation MAE: 2.43220\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.94it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average MAE: 1.75724\n","Validation MAE: 2.34100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average MAE: 1.66868\n","Validation MAE: 2.20905\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.73it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average MAE: 1.60519\n","Validation MAE: 2.08768\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.72it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average MAE: 1.58890\n","Validation MAE: 2.13052\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.53103\n","Validation MAE: 1.99545\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 1.48431\n","Validation MAE: 2.05491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 1.49731\n","Validation MAE: 1.97387\n","Test MAE: 1.71630\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WS5wUVOWQmsf","executionInfo":{"status":"ok","timestamp":1728597915660,"user_tz":360,"elapsed":825686,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"4d4bb8f4-f175-4c8a-a514-f7a2e092790a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:42<00:00, 44.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.55740\n","Validation MAE: 2.16319\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:41<00:00, 46.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.36328\n","Validation MAE: 1.96958\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 43.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.24844\n","Validation MAE: 1.91169\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.18214\n","Validation MAE: 1.87142\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.08860\n","Validation MAE: 2.04773\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.03734\n","Validation MAE: 1.69043\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:43<00:00, 43.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.95420\n","Validation MAE: 1.77980\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.86566\n","Validation MAE: 1.54388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.73050\n","Validation MAE: 1.62706\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 43.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.63665\n","Validation MAE: 1.43829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.65011\n","Validation MAE: 1.61382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.63665\n","Validation MAE: 1.37599\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:47<00:00, 40.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.59954\n","Validation MAE: 1.51327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 42.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.56359\n","Validation MAE: 1.43384\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.63790\n","Validation MAE: 1.41333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.54214\n","Validation MAE: 1.59386\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 42.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.60376\n","Validation MAE: 1.44538\n","Early stopping triggered.\n","Test MAE: 1.46003\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5epMzpL18prZ","executionInfo":{"status":"ok","timestamp":1728601080283,"user_tz":360,"elapsed":714296,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"d45c3c90-ae26-415d-d202-911b469fb069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.51830\n","Validation MAE: 2.09994\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.36492\n","Validation MAE: 2.06528\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.39304\n","Validation MAE: 1.92388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.25737\n","Validation MAE: 1.83519\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 57.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.19016\n","Validation MAE: 1.79237\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.11083\n","Validation MAE: 1.88865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 2.26638\n","Validation MAE: 2.04351\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 2.12054\n","Validation MAE: 1.74315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.98500\n","Validation MAE: 1.86008\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.89674\n","Validation MAE: 1.60660\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.82288\n","Validation MAE: 1.61284\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.70637\n","Validation MAE: 1.54779\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.65584\n","Validation MAE: 1.43947\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.57366\n","Validation MAE: 1.30272\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.53315\n","Validation MAE: 1.28766\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.63625\n","Validation MAE: 1.23703\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.40852\n","Validation MAE: 1.29505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.41947\n","Validation MAE: 1.38161\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 1.49975\n","Validation MAE: 1.25863\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 1.61780\n","Validation MAE: 1.39766\n","Test MAE: 1.58970\n"]}]},{"cell_type":"code","source":["avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrlWKW1RDNod","executionInfo":{"status":"ok","timestamp":1728590963886,"user_tz":360,"elapsed":145,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"96df6936-4b48-4203-be03-d09412196db8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.02103\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":964},"id":"H8wLuczmtvRh","outputId":"8d9c3edd-cf1b-482f-fb04-e8d783f3a4a6","executionInfo":{"status":"error","timestamp":1728589033737,"user_tz":360,"elapsed":402609,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:37<00:00, 50.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 000, Average loss: 0.00551, Accuracy: 0.99947\n","Validation Loss: 0.00003, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:38<00:00, 49.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 48.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 47.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00004, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 48.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:41<00:00, 45.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00006, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:48<00:00, 38.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00002, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▊  | 1494/1900 [00:37<00:10, 40.11it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d49818df1892>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aggregate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Average loss and accuracy for the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","# model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovvpFxpi73_f","executionInfo":{"status":"ok","timestamp":1728589057239,"user_tz":360,"elapsed":4587,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"dd7827c5-2c14-4b73-b66a-afd8afba2eba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.83902, Test Accuracy: 1.00000\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EplJFvln5KM1","executionInfo":{"status":"ok","timestamp":1728525257282,"user_tz":360,"elapsed":965549,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7499319d-2c5f-4855-b943-1a72cf500583"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:26<00:00, 69.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85077, Accuracy: 0.61379\n","Validation Loss: 0.68999, Validation Accuracy: 0.70090\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.67507, Accuracy: 0.71147\n","Validation Loss: 0.74277, Validation Accuracy: 0.68186\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.62121, Accuracy: 0.73201\n","Validation Loss: 0.58771, Validation Accuracy: 0.75351\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.63it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.59840, Accuracy: 0.74487\n","Validation Loss: 0.57700, Validation Accuracy: 0.75802\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.57462, Accuracy: 0.75689\n","Validation Loss: 0.59203, Validation Accuracy: 0.75451\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.33it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.57065, Accuracy: 0.75739\n","Validation Loss: 0.55757, Validation Accuracy: 0.76353\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.34it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.56141, Accuracy: 0.76724\n","Validation Loss: 0.60380, Validation Accuracy: 0.72745\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.60it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.55616, Accuracy: 0.76691\n","Validation Loss: 0.56383, Validation Accuracy: 0.75752\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.37it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.54910, Accuracy: 0.76674\n","Validation Loss: 0.57712, Validation Accuracy: 0.76052\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average loss: 0.53870, Accuracy: 0.77609\n","Validation Loss: 0.59208, Validation Accuracy: 0.73297\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average loss: 0.54117, Accuracy: 0.77208\n","Validation Loss: 0.56655, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average loss: 0.53967, Accuracy: 0.77409\n","Validation Loss: 0.54259, Validation Accuracy: 0.77705\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average loss: 0.53608, Accuracy: 0.76707\n","Validation Loss: 0.54477, Validation Accuracy: 0.76954\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average loss: 0.52757, Accuracy: 0.77425\n","Validation Loss: 0.54618, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average loss: 0.52578, Accuracy: 0.77826\n","Validation Loss: 0.55329, Validation Accuracy: 0.77505\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:25<00:00, 69.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average loss: 0.51995, Accuracy: 0.78477\n","Validation Loss: 0.56865, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average loss: 0.51970, Accuracy: 0.78193\n","Validation Loss: 0.55099, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.51853, Accuracy: 0.78694\n","Validation Loss: 0.57027, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:24<00:00, 71.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.51247, Accuracy: 0.78060\n","Validation Loss: 0.55355, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.51177, Accuracy: 0.78527\n","Validation Loss: 0.53661, Validation Accuracy: 0.77906\n","Model improved! Saving model...\n","Test Loss: 0.50733, Test Accuracy: 0.80120\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OojvRWwIDjZS","executionInfo":{"status":"ok","timestamp":1728575768727,"user_tz":360,"elapsed":151636,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"5140a4ef-d98e-4ab1-a0a9-65955e3e38e5"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:11<00:00, 84.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85436, Accuracy: 0.60778\n","Validation Loss: 0.74178, Validation Accuracy: 0.65681\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.11it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64916, Accuracy: 0.71548\n","Validation Loss: 0.73019, Validation Accuracy: 0.67134\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60810, Accuracy: 0.73668\n","Validation Loss: 0.64961, Validation Accuracy: 0.72094\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.82it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.58794, Accuracy: 0.74720\n","Validation Loss: 0.63767, Validation Accuracy: 0.72846\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56584, Accuracy: 0.76340\n","Validation Loss: 0.65949, Validation Accuracy: 0.70942\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:05<00:00, 90.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55449, Accuracy: 0.76056\n","Validation Loss: 0.60995, Validation Accuracy: 0.73747\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.55171, Accuracy: 0.76089\n","Validation Loss: 0.61828, Validation Accuracy: 0.74198\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.02it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53734, Accuracy: 0.77225\n","Validation Loss: 0.61481, Validation Accuracy: 0.73597\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52516, Accuracy: 0.77926\n","Validation Loss: 0.57212, Validation Accuracy: 0.76303\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51602, Accuracy: 0.78143\n","Validation Loss: 0.59689, Validation Accuracy: 0.75301\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.17it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.51498, Accuracy: 0.78160\n","Validation Loss: 0.59276, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.89it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.52642, Accuracy: 0.77793\n","Validation Loss: 0.60376, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.92it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.51168, Accuracy: 0.78728\n","Validation Loss: 0.56862, Validation Accuracy: 0.76453\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.50189, Accuracy: 0.78310\n","Validation Loss: 0.61160, Validation Accuracy: 0.75200\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49787, Accuracy: 0.79496\n","Validation Loss: 0.60499, Validation Accuracy: 0.76653\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.49510, Accuracy: 0.79245\n","Validation Loss: 0.57490, Validation Accuracy: 0.76854\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.95it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.49007, Accuracy: 0.79279\n","Validation Loss: 0.57761, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.39it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.48619, Accuracy: 0.79563\n","Validation Loss: 0.56819, Validation Accuracy: 0.77204\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48783, Accuracy: 0.79663\n","Validation Loss: 0.57474, Validation Accuracy: 0.75100\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47551, Accuracy: 0.79846\n","Validation Loss: 0.59259, Validation Accuracy: 0.76102\n","No improvement.\n","Test Loss: 0.53733, Test Accuracy: 0.78117\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTtJcZP_E_fI","executionInfo":{"status":"ok","timestamp":1728580146768,"user_tz":360,"elapsed":249167,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"af119501-b53e-41d2-aaff-6ec2727aabb8"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 74.93it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.82706, Accuracy: 0.62765\n","Validation Loss: 0.77245, Validation Accuracy: 0.66283\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 77.79it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64119, Accuracy: 0.72366\n","Validation Loss: 0.64681, Validation Accuracy: 0.72545\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.60it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60780, Accuracy: 0.74086\n","Validation Loss: 0.59995, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.57781, Accuracy: 0.75405\n","Validation Loss: 0.65299, Validation Accuracy: 0.71894\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56418, Accuracy: 0.75906\n","Validation Loss: 0.61743, Validation Accuracy: 0.72695\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.76it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55040, Accuracy: 0.76824\n","Validation Loss: 0.58008, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.69it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.53890, Accuracy: 0.77642\n","Validation Loss: 0.57799, Validation Accuracy: 0.75651\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:15<00:00, 78.94it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53069, Accuracy: 0.78210\n","Validation Loss: 0.57792, Validation Accuracy: 0.76754\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.56it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52230, Accuracy: 0.78761\n","Validation Loss: 0.55527, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.62it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51634, Accuracy: 0.78210\n","Validation Loss: 0.59114, Validation Accuracy: 0.75701\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.50713, Accuracy: 0.78327\n","Validation Loss: 0.58000, Validation Accuracy: 0.75802\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.26it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.50051, Accuracy: 0.79162\n","Validation Loss: 0.57951, Validation Accuracy: 0.76503\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.71it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.49515, Accuracy: 0.79279\n","Validation Loss: 0.57201, Validation Accuracy: 0.77154\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.49333, Accuracy: 0.79262\n","Validation Loss: 0.55736, Validation Accuracy: 0.77455\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49008, Accuracy: 0.79663\n","Validation Loss: 0.56211, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.48785, Accuracy: 0.79679\n","Validation Loss: 0.55073, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.13it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.48828, Accuracy: 0.79279\n","Validation Loss: 0.56119, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.47811, Accuracy: 0.80681\n","Validation Loss: 0.57704, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48195, Accuracy: 0.79813\n","Validation Loss: 0.54990, Validation Accuracy: 0.77856\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47356, Accuracy: 0.80314\n","Validation Loss: 0.55569, Validation Accuracy: 0.77655\n","No improvement.\n","Test Loss: 0.53218, Test Accuracy: 0.77967\n"]}]},{"cell_type":"code","source":["out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eIlysDDTCnK","executionInfo":{"status":"ok","timestamp":1728507650969,"user_tz":360,"elapsed":17,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"11b82aad-340a-4c14-a789-f778bd2cfe39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3])"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"hrx8uChapzv-","executionInfo":{"status":"error","timestamp":1728577930581,"user_tz":360,"elapsed":7,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"f14f0288-72e8-4bfb-aee4-caaa38f24113"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-630d30490e8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Testing phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."]}]},{"cell_type":"markdown","source":["# AttentiveFP with Edge Features Training and with explicit H"],"metadata":{"id":"BgJHKrsJBbod"}},{"cell_type":"code","source":["# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index,  data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')  # Optionally save the model here\n","        # torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n"],"metadata":{"id":"FR1hgaxO3nss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    data = t.to(device)\n","    out =  model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))\n","    if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"iW8qj2L1hly3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hgYz5-AQKRzu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N2Sr6W94KR2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ENl3Qi2bKR5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bgncwAnKKR77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"Cn6GHEwApotV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OruDaljhkJo1"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"BdRts-d6xvqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"XYPTqNQ3Jjfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"bT1TBhmLm-Xz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSMB8bn8EgzS"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"y26rL55OFsiv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"o_KfMVv7LfH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTq0pyD8kLPD"},"outputs":[],"source":["#test SMILES string\n","def evaluate_smiles(smiles_string):\n","    classes = ['insoluble', 'slightly soluble', 'soluble']\n","    G = read_smiles(smiles_string, explicit_hydrogen=True) #decode smiles string\n","    feature = element_to_onehot(np.asarray(G.nodes(data='element'))[:, 1]) #convert element to one-hot vector\n","    edges = np.asarray(G.edges) #get edge array\n","    index = np.asarray([edges[:,0], edges[:,1]]) #reformat edge array to torch geometric suitable format\n","    d = Data(x=torch.tensor(feature, dtype=torch.float),edge_index=torch.tensor(index, dtype=torch.long)) #create torch gemoetry Data object\n","    data = d.to(device) #send data to device memory\n","    model.eval() #set model to evaluate mode\n","    print(classes[torch.argmax(torch.softmax(model(data), dim=0)).item()]) #evaluate the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jA3XzaqSEgzU"},"outputs":[],"source":["evaluate_smiles('C(C(C1C(=C(C(=O)O1)O)O)O)O') #test out the model on Vitamin C"]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"sFJravvfFXnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"y97qNDsUFZSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n"],"metadata":{"id":"pVreebmsFa25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n"],"metadata":{"id":"cFVXAU2mFa-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"o1P2nnTsFbG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n"],"metadata":{"id":"eOURHC-aFbWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"l5vTfaraFbc3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1HA6r0-vwQaMEzZv67ynoo2rRZjpJ82kI","timestamp":1728587242065}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}