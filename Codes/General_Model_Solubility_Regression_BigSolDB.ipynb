{"cells":[{"cell_type":"code","source":["!pip install torch\n","!pip install torch-geometric\n","!pip install pysmiles\n","!pip install rdkit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywbw1oASEjEd","executionInfo":{"status":"ok","timestamp":1729522721246,"user_tz":360,"elapsed":14136,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"9d6cad1d-45af-4774-e154-9fa9590061d7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.15.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n","Collecting pysmiles\n","  Downloading pysmiles-1.1.2-py2.py3-none-any.whl.metadata (10 kB)\n","Collecting pbr (from pysmiles)\n","  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pysmiles) (3.4.1)\n","Downloading pysmiles-1.1.2-py2.py3-none-any.whl (22 kB)\n","Downloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pbr, pysmiles\n","Successfully installed pbr-6.1.0 pysmiles-1.1.2\n","Collecting rdkit\n","  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n","Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rdkit\n","Successfully installed rdkit-2024.3.5\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZevvLDjT7rMD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729522760055,"user_tz":360,"elapsed":38813,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"11d0ff66-e2af-4877-9c0b-dc9414cef302"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from pysmiles import read_smiles\n","import pandas as pd\n","import logging\n","from tqdm import tqdm\n","import torch\n","from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n","import torch.nn.functional as F\n","from torch_geometric.nn import MessagePassing, GCNConv\n","from torch_geometric.utils import remove_self_loops, add_self_loops, degree\n","from torch_geometric.data import Data\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","logging.getLogger('pysmiles').setLevel(logging.CRITICAL)"]},{"cell_type":"markdown","source":["# Dataset\n","1. AqSolDB (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","2. OChem (https://ochem.eu/login/show.do?render-mode=full)\n","3. BigSolDB (https://zenodo.org/records/6984601)\n","\n"],"metadata":{"id":"OhZwPD4fDh2F"}},{"cell_type":"markdown","source":["# BigSolDB"],"metadata":{"id":"T3D7t9ODx3dt"}},{"cell_type":"code","source":["# BigSolDB.csv\n","\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","df = pd.read_csv('gdrive/My Drive/Base_GNN_Solubility/BigSolDB.csv')\n","# df = df[df['Solvent']=='water']\n","df['Solubility'] = np.log(df['Solubility'])\n","df = df.reset_index(drop=True)\n","\n","X_smiles = list(df['SMILES']) #get smiles strings from file\n","X_smiles_Solvent = list(df['SMILES_Solvent'])\n","Y = np.asarray(df['Solubility']) #get solubility values from file\n","\n","# columns_to_normalize = [\n","#     \"MolWt\",\n","#     \"MolLogP\",\n","#     \"MolMR\",\n","#     \"HeavyAtomCount\",\n","#     \"NumHAcceptors\",\n","#     \"NumHDonors\",\n","#     \"NumHeteroatoms\",\n","#     \"NumRotatableBonds\"]\n","\n","columns_to_normalize = [\n","    \"T,K\"]\n","\n","scaler = MinMaxScaler()\n","df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])*100\n","\n","\n","# def is_valid_smiles(smiles):\n","#     \"\"\"Check if a SMILES string is valid.\"\"\"\n","#     try:\n","#         mol = Chem.MolFromSmiles(smiles)\n","#         return mol is not None\n","#     except Exception:\n","#         return False\n","\n","# # Remove invalid solute SMILES\n","# df = df[df['SMILES'].apply(is_valid_smiles)]\n","\n","# # Remove invalid solvent SMILES\n","# df = df[df['SMILES_Solvent'].apply(is_valid_smiles)]\n","# df\n","\n","\n","df = df[~df['SMILES'].str.contains('-')]\n","df = df[~df['SMILES_Solvent'].str.contains('-')]\n","df.reset_index(drop=True, inplace=True)\n","df\n"],"metadata":{"id":"YOIAiOYBx3nW","executionInfo":{"status":"ok","timestamp":1729522801472,"user_tz":360,"elapsed":356,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"71a26a28-205e-4929-98f6-08b571cfb7be"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               SMILES      T,K  Solubility   Solvent  \\\n","0              ON(Cc1ccccc1)Cc1ccccc1  18.7500   -6.675850  methanol   \n","1              ON(Cc1ccccc1)Cc1ccccc1  22.5000   -6.369509  methanol   \n","2              ON(Cc1ccccc1)Cc1ccccc1  25.1875   -6.168679  methanol   \n","3              ON(Cc1ccccc1)Cc1ccccc1  28.6875   -5.892525  methanol   \n","4              ON(Cc1ccccc1)Cc1ccccc1  31.1875   -5.705684  methanol   \n","...                               ...      ...         ...       ...   \n","42014  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  44.6875   -4.112916       DMS   \n","42015  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  46.8125   -3.967536       DMS   \n","42016  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  48.4375   -3.860855       DMS   \n","42017  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  50.0625   -3.753738       DMS   \n","42018  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  52.0000   -3.616001       DMS   \n","\n","         SMILES_Solvent                       Source  \n","0                    CO     10.1021/acs.jced.9b01028  \n","1                    CO     10.1021/acs.jced.9b01028  \n","2                    CO     10.1021/acs.jced.9b01028  \n","3                    CO     10.1021/acs.jced.9b01028  \n","4                    CO     10.1021/acs.jced.9b01028  \n","...                 ...                          ...  \n","42014  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","42015  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","42016  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","42017  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","42018  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","\n","[42019 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-adf970fe-75bc-4332-995f-f3da494f4dbd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMILES</th>\n","      <th>T,K</th>\n","      <th>Solubility</th>\n","      <th>Solvent</th>\n","      <th>SMILES_Solvent</th>\n","      <th>Source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>18.7500</td>\n","      <td>-6.675850</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>22.5000</td>\n","      <td>-6.369509</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>25.1875</td>\n","      <td>-6.168679</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>28.6875</td>\n","      <td>-5.892525</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>31.1875</td>\n","      <td>-5.705684</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>42014</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>44.6875</td>\n","      <td>-4.112916</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>42015</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>46.8125</td>\n","      <td>-3.967536</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>42016</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>48.4375</td>\n","      <td>-3.860855</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>42017</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>50.0625</td>\n","      <td>-3.753738</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>42018</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>52.0000</td>\n","      <td>-3.616001</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>42019 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adf970fe-75bc-4332-995f-f3da494f4dbd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-adf970fe-75bc-4332-995f-f3da494f4dbd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-adf970fe-75bc-4332-995f-f3da494f4dbd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bf71e7c2-1378-4b70-b260-7d92f7af45d0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf71e7c2-1378-4b70-b260-7d92f7af45d0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bf71e7c2-1378-4b70-b260-7d92f7af45d0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_cdc27f59-9c98-4880-8de0-cce6903fb071\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cdc27f59-9c98-4880-8de0-cce6903fb071 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 42019,\n  \"fields\": [\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 645,\n        \"samples\": [\n          \"CC(=O)c1ccc(NC2=NCCC3(CCCCC3)S2)cc1\",\n          \"Oc1ccc(O)cc1\",\n          \"CN=C1CN(O)C(c2ccccc2)=c2cc(Cl)ccc2=N1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T,K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.18198303149532,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2628,\n        \"samples\": [\n          24.381250000000023,\n          31.656250000000007,\n          31.2875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solubility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6872665951223547,\n        \"min\": -16.120799302532635,\n        \"max\": -0.050661914802227995,\n        \"num_unique_values\": 22945,\n        \"samples\": [\n          -7.5593767127135845,\n          -6.78624586158494,\n          -2.916921093129701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"dipropyl ether\",\n          \"n-heptanol\",\n          \"1,4-dioxane\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES_Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 122,\n        \"samples\": [\n          \"CCC(C)O\",\n          \"CC(=O)O\",\n          \"CC(=O)CC(C)=O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 604,\n        \"samples\": [\n          \"10.1021/acs.jced.8b01014\",\n          \"10.1021/acs.jced.0c00043\",\n          \"10.1021/je8002332\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}]},{"source":["# @title Solubility\n","\n","from matplotlib import pyplot as plt\n","df['Solubility'].plot(kind='hist', bins=20, title='Solubility')\n","plt.gca().spines[['top', 'right',]].set_visible(False)"],"cell_type":"code","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":452},"id":"79nY1CLHRx7T","executionInfo":{"status":"ok","timestamp":1729450418452,"user_tz":360,"elapsed":319,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"9376bd0f-8c14-4b96-e8de-ce5f228383b2"}},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"SPF-zHqNf0n7","executionInfo":{"status":"ok","timestamp":1729286331440,"user_tz":360,"elapsed":373,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"915cfae0-e4e9-4ce8-8b62-fabe56c79998"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               SMILES      T,K  Solubility   Solvent  \\\n","0              ON(Cc1ccccc1)Cc1ccccc1  18.7500   -6.675850  methanol   \n","1              ON(Cc1ccccc1)Cc1ccccc1  22.5000   -6.369509  methanol   \n","2              ON(Cc1ccccc1)Cc1ccccc1  25.1875   -6.168679  methanol   \n","3              ON(Cc1ccccc1)Cc1ccccc1  28.6875   -5.892525  methanol   \n","4              ON(Cc1ccccc1)Cc1ccccc1  31.1875   -5.705684  methanol   \n","...                               ...      ...         ...       ...   \n","54268  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  44.6875   -4.112916       DMS   \n","54269  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  46.8125   -3.967536       DMS   \n","54270  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  48.4375   -3.860855       DMS   \n","54271  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  50.0625   -3.753738       DMS   \n","54272  COC(=O)C1CC(=O)C(C(=O)OC)CC1=O  52.0000   -3.616001       DMS   \n","\n","         SMILES_Solvent                       Source  \n","0                    CO     10.1021/acs.jced.9b01028  \n","1                    CO     10.1021/acs.jced.9b01028  \n","2                    CO     10.1021/acs.jced.9b01028  \n","3                    CO     10.1021/acs.jced.9b01028  \n","4                    CO     10.1021/acs.jced.9b01028  \n","...                 ...                          ...  \n","54268  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54269  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54270  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54271  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","54272  COC(=O)CCC(=O)OC  10.1016/j.fluid.2014.04.012  \n","\n","[54273 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-6d7f322f-e445-4db4-952d-6e807a4a4af5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMILES</th>\n","      <th>T,K</th>\n","      <th>Solubility</th>\n","      <th>Solvent</th>\n","      <th>SMILES_Solvent</th>\n","      <th>Source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>18.7500</td>\n","      <td>-6.675850</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>22.5000</td>\n","      <td>-6.369509</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>25.1875</td>\n","      <td>-6.168679</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>28.6875</td>\n","      <td>-5.892525</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ON(Cc1ccccc1)Cc1ccccc1</td>\n","      <td>31.1875</td>\n","      <td>-5.705684</td>\n","      <td>methanol</td>\n","      <td>CO</td>\n","      <td>10.1021/acs.jced.9b01028</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54268</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>44.6875</td>\n","      <td>-4.112916</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54269</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>46.8125</td>\n","      <td>-3.967536</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54270</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>48.4375</td>\n","      <td>-3.860855</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54271</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>50.0625</td>\n","      <td>-3.753738</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","    <tr>\n","      <th>54272</th>\n","      <td>COC(=O)C1CC(=O)C(C(=O)OC)CC1=O</td>\n","      <td>52.0000</td>\n","      <td>-3.616001</td>\n","      <td>DMS</td>\n","      <td>COC(=O)CCC(=O)OC</td>\n","      <td>10.1016/j.fluid.2014.04.012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54273 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d7f322f-e445-4db4-952d-6e807a4a4af5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6d7f322f-e445-4db4-952d-6e807a4a4af5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6d7f322f-e445-4db4-952d-6e807a4a4af5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d16c235f-89bb-42fe-8df0-cb8142fc5d44\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d16c235f-89bb-42fe-8df0-cb8142fc5d44')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d16c235f-89bb-42fe-8df0-cb8142fc5d44 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_a23b0808-bf81-4177-85f4-ec81cb02613d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_a23b0808-bf81-4177-85f4-ec81cb02613d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 54273,\n  \"fields\": [\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 830,\n        \"samples\": [\n          \"Cc1cc(C)cc(OCC2CNC(=O)O2)c1\",\n          \"O=c1ccc2ccccc2o1\",\n          \"OC[C@H]1O[C@H](O[C@]2(CCl)O[C@H](CCl)[C@@H](O)[C@@H]2O)[C@H](O)[C@@H](O)[C@H]1Cl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T,K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.16168289728885,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2856,\n        \"samples\": [\n          32.69374999999999,\n          31.200000000000006,\n          42.55000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solubility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7575861321573574,\n        \"min\": -23.62368793069608,\n        \"max\": -0.050661914802227995,\n        \"num_unique_values\": 26997,\n        \"samples\": [\n          -3.627445747929844,\n          -8.711445639078157,\n          -6.765388037695215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 138,\n        \"samples\": [\n          \"m-xylene\",\n          \"n-decanol\",\n          \"toluene\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES_Solvent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 129,\n        \"samples\": [\n          \"CCCOCCC\",\n          \"CCCCCCCO\",\n          \"C1COCCO1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 771,\n        \"samples\": [\n          \"10.1021/je7002463\",\n          \"10.1021/je800991v\",\n          \"10.1021/je8002332\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import os.path as osp\n","import random\n","import pandas as pd\n","import torch\n","from rdkit import Chem\n","from tqdm import tqdm\n","from torch_geometric.data import Data\n","\n","class GenFeatures:\n","    def __init__(self):\n","        self.symbols = [\n","            'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","            'Te', 'I', 'At', 'other'\n","        ]\n","        self.hybridizations = [\n","            Chem.rdchem.HybridizationType.S,\n","            Chem.rdchem.HybridizationType.SP,\n","            Chem.rdchem.HybridizationType.SP2,\n","            Chem.rdchem.HybridizationType.SP3,\n","            Chem.rdchem.HybridizationType.SP3D,\n","            Chem.rdchem.HybridizationType.SP3D2,\n","            Chem.rdchem.HybridizationType.UNSPECIFIED,\n","            'other',\n","        ]\n","        self.stereos = [\n","            Chem.rdchem.BondStereo.STEREONONE,\n","            Chem.rdchem.BondStereo.STEREOANY,\n","            Chem.rdchem.BondStereo.STEREOZ,\n","            Chem.rdchem.BondStereo.STEREOE,\n","        ]\n","\n","    def __call__(self, smiles, i, y):\n","        # Generate features for the molecule\n","        data = Data()\n","        mol = Chem.MolFromSmiles(smiles)\n","        mol = Chem.AddHs(mol)\n","\n","        xs = []\n","        for atom in mol.GetAtoms():\n","            symbol = [0.] * len(self.symbols)\n","            atom_symbol = atom.GetSymbol()\n","            if atom_symbol in self.symbols:\n","                symbol[self.symbols.index(atom_symbol)] = 1.\n","            else:\n","                symbol[-1] = 1.  # Mark as 'other'\n","\n","            degree = [0.] * 6\n","            atom_degree = atom.GetDegree()\n","            if atom_degree < len(degree):\n","                degree[atom_degree] = 1.\n","\n","            formal_charge = atom.GetFormalCharge()\n","            radical_electrons = atom.GetNumRadicalElectrons()\n","            hybridization = [0.] * len(self.hybridizations)\n","            try:\n","                hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","            except ValueError:\n","                hybridization[-1] = 1.  # Default to 'other'\n","\n","            aromaticity = 1. if atom.GetIsAromatic() else 0.\n","            hydrogens = [0.] * 5\n","            total_hydrogens = atom.GetTotalNumHs()\n","            if total_hydrogens < len(hydrogens):\n","                hydrogens[total_hydrogens] = 1.\n","            else:\n","                hydrogens[-1] = 1.\n","\n","            chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","            chirality_type = [0.] * 2\n","            if atom.HasProp('_CIPCode'):\n","                cip_code = atom.GetProp('_CIPCode')\n","                if cip_code in ['R', 'S']:\n","                    chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","            x = torch.tensor(symbol + degree + [formal_charge] +\n","                             [radical_electrons] + hybridization +\n","                             [aromaticity] + hydrogens + [chirality] +\n","                             chirality_type)\n","            xs.append(x)\n","\n","        data.x = torch.stack(xs, dim=0)\n","        data.y = torch.tensor(y, dtype=torch.float)\n","\n","        edge_indices = []\n","        edge_attrs = []\n","        for bond in mol.GetBonds():\n","            edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","            edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","            bond_type = bond.GetBondType()\n","            single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","            double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","            triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","            aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","            conjugation = 1. if bond.GetIsConjugated() else 0.\n","            ring = 1. if bond.IsInRing() else 0.\n","            stereo = [0.] * 4\n","            stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","            edge_attr = torch.tensor(\n","                [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","            edge_attrs += [edge_attr, edge_attr]\n","\n","        if len(edge_attrs) == 0:\n","            data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","            data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","        else:\n","            data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","            data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","        graph_level_features = pd.to_numeric(df.iloc[i, :][[\"T,K\"]], errors='coerce').fillna(0).values\n","        graph_level_features = torch.tensor(graph_level_features, dtype=torch.float)\n","        data.graph_level_features = graph_level_features\n","\n","        return data\n","\n","\n","# Assuming df contains columns 'SMILES' for solutes and 'SMILES_Solvent' for solvents\n","X_smiles = list(df['SMILES'])\n","X_smiles_solvent = list(df['SMILES_Solvent'])\n","Y_solute = list(df['Solubility'])  # Your target for solutes\n","Y_solvent = list(df['Solubility'])   # Your target for solvents\n","\n","pre_transform = GenFeatures()\n","\n","data_solute = []\n","data_solvent = []\n","\n","# Process solutes\n","for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i, Y_solute[i])\n","        data_solute.append(node_edge_featurization)\n","    except Exception as e:\n","        print(f\"Error processing solute {smiles}: {e}\")\n","\n","# Process solvents\n","for i, smiles in tqdm(enumerate(X_smiles_solvent), total=len(X_smiles_solvent)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i, Y_solvent[i])\n","        data_solvent.append(node_edge_featurization)\n","    except Exception as e:\n","        print(f\"Error processing solvent {smiles}: {e}\")\n","\n","# Shuffle and split the data\n","combined_data = list(zip(data_solute, data_solvent))\n","random.shuffle(combined_data)\n","train_size = int(len(combined_data) * 0.6)\n","val_size = int(len(combined_data) * 0.2)\n","train_data = combined_data[:train_size]\n","val_data = combined_data[train_size:train_size + val_size]\n","test_data = combined_data[train_size + val_size:]\n","\n","print(f\"Training data: {len(train_data)}, Validation data: {len(val_data)}, Test data: {len(test_data)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ocy2rq75H6cB","executionInfo":{"status":"ok","timestamp":1729522983508,"user_tz":360,"elapsed":172047,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"065a4115-f446-4001-d09d-dc7da78998ab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 42019/42019 [01:51<00:00, 377.35it/s]\n","100%|██████████| 42019/42019 [01:00<00:00, 697.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training data: 25211, Validation data: 8403, Test data: 8405\n"]}]},{"cell_type":"code","source":["combined_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaDdGWVMjpLB","executionInfo":{"status":"ok","timestamp":1729287743862,"user_tz":360,"elapsed":411,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"9a321395-cba6-4b89-84f4-472d44d9ddf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Data(x=[42, 41], y=-5.921938419342041, edge_index=[2, 90], edge_attr=[90, 10], graph_level_features=[1]),\n"," Data(x=[27, 41], y=-5.921938419342041, edge_index=[2, 52], edge_attr=[52, 10], graph_level_features=[1]))"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["combined_data[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0n0K6gexjydD","executionInfo":{"status":"ok","timestamp":1729287755172,"user_tz":360,"elapsed":358,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"40819916-6694-49cc-d4ae-8e34f64bef97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Data(x=[23, 41], y=-3.424978017807007, edge_index=[2, 44], edge_attr=[44, 10], graph_level_features=[1]),\n"," Data(x=[3, 41], y=-3.424978017807007, edge_index=[2, 4], edge_attr=[4, 10], graph_level_features=[1]))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["combined_data[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKmSUJ8Cj1Bt","executionInfo":{"status":"ok","timestamp":1729287768134,"user_tz":360,"elapsed":554,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a7b7a175-4c32-40f7-952c-e06e9ed64663"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Data(x=[35, 41], y=-9.783218383789062, edge_index=[2, 74], edge_attr=[74, 10], graph_level_features=[1]),\n"," Data(x=[15, 41], y=-9.783218383789062, edge_index=[2, 28], edge_attr=[28, 10], graph_level_features=[1]))"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["combined_data[2][0].y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7X7OpDWj2O2","executionInfo":{"status":"ok","timestamp":1729288823331,"user_tz":360,"elapsed":336,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"5667d49c-f406-400d-f59c-ca60fc16370a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-9.7832)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":[],"metadata":{"id":"6Sb82fmBj2Rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X-lu_T44j2UK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# General Model for both Modeling Solvent-Solute Pair\n"],"metadata":{"id":"2CAoWGL7c5Kb"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        # return self.lin2(out)\n","        return out\n","\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","class Solute_Solvent_Model(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout):\n","        super(Solute_Solvent_Model, self).__init__()\n","        self.attentive_fp = AttentiveFP(in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout)\n","        self.linear = torch.nn.Linear(hidden_channels*2+1, 1)\n","\n","    def forward(self, combined_data):\n","        data_solute, data_solvent = combined_data\n","        x1, edge_index1, edge_attr1, batch1, graph_level_features = data_solute.x, data_solute.edge_index, data_solute.edge_attr, torch.zeros(data_solute.x.size(0), dtype=torch.long), data_solute.graph_level_features\n","        out = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2, edge_index2, edge_attr2, batch2 = data_solvent.x, data_solvent.edge_index, data_solvent.edge_attr, torch.zeros(data_solvent.x.size(0), dtype=torch.long)\n","        x1 = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2 = self.attentive_fp(x2, edge_index2, edge_attr2, batch2)\n","\n","\n","        x = torch.cat((x1, x2), dim=1)\n","        # print(x.shape)\n","        x = torch.concat((x, graph_level_features.unsqueeze(0)), dim = -1)\n","        # print(x.shape)\n","        x = self.linear(x)\n","        # print(x.shape)\n","\n","        return x\n","\n","    def __repr__(self):\n","        return self.attentive_fp.__repr__()\n","\n","\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","model = Solute_Solvent_Model(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","# # model = Net().to(device) #create network and send to the device memory\n","# model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    # random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train_data):  # Go over each training point\n","        data = d # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data)  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train_data)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val_data:\n","            data = d  # Send data to device\n","            out = model(data)  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val_data)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWC_Oio2UEWm","outputId":"f5ede239-d0f9-41bd-f4a5-d3d7a14958db"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:24<00:00, 40.39it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.77998\n","Validation MAE: 1.59979\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:35<00:00, 43.78it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 1.48991\n","Validation MAE: 1.37517\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:31<00:00, 44.12it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 1.36794\n","Validation MAE: 1.31930\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:43<00:00, 43.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.30199\n","Validation MAE: 1.28751\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:44<00:00, 43.17it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.25870\n","Validation MAE: 1.24200\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:32<00:00, 44.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.23924\n","Validation MAE: 1.17676\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:22<00:00, 44.84it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.19571\n","Validation MAE: 1.16288\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:28<00:00, 44.33it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.19201\n","Validation MAE: 1.15310\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:17<00:00, 45.21it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.18790\n","Validation MAE: 1.13862\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:12<00:00, 45.65it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 1.23368\n","Validation MAE: 1.38566\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:23<00:00, 44.73it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 1.19350\n","Validation MAE: 1.15082\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:13<00:00, 45.58it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average MAE: 1.15947\n","Validation MAE: 1.16322\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:14<00:00, 45.49it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average MAE: 1.14381\n","Validation MAE: 1.15293\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:21<00:00, 44.90it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average MAE: 1.14098\n","Validation MAE: 1.11698\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:20<00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.10936\n","Validation MAE: 1.09034\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:27<00:00, 44.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.10917\n","Validation MAE: 1.11368\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 206/25211 [00:04<09:25, 44.24it/s]"]}]},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        # return self.lin2(out)\n","        return out\n","\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","class Solute_Solvent_Model(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout):\n","        super(Solute_Solvent_Model, self).__init__()\n","        self.attentive_fp = AttentiveFP(in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout)\n","        self.linear = torch.nn.Linear(hidden_channels*2+1, 1)\n","\n","    def forward(self, combined_data):\n","        data_solute, data_solvent = combined_data\n","        x1, edge_index1, edge_attr1, batch1, graph_level_features = data_solute.x, data_solute.edge_index, data_solute.edge_attr, torch.zeros(data_solute.x.size(0), dtype=torch.long), data_solute.graph_level_features\n","        out = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2, edge_index2, edge_attr2, batch2 = data_solvent.x, data_solvent.edge_index, data_solvent.edge_attr, torch.zeros(data_solvent.x.size(0), dtype=torch.long)\n","        x1 = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2 = self.attentive_fp(x2, edge_index2, edge_attr2, batch2)\n","\n","\n","        x = torch.cat((x1, x2), dim=1)\n","        # print(x.shape)\n","        x = torch.concat((x, graph_level_features.unsqueeze(0)), dim = -1)\n","        # print(x.shape)\n","        x = self.linear(x)\n","        # print(x.shape)\n","\n","        return x\n","\n","    def __repr__(self):\n","        return self.attentive_fp.__repr__()\n","\n","\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","model = Solute_Solvent_Model(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","\n","mae_loss = nn.L1Loss()\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEYdNrQ1FEqg","executionInfo":{"status":"ok","timestamp":1729464012102,"user_tz":360,"elapsed":78134,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"0d4ffabc-0ffb-44d5-9d75-f937f2e4afc9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 1.08561\n","R-squared: 0.66814\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","\n","\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    # random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train_data):  # Go over each training point\n","        data = d # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data)  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train_data)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val_data:\n","            data = d  # Send data to device\n","            out = model(data)  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val_data)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"M5_iRcpzF95u","executionInfo":{"status":"error","timestamp":1729472451037,"user_tz":360,"elapsed":475262,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"c7a028bd-950e-442f-b4b3-0e721f9fcf52"},"execution_count":10,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:15<00:00, 40.98it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.39086\n","Validation MAE: 1.24778\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:40<00:00, 43.40it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 1.13557\n","Validation MAE: 1.04414\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:30<00:00, 39.96it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 1.11370\n","Validation MAE: 1.07055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:44<00:00, 39.13it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.13918\n","Validation MAE: 1.12707\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:40<00:00, 39.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.12720\n","Validation MAE: 1.09328\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:28<00:00, 44.34it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.14847\n","Validation MAE: 1.07197\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:28<00:00, 44.38it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.11145\n","Validation MAE: 1.12070\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:11<00:00, 45.71it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.11606\n","Validation MAE: 1.03730\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:16<00:00, 45.30it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.10212\n","Validation MAE: 1.06518\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:06<00:00, 46.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 1.09697\n","Validation MAE: 1.04174\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:03<00:00, 46.41it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 1.08802\n","Validation MAE: 1.09026\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:02<00:00, 46.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.08603\n","Validation MAE: 1.13592\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 20062/25211 [07:17<01:52, 45.82it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-82770827f97a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;31m# Send data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate data point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-6ecb8b133058>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, combined_data)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_solvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_solvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_solvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_solvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentive_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentive_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-6ecb8b133058>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_convs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_grus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1475\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m         ret = _VF.gru_cell(\n\u001b[0m\u001b[1;32m   1478\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","class Solute_Solvent_Model(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout):\n","        super(Solute_Solvent_Model, self).__init__()\n","        self.attentive_fp = AttentiveFP(in_channels, hidden_channels, out_channels, edge_dim, num_layers, num_timesteps, dropout)\n","        self.linear = torch.nn.Linear(out_channels*2+1, 1)\n","\n","    def forward(self, combined_data):\n","        data_solute, data_solvent = combined_data\n","        x1, edge_index1, edge_attr1, batch1, graph_level_features = data_solute.x, data_solute.edge_index, data_solute.edge_attr, torch.zeros(data_solute.x.size(0), dtype=torch.long), data_solute.graph_level_features\n","        out = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2, edge_index2, edge_attr2, batch2 = data_solvent.x, data_solvent.edge_index, data_solvent.edge_attr, torch.zeros(data_solvent.x.size(0), dtype=torch.long)\n","        x1 = self.attentive_fp(x1, edge_index1, edge_attr1, batch1)\n","        x2 = self.attentive_fp(x2, edge_index2, edge_attr2, batch2)\n","\n","\n","        x = torch.cat((x1, x2), dim=1)\n","        x = torch.concat((x, graph_level_features.unsqueeze(0)), dim = -1)\n","        x = self.linear(x)\n","\n","        return x\n","\n","    def __repr__(self):\n","        return self.attentive_fp.__repr__()\n","\n","\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","model = Solute_Solvent_Model(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","# # model = Net().to(device) #create network and send to the device memory\n","# model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    # random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train_data):  # Go over each training point\n","        data = d # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data)  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train_data)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val_data:\n","            data = d  # Send data to device\n","            out = model(data)  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val_data)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h70s8aSHc5UT","outputId":"09f78069-2a75-4c2d-8962-d6e041521897"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [13:09<00:00, 31.95it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.92067\n","Validation MAE: 1.62651\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:36<00:00, 36.18it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 1.60857\n","Validation MAE: 1.48909\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:49<00:00, 38.83it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 1.49596\n","Validation MAE: 1.46925\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:33<00:00, 39.77it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.41560\n","Validation MAE: 1.28585\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:39<00:00, 39.44it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.37840\n","Validation MAE: 1.28561\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:01<00:00, 38.09it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.35123\n","Validation MAE: 1.29248\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:33<00:00, 36.33it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.31783\n","Validation MAE: 1.28501\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:03<00:00, 38.01it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.33488\n","Validation MAE: 1.29817\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:20<00:00, 37.04it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.32654\n","Validation MAE: 1.27067\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:11<00:00, 37.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 1.29366\n","Validation MAE: 1.26806\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:44<00:00, 39.14it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 1.29045\n","Validation MAE: 1.21578\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:04<00:00, 37.92it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average MAE: 1.25838\n","Validation MAE: 1.19925\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:47<00:00, 38.93it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average MAE: 1.25608\n","Validation MAE: 1.17875\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:45<00:00, 39.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average MAE: 1.25330\n","Validation MAE: 1.20199\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:58<00:00, 38.29it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average MAE: 1.24760\n","Validation MAE: 1.19503\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:31<00:00, 36.44it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average MAE: 1.21200\n","Validation MAE: 1.23582\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:19<00:00, 37.09it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average MAE: 1.20149\n","Validation MAE: 1.13093\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:15<00:00, 37.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 018, Average MAE: 1.17836\n","Validation MAE: 1.16561\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 8315/25211 [03:41<06:56, 40.61it/s]"]}]},{"cell_type":"code","source":["model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    # random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train_data):  # Go over each training point\n","        data = d # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data)  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train_data)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val_data:\n","            data = d  # Send data to device\n","            out = model(data)  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val_data)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wuu49_sDlSmy","executionInfo":{"status":"error","timestamp":1729395728149,"user_tz":360,"elapsed":7098740,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7507b1f1-a2f8-4d73-810e-87babf17c2d7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:36<00:00, 43.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.44943\n","Validation MAE: 1.26110\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:10<00:00, 45.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 1.22009\n","Validation MAE: 1.21032\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:28<00:00, 44.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 1.19712\n","Validation MAE: 1.20192\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:13<00:00, 45.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 1.19677\n","Validation MAE: 1.19407\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:14<00:00, 45.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 1.17991\n","Validation MAE: 1.16129\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:05<00:00, 46.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 1.18330\n","Validation MAE: 1.16967\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:02<00:00, 46.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.16457\n","Validation MAE: 1.13351\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:22<00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.17222\n","Validation MAE: 1.16227\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [10:10<00:00, 41.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.18419\n","Validation MAE: 1.14097\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:05<00:00, 46.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.16564\n","Validation MAE: 1.13275\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25211/25211 [09:06<00:00, 46.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.15826\n","Validation MAE: 1.16697\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 15804/25211 [05:47<03:26, 45.49it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d61289a0e396>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate data point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aggregate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3353\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3354\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    # random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train_data):  # Go over each training point\n","        data = d # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data)  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train_data)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val_data:\n","            data = d  # Send data to device\n","            out = model(data)  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val_data)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":911},"id":"mkYBLWAaUGir","executionInfo":{"status":"error","timestamp":1729440643334,"user_tz":360,"elapsed":9428,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"40b0da22-57cb-4d1b-840c-d563a38e6840"},"execution_count":15,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [11:07<00:00, 37.74it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.45148\n","Validation MAE: 1.23363\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:57<00:00, 42.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 1.16940\n","Validation MAE: 1.11649\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:29<00:00, 40.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 1.15229\n","Validation MAE: 1.09312\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:11<00:00, 41.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.12733\n","Validation MAE: 1.10043\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [10:51<00:00, 38.72it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.12822\n","Validation MAE: 1.08749\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:08<00:00, 45.97it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.38769\n","Validation MAE: 1.39104\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:15<00:00, 45.36it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.32142\n","Validation MAE: 1.20813\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:23<00:00, 44.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.23368\n","Validation MAE: 1.21758\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 25211/25211 [09:30<00:00, 44.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.24996\n","Validation MAE: 1.18082\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 14155/25211 [05:09<04:01, 45.75it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d61289a0e396>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;31m# Send data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate data point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# no T"],"metadata":{"id":"fyngrVCdSRc5"}},{"cell_type":"code","source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G14y9CupBMET","executionInfo":{"status":"ok","timestamp":1729395795323,"user_tz":360,"elapsed":55343,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"5bff5935-9e5d-4bde-d29f-59c0531ddc62"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 1.15364\n","R-squared: 0.65158\n"]}]},{"cell_type":"markdown","source":["# W. T"],"metadata":{"id":"c0xak8ArSUBy"}},{"cell_type":"code","source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kda2rpDSUJp","executionInfo":{"status":"ok","timestamp":1729440728811,"user_tz":360,"elapsed":78010,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"9d4432d7-b41d-4d14-9ab8-b3b0bffc3a61"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 1.09993\n","R-squared: 0.66613\n"]}]},{"cell_type":"markdown","source":["# W. T (version 2)"],"metadata":{"id":"-OOVGVEimASr"}},{"cell_type":"code","source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test_data:\n","        data = d\n","        out = model(data)  # Evaluate test point\n","        actual_values = data[0].y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data[0].y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test_data)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5dTGRKvl_yD","executionInfo":{"status":"ok","timestamp":1729472583691,"user_tz":360,"elapsed":75683,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a7d2ba12-13fe-4243-961c-78a5aaca8e4a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 1.06140\n","R-squared: 0.67394\n"]}]},{"cell_type":"markdown","source":["# AttentiveFP (with edge features)"],"metadata":{"id":"-hJQ36Jl3QAd"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"UX5bVRU-3QIh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Proposed New Architecture"],"metadata":{"id":"cBBJ1JYJPz2-"}},{"cell_type":"markdown","source":["#replace GAT by SAGEConv"],"metadata":{"id":"Qr2GHwa6SDAo"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GCNConv, GraphConv, SAGEConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = SAGEConv(hidden_channels, hidden_channels)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = SAGEConv(hidden_channels, hidden_channels)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"CLNxaXZ1SB1m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Improved GRU"],"metadata":{"id":"aO_VPlr6erj6"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","# class EnhancedGRUCell(nn.Module):\n","#     def __init__(self, input_size, hidden_size):\n","#         super(EnhancedGRUCell, self).__init__()\n","#         self.gru = nn.GRUCell(input_size, hidden_size)\n","#         self.layer_norm = nn.LayerNorm(hidden_size)\n","\n","#     def reset_parameters(self):\n","#         self.gru.reset_parameters()  # Reset parameters of the underlying GRU\n","\n","#     def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","#         hidden = self.gru(input, hidden)\n","#         return self.layer_norm(hidden)\n","\n","\n","class EnhancedGRUCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EnhancedGRUCell, self).__init__()\n","        self.gru = nn.GRUCell(input_size, hidden_size)\n","        self.layer_norm = nn.LayerNorm(hidden_size)\n","        # self.dropout = nn.Dropout(dropout_rate)\n","\n","    def reset_parameters(self):\n","        self.gru.reset_parameters()\n","\n","    def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","        new_hidden = self.gru(input, hidden)\n","        new_hidden = self.layer_norm(new_hidden + hidden)  # Residual connection\n","        return new_hidden\n","\n","\n","\n","class AttentiveFP(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = nn.Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.atom_convs = nn.ModuleList()\n","        self.atom_grus = nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(EnhancedGRUCell(hidden_channels, hidden_channels))  # Use enhanced GRU\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","        self.mol_gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.lin2 = nn.Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x)  # Use enhanced GRU\n","        x = F.relu(x)\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x)  # Use enhanced GRU\n","            x = F.relu(x)\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out)  # Use enhanced GRU\n","            out = F.relu(out)\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"ruGBrLAiP0Ao"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# replace GRU by LSTM"],"metadata":{"id":"J-c2UcHSeu7n"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import LSTMCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_lstm = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_lstm.append(LSTMCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False\n","        self.mol_lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.lstm.reset_parameters()\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            conv.reset_parameters()\n","            lstm.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_lstm.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","\n","    # def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","    #             batch: Tensor) -> Tensor:\n","    #     \"\"\"\"\"\"  # noqa: D419\n","    #     # Atom Embedding:\n","    #     x = F.leaky_relu_(self.lin1(x))\n","\n","    #     h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","    #     h = F.dropout(h, p=self.dropout, training=self.training)\n","    #     x = self.gru(h, x).relu_()\n","\n","    #     for conv, gru in zip(self.atom_convs, self.atom_grus):\n","    #         h = conv(x, edge_index)\n","    #         h = F.elu(h)\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         x = gru(h, x).relu()\n","\n","    #     # Molecule Embedding:\n","    #     row = torch.arange(batch.size(0), device=batch.device)\n","    #     edge_index = torch.stack([row, batch], dim=0)\n","\n","    #     out = global_add_pool(x, batch).relu_()\n","    #     for t in range(self.num_timesteps):\n","    #         h = F.elu_(self.mol_conv((x, out), edge_index))\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         out = self.mol_gru(h, out).relu_()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Initialize hidden and cell states for the LSTM\n","        # hx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        # cx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        cx = x\n","\n","        # # Using LSTMCell\n","        # hx, cx = self.lstm(h, (hx, cx))  # Update x with LSTM\n","\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x, cx = lstm(h, (x, cx))  # Update x with LSTM\n","            x = x.relu()\n","\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        cx = out\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out, cx = self.mol_lstm(h, (out, cx))  # Update out with LSTM\n","            out = out.relu()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"IYZC0NAJevD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-gdqoE6Zgf5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","from torch_geometric.transforms import GDC\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.graph_transform = GDC()\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, data, edge_attr,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        print(data.x.shape)\n","        print(data.edge_index.shape)\n","        new_data = self.graph_transform(data)\n","        x, edge_index = new_data.x, new_data.edge_index\n","        print(new_data.x.shape)\n","        print(new_data.edge_index.shape)\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"DiLNbRiKrVXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","from torch_geometric.transforms import GDC\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n","        # edge_updater_type: (x: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFPNew(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.graph_transform = myGDC()\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, data,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        # print(data.edge_index.shape)\n","        # new_data = self.graph_transform(data)\n","\n","        # x, edge_index = new_data.x, new_data.edge_index\n","        # x = F.leaky_relu_(self.lin1(x))\n","\n","\n","      # Check if there are edges in the graph\n","        # print(data.edge_index.shape)\n","        if data.edge_index.size(1) == 0:\n","            # print(\"No edges found. Skipping graph diffusion.\")\n","            x, edge_index = data.x, data.edge_index\n","            x = F.leaky_relu_(self.lin1(data.x))  # Apply linear transformation directly\n","\n","        else:\n","            new_data = self.graph_transform(data)\n","            x, edge_index = new_data.x, new_data.edge_index\n","            x = F.leaky_relu_(self.lin1(x))\n","\n","        # if data.edge_index.size(1) == 0:\n","        #     print(\"No edges found. Skipping graph diffusion.\")\n","        #     x = F.leaky_relu_(self.lin1(data.x))\n","        #     return self.lin2(global_add_pool(x, batch))  # Return output directly\n","\n","        # # Proceed with graph diffusion if edges exist\n","        # try:\n","        #     new_data = self.graph_transform(data)\n","        #     x, edge_index = new_data.x, new_data.edge_index\n","        #     # print(\"Transformed edge index shape:\", edge_index.shape)\n","\n","        #     # Apply the first linear transformation\n","        #     x = F.leaky_relu_(self.lin1(x))\n","\n","        # except Exception as e:\n","        #     print(\"Error during graph transformation:\", e)\n","        #     return None  # Handle appropriately\n","\n","\n","\n","        h = F.elu_(self.gate_conv(x, edge_index))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"BBFiDlWNxD-R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Replace GATConv by GINConv"],"metadata":{"id":"UVe6r3kY9Cw0"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GINConv, TransformerConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = TransformerConv(32, 8, heads=4)\n","\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","\n","        self.mol_conv = TransformerConv(32, 8, heads=4)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"RFPXVE1KcM_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"LSOA7hHEa5fY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        alpha = F.softmax(scores, dim=1)  # Compute softmax for attention weights\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features"],"metadata":{"id":"ZDshdGtj40DQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 8)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"xoWeBBtpMI88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 1)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+1, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"-zwebL4oJ0_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        head: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.head = head\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 8)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATv2Conv(hidden_channels, int(hidden_channels/2), heads = head, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATv2Conv(hidden_channels, int(hidden_channels/2), heads = head,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+1, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"8usAGQ65J1Cv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AttentiveMolBERT"],"metadata":{"id":"ZJ43S4bvQPUn"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor, nn\n","from torch.nn import GRUCell, Linear, Parameter\n","from torch_geometric.nn import GATConv, global_add_pool\n","from torch_geometric.utils import softmax\n","from torch_geometric.nn import MessagePassing\n","\n","class GATEConv(MessagePassing):\n","    def __init__(self, in_channels: int, out_channels: int, edge_dim: int, dropout: float = 0.0):\n","        super().__init__(aggr='add', node_dim=0)\n","        self.dropout = dropout\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","        self.bias = Parameter(torch.empty(out_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.att_l)\n","        nn.init.xavier_uniform_(self.att_r)\n","        nn.init.xavier_uniform_(self.lin1.weight)\n","        nn.init.xavier_uniform_(self.lin2.weight)\n","        nn.init.zeros_(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_update(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha) + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor, index: Tensor, ptr: OptTensor, size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = F.leaky_relu_(alpha_j + alpha_i)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        return F.dropout(alpha, p=self.dropout, training=self.training)\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveMolBERT(nn.Module):\n","    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, edge_dim: int, num_layers: int, num_timesteps: int, dropout: float = 0.0):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = nn.ModuleList()\n","        for _ in range(num_layers):\n","            self.atom_convs.append(GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False))\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        for conv in self.atom_convs:\n","            conv.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding\n","        x = F.leaky_relu_(self.lin1(x))\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv in self.atom_convs:\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = h + x  # Residual connection\n","\n","        out = global_add_pool(x, batch).relu_()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"],"metadata":{"id":"ULOqx-uVJ1FM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ztdA_vd7J1H_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Featurization for AttentiveFP\n"],"metadata":{"id":"OxOL5EldvTzQ"}},{"cell_type":"code","source":["# import os.path as osp\n","# from math import sqrt\n","# import torch\n","# import torch.nn.functional as F\n","# from rdkit import Chem\n","# from torch_geometric.datasets import MoleculeNet\n","# from torch_geometric.loader import DataLoader\n","# from torch_geometric.nn.models import AttentiveFP\n","\n","# class GenFeatures:\n","#     def __init__(self):\n","#         # self.symbols = [\n","#         #     'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","#         #     'Te', 'I', 'At', 'other'\n","#         # ]\n","\n","#         self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","#             'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","#             'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al',\n","#             'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","#             'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","#             'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","#         self.hybridizations = [\n","#             Chem.rdchem.HybridizationType.S,\n","#             Chem.rdchem.HybridizationType.SP,\n","#             Chem.rdchem.HybridizationType.SP2,\n","#             Chem.rdchem.HybridizationType.SP3,\n","#             Chem.rdchem.HybridizationType.SP3D,\n","#             Chem.rdchem.HybridizationType.SP3D2,\n","#             Chem.rdchem.HybridizationType.UNSPECIFIED,\n","#             'other',\n","#         ]\n","\n","\n","\n","#         self.stereos = [\n","#             Chem.rdchem.BondStereo.STEREONONE,\n","#             Chem.rdchem.BondStereo.STEREOANY,\n","#             Chem.rdchem.BondStereo.STEREOZ,\n","#             Chem.rdchem.BondStereo.STEREOE,\n","#         ]\n","\n","#     def __call__(self, smiles, i):\n","#         # Generate AttentiveFP features\n","#         data = Data()\n","#         mol = Chem.MolFromSmiles(smiles)\n","#         mol = Chem.AddHs(mol)\n","\n","#         xs = []\n","\n","#         for atom in mol.GetAtoms():\n","#           # Initialize the symbol vector\n","#           symbol = [0.] * len(self.symbols)\n","\n","#           # Handle atom symbol\n","#           atom_symbol = atom.GetSymbol()\n","#           if atom_symbol in self.symbols:\n","#               symbol[self.symbols.index(atom_symbol)] = 1.\n","#           else:\n","#               print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","#               symbol[-1] = 1.  # Mark as 'other'\n","\n","#           # Degree of the atom\n","#           degree = [0.] * 6  # Degree list can handle degrees 0-5\n","#           atom_degree = atom.GetDegree()\n","#           if atom_degree < len(degree):\n","#               degree[atom_degree] = 1.\n","\n","#           # Formal charge and radical electrons\n","#           formal_charge = atom.GetFormalCharge()\n","#           radical_electrons = atom.GetNumRadicalElectrons()\n","\n","#           # Hybridization handling\n","#           hybridization = [0.] * len(self.hybridizations)\n","#           try:\n","#               hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","#           except ValueError:\n","#               print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","#               hybridization[-1] = 1.  # Default to 'other'\n","\n","#           # Aromaticity\n","#           aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","#           # Hydrogens\n","#           hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","#           total_hydrogens = atom.GetTotalNumHs()\n","#           if total_hydrogens < len(hydrogens):\n","#               hydrogens[total_hydrogens] = 1.\n","#           else:\n","#               hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","#           # Chirality\n","#           chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","#           chirality_type = [0.] * 2\n","#           if atom.HasProp('_CIPCode'):\n","#               cip_code = atom.GetProp('_CIPCode')\n","#               if cip_code in ['R', 'S']:\n","#                   chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","#           # Construct the feature tensor\n","#           x = torch.tensor(symbol + degree + [formal_charge] +\n","#                           [radical_electrons] + hybridization +\n","#                           [aromaticity] + hydrogens + [chirality] +\n","#                           chirality_type)\n","#           xs.append(x)\n","\n","\n","\n","#         data.x = torch.stack(xs, dim=0)\n","#         data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","\n","#         edge_indices = []\n","#         edge_attrs = []\n","#         for bond in mol.GetBonds():\n","#             edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","#             edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","#             bond_type = bond.GetBondType()\n","#             single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","#             double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","#             triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","#             aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","#             conjugation = 1. if bond.GetIsConjugated() else 0.\n","#             ring = 1. if bond.IsInRing() else 0.\n","#             stereo = [0.] * 4\n","#             stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","#             edge_attr = torch.tensor(\n","#                 [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","#             edge_attrs += [edge_attr, edge_attr]\n","\n","#         if len(edge_attrs) == 0:\n","#             data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","#             data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","#         else:\n","#             data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","#             data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","\n","#         return data\n","\n","\n","# pre_transform=GenFeatures()\n","\n","# data = list()\n","\n","# for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","#     try:\n","#         node_edge_featurization = pre_transform(smiles, i)\n","#         data.append(node_edge_featurization)\n","\n","#     except Exception as e:\n","#         print(f\"Error processing {smiles}: {e}\")\n","\n","# random.shuffle(data)\n","# train = data[:int(len(data)*0.6)] #train set\n","# val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","# test = data[int(len(data)*0.8):]"],"metadata":{"id":"VXj2MejQvT9p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Featurization for AttentiveFP + Graph-level Features"],"metadata":{"id":"GtxALBjvQPap"}},{"cell_type":"code","source":["import os.path as osp\n","from math import sqrt\n","import torch\n","import torch.nn.functional as F\n","from rdkit import Chem\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn.models import AttentiveFP\n","\n","class GenFeatures:\n","    def __init__(self):\n","        # self.symbols = [\n","        #     'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","        #     'Te', 'I', 'At', 'other'\n","        # ]\n","\n","        self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","            'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","            'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al',\n","            'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","            'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","            'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","        self.hybridizations = [\n","            Chem.rdchem.HybridizationType.S,\n","            Chem.rdchem.HybridizationType.SP,\n","            Chem.rdchem.HybridizationType.SP2,\n","            Chem.rdchem.HybridizationType.SP3,\n","            Chem.rdchem.HybridizationType.SP3D,\n","            Chem.rdchem.HybridizationType.SP3D2,\n","            Chem.rdchem.HybridizationType.UNSPECIFIED,\n","            'other',\n","        ]\n","\n","\n","\n","        self.stereos = [\n","            Chem.rdchem.BondStereo.STEREONONE,\n","            Chem.rdchem.BondStereo.STEREOANY,\n","            Chem.rdchem.BondStereo.STEREOZ,\n","            Chem.rdchem.BondStereo.STEREOE,\n","        ]\n","\n","    def __call__(self, smiles, i):\n","        # Generate AttentiveFP features\n","        data = Data()\n","        mol = Chem.MolFromSmiles(smiles)\n","        mol = Chem.AddHs(mol)\n","\n","        xs = []\n","\n","        for atom in mol.GetAtoms():\n","          # Initialize the symbol vector\n","          symbol = [0.] * len(self.symbols)\n","\n","          # Handle atom symbol\n","          atom_symbol = atom.GetSymbol()\n","          if atom_symbol in self.symbols:\n","              symbol[self.symbols.index(atom_symbol)] = 1.\n","          else:\n","              print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","              symbol[-1] = 1.  # Mark as 'other'\n","\n","          # Degree of the atom\n","          degree = [0.] * 6  # Degree list can handle degrees 0-5\n","          atom_degree = atom.GetDegree()\n","          if atom_degree < len(degree):\n","              degree[atom_degree] = 1.\n","\n","          # Formal charge and radical electrons\n","          formal_charge = atom.GetFormalCharge()\n","          radical_electrons = atom.GetNumRadicalElectrons()\n","\n","          # Hybridization handling\n","          hybridization = [0.] * len(self.hybridizations)\n","          try:\n","              hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","          except ValueError:\n","              print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","              hybridization[-1] = 1.  # Default to 'other'\n","\n","          # Aromaticity\n","          aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","          # Hydrogens\n","          hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","          total_hydrogens = atom.GetTotalNumHs()\n","          if total_hydrogens < len(hydrogens):\n","              hydrogens[total_hydrogens] = 1.\n","          else:\n","              hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","          # Chirality\n","          chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","          chirality_type = [0.] * 2\n","          if atom.HasProp('_CIPCode'):\n","              cip_code = atom.GetProp('_CIPCode')\n","              if cip_code in ['R', 'S']:\n","                  chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","          # Construct the feature tensor\n","          x = torch.tensor(symbol + degree + [formal_charge] +\n","                          [radical_electrons] + hybridization +\n","                          [aromaticity] + hydrogens + [chirality] +\n","                          chirality_type)\n","          xs.append(x)\n","\n","\n","\n","        data.x = torch.stack(xs, dim=0)\n","        # data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","        data.y = torch.tensor(Y[i], dtype=torch.float)\n","\n","        edge_indices = []\n","        edge_attrs = []\n","        for bond in mol.GetBonds():\n","            edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","            edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","            bond_type = bond.GetBondType()\n","            single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","            double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","            triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","            aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","            conjugation = 1. if bond.GetIsConjugated() else 0.\n","            ring = 1. if bond.IsInRing() else 0.\n","            stereo = [0.] * 4\n","            stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","            edge_attr = torch.tensor(\n","                [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","            edge_attrs += [edge_attr, edge_attr]\n","\n","        if len(edge_attrs) == 0:\n","            data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","            data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","        else:\n","            data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","            data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","        # graph_level_features = pd.to_numeric(df.iloc[i, :][9:], errors='coerce').fillna(0).values\n","\n","  #       graph_level_features = pd.to_numeric(df.iloc[0, :][[\"MolWt\", \"MolLogP\", \"MolMR\", \"HeavyAtomCount\", \"NumHAcceptors\", \"NumHDonors\", \"NumHeteroatoms\",\n","  #  \"NumRotatableBonds\"]], errors='coerce').fillna(0).values\n","        graph_level_features = pd.to_numeric(df.iloc[i, :][[\"T,K\"]], errors='coerce').fillna(0).values\n","        graph_level_features = torch.tensor(graph_level_features, dtype=torch.float)\n","        data.graph_level_features = graph_level_features\n","\n","        return data\n","\n","\n","pre_transform=GenFeatures()\n","\n","data = list()\n","\n","for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i)\n","        data.append(node_edge_featurization)\n","\n","    except Exception as e:\n","        print(f\"Error processing {smiles}: {e}\")\n","\n","random.shuffle(data)\n","train = data[:int(len(data)*0.6)] #train set\n","val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","test = data[int(len(data)*0.8):]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LdVwrBeQPj9","executionInfo":{"status":"ok","timestamp":1728662623986,"user_tz":360,"elapsed":12604,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a7db668c-3dca-4b38-9152-f930f3c91acd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3168/3168 [00:12<00:00, 257.80it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFzZA-Q7EgzS"},"outputs":[],"source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFPNew(in_channels = 71, hidden_channels = 32, out_channels = 3, edge_dim = 0, num_layers = 3, num_timesteps = 3, dropout = 0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFPNew(in_channels = 87, hidden_channels = 32, out_channels = 3, edge_dim = 0, num_layers = 3, num_timesteps = 3, dropout = 0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"-a6flXE9xzGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 87, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"cOVkaMVRQ1Rv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveMolBERT(in_channels = 87, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"pQ9NfNxxQWRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AttentiveFP w/o Edge Features Training"],"metadata":{"id":"tyXhiln4gFQm"}},{"cell_type":"code","source":["# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')  # Optionally save the model here\n","        # torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Optionally, load the best model for evaluation or inference\n","# model.load_state_dict(torch.load('best_model.pth'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DB6eEap3gFbz","executionInfo":{"status":"ok","timestamp":1728333167248,"user_tz":360,"elapsed":1320641,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"fd452813-5dd5-4d4a-e6c2-a94fcc4bda78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:02<00:00, 96.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 000, Average loss: 0.70926, Accuracy: 0.68576\n","Validation Loss: 0.64483, Validation Accuracy: 0.71092\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 101.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average loss: 0.63151, Accuracy: 0.72266\n","Validation Loss: 0.60271, Validation Accuracy: 0.73798\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 101.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average loss: 0.60593, Accuracy: 0.74153\n","Validation Loss: 0.61000, Validation Accuracy: 0.73246\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average loss: 0.58053, Accuracy: 0.75154\n","Validation Loss: 0.67686, Validation Accuracy: 0.69990\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 101.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average loss: 0.56697, Accuracy: 0.76190\n","Validation Loss: 0.63124, Validation Accuracy: 0.73848\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 102.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average loss: 0.55681, Accuracy: 0.76273\n","Validation Loss: 0.58907, Validation Accuracy: 0.74248\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:58<00:00, 102.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average loss: 0.54467, Accuracy: 0.77459\n","Validation Loss: 0.56848, Validation Accuracy: 0.76303\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 99.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average loss: 0.53785, Accuracy: 0.77442\n","Validation Loss: 0.65105, Validation Accuracy: 0.70190\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average loss: 0.53822, Accuracy: 0.77158\n","Validation Loss: 0.54278, Validation Accuracy: 0.77756\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 98.71it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average loss: 0.52779, Accuracy: 0.77726\n","Validation Loss: 0.54546, Validation Accuracy: 0.77305\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average loss: 0.52502, Accuracy: 0.78260\n","Validation Loss: 0.54349, Validation Accuracy: 0.77355\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.72it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average loss: 0.51573, Accuracy: 0.78360\n","Validation Loss: 0.54098, Validation Accuracy: 0.77505\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average loss: 0.51238, Accuracy: 0.78477\n","Validation Loss: 0.54578, Validation Accuracy: 0.77505\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average loss: 0.50563, Accuracy: 0.78461\n","Validation Loss: 0.56887, Validation Accuracy: 0.76303\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average loss: 0.50559, Accuracy: 0.78845\n","Validation Loss: 0.55062, Validation Accuracy: 0.77555\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.61it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average loss: 0.49962, Accuracy: 0.79078\n","Validation Loss: 0.57165, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average loss: 0.49323, Accuracy: 0.79195\n","Validation Loss: 0.56314, Validation Accuracy: 0.77004\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [00:59<00:00, 100.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.48711, Accuracy: 0.79813\n","Validation Loss: 0.56914, Validation Accuracy: 0.75952\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 98.22it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48451, Accuracy: 0.80063\n","Validation Loss: 0.52357, Validation Accuracy: 0.78858\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:00<00:00, 99.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47955, Accuracy: 0.80264\n","Validation Loss: 0.55852, Validation Accuracy: 0.76503\n","No improvement.\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JciblYzxs_hh","executionInfo":{"status":"ok","timestamp":1728494238088,"user_tz":360,"elapsed":182,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"37249490-e0cc-470a-fac0-fdff972fb6f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[23, 87], y=[1, 3], edge_index=[2, 48], edge_attr=[48, 10], graph_level_features=[17])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    data = t.to(device)\n","    out =  model(data.x, data.edge_index, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))\n","    if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"UqhNYjW7smfG","executionInfo":{"status":"ok","timestamp":1728333635588,"user_tz":360,"elapsed":9185,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1ae67029-66cb-43aa-f143-27364ef5e743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1997/1997 [00:08<00:00, 229.40it/s]"]},{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.756634952428643\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([756., 631., 610.]),\n"," array([0.        , 0.66666667, 1.33333333, 2.        ]),\n"," <BarContainer object of 3 artists>)"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["data.x.size(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uUbjPnj4oGe","executionInfo":{"status":"ok","timestamp":1728336537495,"user_tz":360,"elapsed":390,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"8c750da3-1552-472e-ad6c-1bf58797cb00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["# AttentiveFP with Edge Features Training"],"metadata":{"id":"rNgrIHg1IdSX"}},{"cell_type":"code","source":["batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device)\n","print(\"Data x device:\", data.x.device)\n","print(\"Data edge_index device:\", data.edge_index.device)\n","print(\"Data edge_attr device:\", data.edge_attr.device)\n","print(\"Batch device:\", batch.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yhcr0y88g0s","executionInfo":{"status":"ok","timestamp":1728488579831,"user_tz":360,"elapsed":244,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"4f125b8e-9a8a-449f-d1a3-4b5b1cc92f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data x device: cuda:0\n","Data edge_index device: cuda:0\n","Data edge_attr device: cuda:0\n","Batch device: cuda:0\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzp3rZ5ZUtmP","executionInfo":{"status":"ok","timestamp":1728663271131,"user_tz":360,"elapsed":610819,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7b5faea3-350e-40a1-df6c-b5d8e684ae6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:36<00:00, 51.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.28627\n","Validation MAE: 2.65858\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.07751\n","Validation MAE: 2.43465\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 1.94892\n","Validation MAE: 2.60339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 1.88381\n","Validation MAE: 2.30491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 1.82329\n","Validation MAE: 2.26684\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 54.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 1.72628\n","Validation MAE: 2.25792\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.75493\n","Validation MAE: 2.18063\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.70654\n","Validation MAE: 2.17976\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.62180\n","Validation MAE: 2.06170\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.59089\n","Validation MAE: 2.31470\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.61654\n","Validation MAE: 1.91234\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.58546\n","Validation MAE: 2.20706\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.93259\n","Validation MAE: 2.26918\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.61346\n","Validation MAE: 2.00220\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.67116\n","Validation MAE: 2.28591\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.62723\n","Validation MAE: 1.95602\n","Early stopping triggered.\n","Test MAE: 1.73615\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nz8Q7VhS9ugf","executionInfo":{"status":"ok","timestamp":1728593864090,"user_tz":360,"elapsed":678125,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1c8cfdfe-4d2c-4db1-849b-9a0ba43052a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 54.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.58832\n","Validation MAE: 2.23652\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.37303\n","Validation MAE: 1.96590\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.23817\n","Validation MAE: 2.00218\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.10226\n","Validation MAE: 1.77761\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.05996\n","Validation MAE: 1.76992\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.01351\n","Validation MAE: 1.62056\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.90358\n","Validation MAE: 1.73315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.90072\n","Validation MAE: 1.56338\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.92971\n","Validation MAE: 1.60514\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.76356\n","Validation MAE: 1.58469\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 53.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.67738\n","Validation MAE: 2.37662\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:36<00:00, 52.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.67745\n","Validation MAE: 1.43579\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:35<00:00, 52.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.60871\n","Validation MAE: 1.39462\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.60697\n","Validation MAE: 1.47260\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 56.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.50000\n","Validation MAE: 1.48383\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.89802\n","Validation MAE: 2.02080\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.78003\n","Validation MAE: 1.47221\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.51643\n","Validation MAE: 1.46965\n","Early stopping triggered.\n","Test MAE: 1.55539\n"]}]},{"cell_type":"code","source":["test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ziKiX3KG2EZ","executionInfo":{"status":"ok","timestamp":1728591920838,"user_tz":360,"elapsed":5254,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"c9634cf5-129b-4494-cd29-9d40b8efa83c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.02019\n"]}]},{"cell_type":"markdown","source":["# Proposed new architecture"],"metadata":{"id":"7_hmCjEaWeP-"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9g8au03XcOk","executionInfo":{"status":"ok","timestamp":1728664063319,"user_tz":360,"elapsed":90424,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a6cae0d2-951e-4c60-ee92-1eca8e812356"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.42it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 2.31027\n","Validation MAE: 2.75206\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:29<00:00, 63.90it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 2.15914\n","Validation MAE: 2.62723\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:29<00:00, 63.57it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 2.09892\n","Validation MAE: 2.53519\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 63.03it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 1.97871\n","Validation MAE: 2.47611\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 1.92471\n","Validation MAE: 2.70069\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.51it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 1.93344\n","Validation MAE: 2.42635\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.41it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 1.85625\n","Validation MAE: 2.37505\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.31it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 1.83917\n","Validation MAE: 2.38450\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.14it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 1.81451\n","Validation MAE: 2.41327\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.48it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 1.78228\n","Validation MAE: 2.31284\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 61.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 1.74990\n","Validation MAE: 2.33394\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average MAE: 1.69920\n","Validation MAE: 2.22759\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.13it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average MAE: 1.70625\n","Validation MAE: 2.43220\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.94it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average MAE: 1.75724\n","Validation MAE: 2.34100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average MAE: 1.66868\n","Validation MAE: 2.20905\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.73it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average MAE: 1.60519\n","Validation MAE: 2.08768\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.72it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average MAE: 1.58890\n","Validation MAE: 2.13052\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 62.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.53103\n","Validation MAE: 1.99545\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 1.48431\n","Validation MAE: 2.05491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 1.49731\n","Validation MAE: 1.97387\n","Test MAE: 1.71630\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WS5wUVOWQmsf","executionInfo":{"status":"ok","timestamp":1728597915660,"user_tz":360,"elapsed":825686,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"4d4bb8f4-f175-4c8a-a514-f7a2e092790a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:42<00:00, 44.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.55740\n","Validation MAE: 2.16319\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:41<00:00, 46.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.36328\n","Validation MAE: 1.96958\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 43.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.24844\n","Validation MAE: 1.91169\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.18214\n","Validation MAE: 1.87142\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.08860\n","Validation MAE: 2.04773\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.03734\n","Validation MAE: 1.69043\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:43<00:00, 43.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 1.95420\n","Validation MAE: 1.77980\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 1.86566\n","Validation MAE: 1.54388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.73050\n","Validation MAE: 1.62706\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 43.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.63665\n","Validation MAE: 1.43829\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.65011\n","Validation MAE: 1.61382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.63665\n","Validation MAE: 1.37599\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:47<00:00, 40.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.59954\n","Validation MAE: 1.51327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 42.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.56359\n","Validation MAE: 1.43384\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.63790\n","Validation MAE: 1.41333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:44<00:00, 42.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.54214\n","Validation MAE: 1.59386\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 42.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.60376\n","Validation MAE: 1.44538\n","Early stopping triggered.\n","Test MAE: 1.46003\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5epMzpL18prZ","executionInfo":{"status":"ok","timestamp":1728601080283,"user_tz":360,"elapsed":714296,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"d45c3c90-ae26-415d-d202-911b469fb069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:34<00:00, 55.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 2.51830\n","Validation MAE: 2.09994\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 2.36492\n","Validation MAE: 2.06528\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 2.39304\n","Validation MAE: 1.92388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:33<00:00, 57.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 2.25737\n","Validation MAE: 1.83519\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 57.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 2.19016\n","Validation MAE: 1.79237\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 2.11083\n","Validation MAE: 1.88865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 2.26638\n","Validation MAE: 2.04351\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 2.12054\n","Validation MAE: 1.74315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 1.98500\n","Validation MAE: 1.86008\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 1.89674\n","Validation MAE: 1.60660\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 58.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 1.82288\n","Validation MAE: 1.61284\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 1.70637\n","Validation MAE: 1.54779\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:30<00:00, 61.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 1.65584\n","Validation MAE: 1.43947\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 1.57366\n","Validation MAE: 1.30272\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 1.53315\n","Validation MAE: 1.28766\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 1.63625\n","Validation MAE: 1.23703\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:32<00:00, 59.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 1.40852\n","Validation MAE: 1.29505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 1.41947\n","Validation MAE: 1.38161\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 59.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 1.49975\n","Validation MAE: 1.25863\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:31<00:00, 60.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 1.61780\n","Validation MAE: 1.39766\n","Test MAE: 1.58970\n"]}]},{"cell_type":"code","source":["avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrlWKW1RDNod","executionInfo":{"status":"ok","timestamp":1728590963886,"user_tz":360,"elapsed":145,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"96df6936-4b48-4203-be03-d09412196db8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.02103\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":964},"id":"H8wLuczmtvRh","outputId":"8d9c3edd-cf1b-482f-fb04-e8d783f3a4a6","executionInfo":{"status":"error","timestamp":1728589033737,"user_tz":360,"elapsed":402609,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:37<00:00, 50.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 000, Average loss: 0.00551, Accuracy: 0.99947\n","Validation Loss: 0.00003, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:38<00:00, 49.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 48.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 47.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00004, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:39<00:00, 48.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:41<00:00, 45.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00001, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:45<00:00, 41.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00006, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1900/1900 [00:48<00:00, 38.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average loss: 0.00002, Accuracy: 1.00000\n","Validation Loss: 0.00002, Validation Accuracy: 1.00000\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▊  | 1494/1900 [00:37<00:10, 40.11it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d49818df1892>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aggregate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Average loss and accuracy for the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","# model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovvpFxpi73_f","executionInfo":{"status":"ok","timestamp":1728589057239,"user_tz":360,"elapsed":4587,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"dd7827c5-2c14-4b73-b66a-afd8afba2eba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.83902, Test Accuracy: 1.00000\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EplJFvln5KM1","executionInfo":{"status":"ok","timestamp":1728525257282,"user_tz":360,"elapsed":965549,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7499319d-2c5f-4855-b943-1a72cf500583"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:26<00:00, 69.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85077, Accuracy: 0.61379\n","Validation Loss: 0.68999, Validation Accuracy: 0.70090\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.67507, Accuracy: 0.71147\n","Validation Loss: 0.74277, Validation Accuracy: 0.68186\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.62121, Accuracy: 0.73201\n","Validation Loss: 0.58771, Validation Accuracy: 0.75351\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.63it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.59840, Accuracy: 0.74487\n","Validation Loss: 0.57700, Validation Accuracy: 0.75802\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.57462, Accuracy: 0.75689\n","Validation Loss: 0.59203, Validation Accuracy: 0.75451\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.33it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.57065, Accuracy: 0.75739\n","Validation Loss: 0.55757, Validation Accuracy: 0.76353\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.34it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.56141, Accuracy: 0.76724\n","Validation Loss: 0.60380, Validation Accuracy: 0.72745\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.60it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.55616, Accuracy: 0.76691\n","Validation Loss: 0.56383, Validation Accuracy: 0.75752\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.37it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.54910, Accuracy: 0.76674\n","Validation Loss: 0.57712, Validation Accuracy: 0.76052\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average loss: 0.53870, Accuracy: 0.77609\n","Validation Loss: 0.59208, Validation Accuracy: 0.73297\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average loss: 0.54117, Accuracy: 0.77208\n","Validation Loss: 0.56655, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average loss: 0.53967, Accuracy: 0.77409\n","Validation Loss: 0.54259, Validation Accuracy: 0.77705\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average loss: 0.53608, Accuracy: 0.76707\n","Validation Loss: 0.54477, Validation Accuracy: 0.76954\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average loss: 0.52757, Accuracy: 0.77425\n","Validation Loss: 0.54618, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average loss: 0.52578, Accuracy: 0.77826\n","Validation Loss: 0.55329, Validation Accuracy: 0.77505\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:25<00:00, 69.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average loss: 0.51995, Accuracy: 0.78477\n","Validation Loss: 0.56865, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average loss: 0.51970, Accuracy: 0.78193\n","Validation Loss: 0.55099, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.51853, Accuracy: 0.78694\n","Validation Loss: 0.57027, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:24<00:00, 71.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.51247, Accuracy: 0.78060\n","Validation Loss: 0.55355, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.51177, Accuracy: 0.78527\n","Validation Loss: 0.53661, Validation Accuracy: 0.77906\n","Model improved! Saving model...\n","Test Loss: 0.50733, Test Accuracy: 0.80120\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OojvRWwIDjZS","executionInfo":{"status":"ok","timestamp":1728575768727,"user_tz":360,"elapsed":151636,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"5140a4ef-d98e-4ab1-a0a9-65955e3e38e5"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:11<00:00, 84.16it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85436, Accuracy: 0.60778\n","Validation Loss: 0.74178, Validation Accuracy: 0.65681\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.11it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64916, Accuracy: 0.71548\n","Validation Loss: 0.73019, Validation Accuracy: 0.67134\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60810, Accuracy: 0.73668\n","Validation Loss: 0.64961, Validation Accuracy: 0.72094\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.82it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.58794, Accuracy: 0.74720\n","Validation Loss: 0.63767, Validation Accuracy: 0.72846\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56584, Accuracy: 0.76340\n","Validation Loss: 0.65949, Validation Accuracy: 0.70942\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:05<00:00, 90.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55449, Accuracy: 0.76056\n","Validation Loss: 0.60995, Validation Accuracy: 0.73747\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.55171, Accuracy: 0.76089\n","Validation Loss: 0.61828, Validation Accuracy: 0.74198\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.02it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53734, Accuracy: 0.77225\n","Validation Loss: 0.61481, Validation Accuracy: 0.73597\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52516, Accuracy: 0.77926\n","Validation Loss: 0.57212, Validation Accuracy: 0.76303\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51602, Accuracy: 0.78143\n","Validation Loss: 0.59689, Validation Accuracy: 0.75301\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.17it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.51498, Accuracy: 0.78160\n","Validation Loss: 0.59276, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.89it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.52642, Accuracy: 0.77793\n","Validation Loss: 0.60376, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.92it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.51168, Accuracy: 0.78728\n","Validation Loss: 0.56862, Validation Accuracy: 0.76453\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.50189, Accuracy: 0.78310\n","Validation Loss: 0.61160, Validation Accuracy: 0.75200\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49787, Accuracy: 0.79496\n","Validation Loss: 0.60499, Validation Accuracy: 0.76653\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.49510, Accuracy: 0.79245\n","Validation Loss: 0.57490, Validation Accuracy: 0.76854\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.95it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.49007, Accuracy: 0.79279\n","Validation Loss: 0.57761, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.39it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.48619, Accuracy: 0.79563\n","Validation Loss: 0.56819, Validation Accuracy: 0.77204\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48783, Accuracy: 0.79663\n","Validation Loss: 0.57474, Validation Accuracy: 0.75100\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47551, Accuracy: 0.79846\n","Validation Loss: 0.59259, Validation Accuracy: 0.76102\n","No improvement.\n","Test Loss: 0.53733, Test Accuracy: 0.78117\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTtJcZP_E_fI","executionInfo":{"status":"ok","timestamp":1728580146768,"user_tz":360,"elapsed":249167,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"af119501-b53e-41d2-aaff-6ec2727aabb8"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 74.93it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.82706, Accuracy: 0.62765\n","Validation Loss: 0.77245, Validation Accuracy: 0.66283\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 77.79it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64119, Accuracy: 0.72366\n","Validation Loss: 0.64681, Validation Accuracy: 0.72545\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.60it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60780, Accuracy: 0.74086\n","Validation Loss: 0.59995, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.68it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.57781, Accuracy: 0.75405\n","Validation Loss: 0.65299, Validation Accuracy: 0.71894\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56418, Accuracy: 0.75906\n","Validation Loss: 0.61743, Validation Accuracy: 0.72695\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.76it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55040, Accuracy: 0.76824\n","Validation Loss: 0.58008, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.69it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.53890, Accuracy: 0.77642\n","Validation Loss: 0.57799, Validation Accuracy: 0.75651\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:15<00:00, 78.94it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53069, Accuracy: 0.78210\n","Validation Loss: 0.57792, Validation Accuracy: 0.76754\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.56it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52230, Accuracy: 0.78761\n","Validation Loss: 0.55527, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.62it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51634, Accuracy: 0.78210\n","Validation Loss: 0.59114, Validation Accuracy: 0.75701\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.50713, Accuracy: 0.78327\n","Validation Loss: 0.58000, Validation Accuracy: 0.75802\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.26it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.50051, Accuracy: 0.79162\n","Validation Loss: 0.57951, Validation Accuracy: 0.76503\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.71it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.49515, Accuracy: 0.79279\n","Validation Loss: 0.57201, Validation Accuracy: 0.77154\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.49333, Accuracy: 0.79262\n","Validation Loss: 0.55736, Validation Accuracy: 0.77455\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.75it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49008, Accuracy: 0.79663\n","Validation Loss: 0.56211, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.48785, Accuracy: 0.79679\n","Validation Loss: 0.55073, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.13it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.48828, Accuracy: 0.79279\n","Validation Loss: 0.56119, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average loss: 0.47811, Accuracy: 0.80681\n","Validation Loss: 0.57704, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average loss: 0.48195, Accuracy: 0.79813\n","Validation Loss: 0.54990, Validation Accuracy: 0.77856\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average loss: 0.47356, Accuracy: 0.80314\n","Validation Loss: 0.55569, Validation Accuracy: 0.77655\n","No improvement.\n","Test Loss: 0.53218, Test Accuracy: 0.77967\n"]}]},{"cell_type":"code","source":["out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eIlysDDTCnK","executionInfo":{"status":"ok","timestamp":1728507650969,"user_tz":360,"elapsed":17,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"11b82aad-340a-4c14-a789-f778bd2cfe39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3])"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"hrx8uChapzv-","executionInfo":{"status":"error","timestamp":1728577930581,"user_tz":360,"elapsed":7,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"f14f0288-72e8-4bfb-aee4-caaa38f24113"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-630d30490e8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Testing phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."]}]},{"cell_type":"markdown","source":["# AttentiveFP with Edge Features Training and with explicit H"],"metadata":{"id":"BgJHKrsJBbod"}},{"cell_type":"code","source":["# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index,  data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')  # Optionally save the model here\n","        # torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n"],"metadata":{"id":"FR1hgaxO3nss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    data = t.to(device)\n","    out =  model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))\n","    if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"iW8qj2L1hly3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hgYz5-AQKRzu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N2Sr6W94KR2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ENl3Qi2bKR5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bgncwAnKKR77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"Cn6GHEwApotV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OruDaljhkJo1"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"BdRts-d6xvqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"],"metadata":{"id":"XYPTqNQ3Jjfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"bT1TBhmLm-Xz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSMB8bn8EgzS"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"y26rL55OFsiv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"],"metadata":{"id":"o_KfMVv7LfH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTq0pyD8kLPD"},"outputs":[],"source":["#test SMILES string\n","def evaluate_smiles(smiles_string):\n","    classes = ['insoluble', 'slightly soluble', 'soluble']\n","    G = read_smiles(smiles_string, explicit_hydrogen=True) #decode smiles string\n","    feature = element_to_onehot(np.asarray(G.nodes(data='element'))[:, 1]) #convert element to one-hot vector\n","    edges = np.asarray(G.edges) #get edge array\n","    index = np.asarray([edges[:,0], edges[:,1]]) #reformat edge array to torch geometric suitable format\n","    d = Data(x=torch.tensor(feature, dtype=torch.float),edge_index=torch.tensor(index, dtype=torch.long)) #create torch gemoetry Data object\n","    data = d.to(device) #send data to device memory\n","    model.eval() #set model to evaluate mode\n","    print(classes[torch.argmax(torch.softmax(model(data), dim=0)).item()]) #evaluate the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jA3XzaqSEgzU"},"outputs":[],"source":["evaluate_smiles('C(C(C1C(=C(C(=O)O1)O)O)O)O') #test out the model on Vitamin C"]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"sFJravvfFXnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"y97qNDsUFZSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n"],"metadata":{"id":"pVreebmsFa25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n"],"metadata":{"id":"cFVXAU2mFa-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"o1P2nnTsFbG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n"],"metadata":{"id":"eOURHC-aFbWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"l5vTfaraFbc3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1lT8uWY1EvTqd5AwQd6ttCDIuKySWtWXJ","timestamp":1729265203321},{"file_id":"1HA6r0-vwQaMEzZv67ynoo2rRZjpJ82kI","timestamp":1728587242065}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}