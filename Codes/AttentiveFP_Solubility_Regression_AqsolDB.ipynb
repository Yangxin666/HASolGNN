{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14460,"status":"ok","timestamp":1729264308197,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"ywbw1oASEjEd","outputId":"57e28c2f-0785-428e-f1d7-1d6ea426b164"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n","Requirement already satisfied: pysmiles in /usr/local/lib/python3.10/dist-packages (1.1.2)\n","Requirement already satisfied: pbr in /usr/local/lib/python3.10/dist-packages (from pysmiles) (6.1.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pysmiles) (3.4)\n","Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch\n","!pip install torch-geometric\n","!pip install pysmiles\n","!pip install rdkit\n","!pip install transformers torch\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69644,"status":"ok","timestamp":1729264764306,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"ZevvLDjT7rMD","outputId":"e137c11a-f497-4007-8483-d027000d4246"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from pysmiles import read_smiles\n","import pandas as pd\n","import logging\n","from tqdm import tqdm\n","import torch\n","from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n","import torch.nn.functional as F\n","from torch_geometric.nn import MessagePassing, GCNConv\n","from torch_geometric.utils import remove_self_loops, add_self_loops, degree\n","from torch_geometric.data import Data\n","from google.colab import drive\n","from typing import Optional\n","drive.mount('/content/gdrive')\n","\n","logging.getLogger('pysmiles').setLevel(logging.CRITICAL)"]},{"cell_type":"markdown","source":["# Clean Datasets"],"metadata":{"id":"BoPPCpikjnIl"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"executionInfo":{"elapsed":508,"status":"ok","timestamp":1729264860017,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"KjC8aYzrsHRy","outputId":"52d504a8-1723-4762-cc04-fed4a60d34c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID                                               Name  \\\n","0      A-4                           Benzo[cd]indol-2(1H)-one   \n","1      A-5                               4-chlorobenzaldehyde   \n","2      A-9  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n","3     A-10                                       vinyltoluene   \n","4     A-11               3-(3-ethylcyclopentyl)propanoic acid   \n","...    ...                                                ...   \n","8879  I-84                                         tetracaine   \n","8880  I-85                                       tetracycline   \n","8881  I-86                                             thymol   \n","8882  I-93                                          verapamil   \n","8883  I-94                                           warfarin   \n","\n","                                                  InChI  \\\n","0     InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...   \n","1           InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H   \n","2     InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...   \n","3     InChI=1S/C9H10/c1-3-9-6-4-5-8(2)7-9/h3-7H,1H2,2H3   \n","4     InChI=1S/C10H18O2/c1-2-8-3-4-9(7-8)5-6-10(11)1...   \n","...                                                 ...   \n","8879  InChI=1S/C15H24N2O2/c1-4-5-10-16-14-8-6-13(7-9...   \n","8880  InChI=1S/C22H24N2O8/c1-21(31)8-5-4-6-11(25)12(...   \n","8881  InChI=1S/C10H14O/c1-7(2)9-5-4-8(3)6-10(9)11/h4...   \n","8882  InChI=1S/C27H38N2O4/c1-20(2)27(19-28,22-10-12-...   \n","8883  InChI=1S/C19H16O4/c1-12(20)11-15(13-7-3-2-4-8-...   \n","\n","                         InChIKey  \\\n","0     GPYLCFQEKPUWLD-UHFFFAOYSA-N   \n","1     AVPYQKSLYISFPO-UHFFFAOYSA-N   \n","2     FAUAZXVRLVIARB-UHFFFAOYSA-N   \n","3     JZHGRUMIRATHIU-UHFFFAOYSA-N   \n","4     WVRFSLWCFASCIS-UHFFFAOYSA-N   \n","...                           ...   \n","8879  GKCBAIGFKIBETG-UHFFFAOYSA-N   \n","8880  OFVLGDICTFRJMM-WESIUVDSSA-N   \n","8881  MGSRCZKZVOBKFT-UHFFFAOYSA-N   \n","8882  SGTNSNPWRIOYBX-UHFFFAOYSA-N   \n","8883  PJVWKTKQMONHTI-UHFFFAOYSA-N   \n","\n","                                                 SMILES  Solubility        SD  \\\n","0                                  O=C1Nc2cccc3cccc1c23   -3.254767  0.000000   \n","1                                       Clc1ccc(C=O)cc1   -2.177078  0.000000   \n","2     C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065  0.000000   \n","3                                        Cc1cccc(C=C)c1   -3.123150  0.000000   \n","4                                   CCC1CCC(CCC(O)=O)C1   -3.286116  0.000000   \n","...                                                 ...         ...       ...   \n","8879                     C(c1ccc(cc1)NCCCC)(=O)OCCN(C)C   -3.010000  0.000000   \n","8880  OC1=C(C(C2=C(O)[C@@](C(C(C(N)=O)=C(O)[C@H]3N(C...   -2.930000  0.000000   \n","8881                                c1(cc(ccc1C(C)C)C)O   -2.190000  0.019222   \n","8882  COc1ccc(CCN(C)CCCC(C#N)(C(C)C)c2ccc(OC)c(OC)c2...   -3.980000  0.000000   \n","8883              CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O   -4.780000  0.450506   \n","\n","      Ocurrences Group    MolWt  ...  NumRotatableBonds  NumValenceElectrons  \\\n","0              1    G1  169.183  ...                0.0                 62.0   \n","1              1    G1  140.569  ...                1.0                 46.0   \n","2              1    G1  422.525  ...               12.0                164.0   \n","3              1    G1  118.179  ...                1.0                 46.0   \n","4              1    G1  170.252  ...                4.0                 70.0   \n","...          ...   ...      ...  ...                ...                  ...   \n","8879           1    G1  264.369  ...                8.0                106.0   \n","8880           1    G1  444.440  ...                2.0                170.0   \n","8881           3    G5  150.221  ...                1.0                 60.0   \n","8882           1    G1  454.611  ...               13.0                180.0   \n","8883           3    G5  308.333  ...                4.0                116.0   \n","\n","      NumAromaticRings  NumSaturatedRings  NumAliphaticRings  RingCount  \\\n","0                  2.0                0.0                1.0        3.0   \n","1                  1.0                0.0                0.0        1.0   \n","2                  2.0                4.0                4.0        6.0   \n","3                  1.0                0.0                0.0        1.0   \n","4                  0.0                1.0                1.0        1.0   \n","...                ...                ...                ...        ...   \n","8879               1.0                0.0                0.0        1.0   \n","8880               1.0                0.0                3.0        4.0   \n","8881               1.0                0.0                0.0        1.0   \n","8882               2.0                0.0                0.0        2.0   \n","8883               3.0                0.0                0.0        3.0   \n","\n","        TPSA   LabuteASA  BalabanJ      BertzCT  \n","0      29.10   75.183563  2.582996   511.229248  \n","1      17.07   58.261134  3.009782   202.661065  \n","2      56.60  183.183268  1.084427   769.899934  \n","3       0.00   55.836626  3.070761   211.033225  \n","4      37.30   73.973655  2.145839   153.917569  \n","...      ...         ...       ...          ...  \n","8879   41.57  115.300645  2.394548   374.236893  \n","8880  181.62  182.429237  2.047922  1148.584975  \n","8881   20.23   67.685405  3.092720   251.049732  \n","8882   63.95  198.569223  2.023333   938.203977  \n","8883   67.51  132.552025  2.258072   909.550973  \n","\n","[8884 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-37b8b543-e2fb-4167-a512-dcb386b3e5db\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Name</th>\n","      <th>InChI</th>\n","      <th>InChIKey</th>\n","      <th>SMILES</th>\n","      <th>Solubility</th>\n","      <th>SD</th>\n","      <th>Ocurrences</th>\n","      <th>Group</th>\n","      <th>MolWt</th>\n","      <th>...</th>\n","      <th>NumRotatableBonds</th>\n","      <th>NumValenceElectrons</th>\n","      <th>NumAromaticRings</th>\n","      <th>NumSaturatedRings</th>\n","      <th>NumAliphaticRings</th>\n","      <th>RingCount</th>\n","      <th>TPSA</th>\n","      <th>LabuteASA</th>\n","      <th>BalabanJ</th>\n","      <th>BertzCT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A-4</td>\n","      <td>Benzo[cd]indol-2(1H)-one</td>\n","      <td>InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...</td>\n","      <td>GPYLCFQEKPUWLD-UHFFFAOYSA-N</td>\n","      <td>O=C1Nc2cccc3cccc1c23</td>\n","      <td>-3.254767</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>169.183</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>62.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>29.10</td>\n","      <td>75.183563</td>\n","      <td>2.582996</td>\n","      <td>511.229248</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A-5</td>\n","      <td>4-chlorobenzaldehyde</td>\n","      <td>InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H</td>\n","      <td>AVPYQKSLYISFPO-UHFFFAOYSA-N</td>\n","      <td>Clc1ccc(C=O)cc1</td>\n","      <td>-2.177078</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>140.569</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>46.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>17.07</td>\n","      <td>58.261134</td>\n","      <td>3.009782</td>\n","      <td>202.661065</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A-9</td>\n","      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n","      <td>InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...</td>\n","      <td>FAUAZXVRLVIARB-UHFFFAOYSA-N</td>\n","      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n","      <td>-4.662065</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>422.525</td>\n","      <td>...</td>\n","      <td>12.0</td>\n","      <td>164.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>56.60</td>\n","      <td>183.183268</td>\n","      <td>1.084427</td>\n","      <td>769.899934</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A-10</td>\n","      <td>vinyltoluene</td>\n","      <td>InChI=1S/C9H10/c1-3-9-6-4-5-8(2)7-9/h3-7H,1H2,2H3</td>\n","      <td>JZHGRUMIRATHIU-UHFFFAOYSA-N</td>\n","      <td>Cc1cccc(C=C)c1</td>\n","      <td>-3.123150</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>118.179</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>46.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>55.836626</td>\n","      <td>3.070761</td>\n","      <td>211.033225</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A-11</td>\n","      <td>3-(3-ethylcyclopentyl)propanoic acid</td>\n","      <td>InChI=1S/C10H18O2/c1-2-8-3-4-9(7-8)5-6-10(11)1...</td>\n","      <td>WVRFSLWCFASCIS-UHFFFAOYSA-N</td>\n","      <td>CCC1CCC(CCC(O)=O)C1</td>\n","      <td>-3.286116</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>170.252</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>70.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>37.30</td>\n","      <td>73.973655</td>\n","      <td>2.145839</td>\n","      <td>153.917569</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8879</th>\n","      <td>I-84</td>\n","      <td>tetracaine</td>\n","      <td>InChI=1S/C15H24N2O2/c1-4-5-10-16-14-8-6-13(7-9...</td>\n","      <td>GKCBAIGFKIBETG-UHFFFAOYSA-N</td>\n","      <td>C(c1ccc(cc1)NCCCC)(=O)OCCN(C)C</td>\n","      <td>-3.010000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>264.369</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>106.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>41.57</td>\n","      <td>115.300645</td>\n","      <td>2.394548</td>\n","      <td>374.236893</td>\n","    </tr>\n","    <tr>\n","      <th>8880</th>\n","      <td>I-85</td>\n","      <td>tetracycline</td>\n","      <td>InChI=1S/C22H24N2O8/c1-21(31)8-5-4-6-11(25)12(...</td>\n","      <td>OFVLGDICTFRJMM-WESIUVDSSA-N</td>\n","      <td>OC1=C(C(C2=C(O)[C@@](C(C(C(N)=O)=C(O)[C@H]3N(C...</td>\n","      <td>-2.930000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>444.440</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>170.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>181.62</td>\n","      <td>182.429237</td>\n","      <td>2.047922</td>\n","      <td>1148.584975</td>\n","    </tr>\n","    <tr>\n","      <th>8881</th>\n","      <td>I-86</td>\n","      <td>thymol</td>\n","      <td>InChI=1S/C10H14O/c1-7(2)9-5-4-8(3)6-10(9)11/h4...</td>\n","      <td>MGSRCZKZVOBKFT-UHFFFAOYSA-N</td>\n","      <td>c1(cc(ccc1C(C)C)C)O</td>\n","      <td>-2.190000</td>\n","      <td>0.019222</td>\n","      <td>3</td>\n","      <td>G5</td>\n","      <td>150.221</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>60.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>20.23</td>\n","      <td>67.685405</td>\n","      <td>3.092720</td>\n","      <td>251.049732</td>\n","    </tr>\n","    <tr>\n","      <th>8882</th>\n","      <td>I-93</td>\n","      <td>verapamil</td>\n","      <td>InChI=1S/C27H38N2O4/c1-20(2)27(19-28,22-10-12-...</td>\n","      <td>SGTNSNPWRIOYBX-UHFFFAOYSA-N</td>\n","      <td>COc1ccc(CCN(C)CCCC(C#N)(C(C)C)c2ccc(OC)c(OC)c2...</td>\n","      <td>-3.980000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>G1</td>\n","      <td>454.611</td>\n","      <td>...</td>\n","      <td>13.0</td>\n","      <td>180.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>63.95</td>\n","      <td>198.569223</td>\n","      <td>2.023333</td>\n","      <td>938.203977</td>\n","    </tr>\n","    <tr>\n","      <th>8883</th>\n","      <td>I-94</td>\n","      <td>warfarin</td>\n","      <td>InChI=1S/C19H16O4/c1-12(20)11-15(13-7-3-2-4-8-...</td>\n","      <td>PJVWKTKQMONHTI-UHFFFAOYSA-N</td>\n","      <td>CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O</td>\n","      <td>-4.780000</td>\n","      <td>0.450506</td>\n","      <td>3</td>\n","      <td>G5</td>\n","      <td>308.333</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>116.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>67.51</td>\n","      <td>132.552025</td>\n","      <td>2.258072</td>\n","      <td>909.550973</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8884 rows × 26 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b8b543-e2fb-4167-a512-dcb386b3e5db')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-37b8b543-e2fb-4167-a512-dcb386b3e5db button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-37b8b543-e2fb-4167-a512-dcb386b3e5db');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ef56bbe0-242c-4500-8eb7-8ec77ca0d2a4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef56bbe0-242c-4500-8eb7-8ec77ca0d2a4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ef56bbe0-242c-4500-8eb7-8ec77ca0d2a4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_84d499e1-bf23-420d-8c6d-4bf06f7dcacb\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_84d499e1-bf23-420d-8c6d-4bf06f7dcacb button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":5}],"source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","df = pd.read_csv('gdrive/My Drive/Base_GNN_Solubility/curated_solubility_dataset.csv') #read dataset (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","df = df[~df['SMILES'].str.contains('.', regex=False)]\n","df.reset_index(drop=True, inplace=True)\n","# df['Solubility'] = np.exp(df['Solubility'])\n","X_smiles = list(df['SMILES']) #get smiles strings from file\n","Y = np.asarray(df['Solubility']) #get solubility values from file\n","df = df.drop_duplicates()\n","df"]},{"cell_type":"markdown","metadata":{"id":"OhZwPD4fDh2F"},"source":["# Dataset\n","1. AqSolDB (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","2. OChem (https://ochem.eu/login/show.do?render-mode=full)\n","3. BigSolDB (https://zenodo.org/records/6984601)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zK8utGmGx0vd"},"source":["# AqSolDB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZYEUILQAqa6"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","df = pd.read_csv('gdrive/My Drive/Base_GNN_Solubility/curated_solubility_dataset.csv') #read dataset (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8)\n","df = df[~df['SMILES'].str.contains('.', regex=False)]\n","df.reset_index(drop=True, inplace=True)\n","# df['Solubility'] = np.exp(df['Solubility'])\n","X_smiles = list(df['SMILES']) #get smiles strings from file\n","Y = np.asarray(df['Solubility']) #get solubility values from file\n","\n","columns_to_normalize = [\n","    \"MolWt\",\n","    \"MolLogP\",\n","    \"MolMR\",\n","    \"HeavyAtomCount\",\n","    \"NumHAcceptors\",\n","    \"NumHDonors\",\n","    \"NumHeteroatoms\",\n","    \"NumRotatableBonds\"]\n","\n","scaler = MinMaxScaler()\n","df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n","\n","\n","def val_to_class(val):\n","    if val < -3.65: #insoluble\n","        return [1, 0, 0]\n","    elif val < -1.69: #slightly soluble\n","        return [0, 1, 0]\n","    else: #soluble\n","        return [0, 0, 1]"]},{"cell_type":"markdown","metadata":{"id":"-hJQ36Jl3QAd"},"source":["# AttentiveFP (with edge features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UX5bVRU-3QIh"},"outputs":[],"source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"markdown","metadata":{"id":"cBBJ1JYJPz2-"},"source":["# Proposed New Architecture"]},{"cell_type":"markdown","source":["# New"],"metadata":{"id":"Ytsx0XKZW974"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool, SAGEConv\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","class SimpleAttention(nn.Module):\n","    def __init__(self, input_dim):\n","        super(SimpleAttention, self).__init__()\n","        self.attention_weights = nn.Parameter(torch.randn(input_dim))\n","\n","    def forward(self, pooled_output):\n","        # Calculate attention scores as a dot product\n","        scores = torch.matmul(pooled_output, self.attention_weights)\n","\n","        # Apply softmax to get attention weights\n","        att_weights = F.softmax(scores, dim=0)\n","\n","        # Weighted output\n","        out_weighted = att_weights * pooled_output\n","        return out_weighted\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = SAGEConv(hidden_channels, hidden_channels, aggr = 'sum')\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = SAGEConv(hidden_channels, hidden_channels, aggr = 'sum')\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","        self.attention = SimpleAttention(hidden_channels)\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        # out = global_add_pool(x, batch).relu_()\n","        # for t in range(self.num_timesteps):\n","        #     h = F.elu_(self.mol_conv((x, out), edge_index))\n","        #     h = F.dropout(h, p=self.dropout, training=self.training)\n","        #     out = self.mol_gru(h, out).relu_()\n","\n","\n","        out = global_add_pool(x, batch).relu()\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu(self.mol_conv((x, out), edge_index))\n","            # h = self.batch_norm(h)  # Batch normalization\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","            # Attention mechanism\n","            out = F.softmax(self.attention(out), dim=0)\n","\n","            # Residual connection\n","            out = self.mol_gru(h, out).relu() + out\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"rgaeIS9T6yGw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GPSConv"],"metadata":{"id":"yzlA1jFE0uA_"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, GPSConv, MessagePassing, global_add_pool, global_mean_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GPSConv(hidden_channels, GATConv)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            # conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"uuQmf-MH0uMd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SuperGAT"],"metadata":{"id":"MxNVtMzIM6M-"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool, SuperGATConv\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = SuperGATConv(hidden_channels, hidden_channels)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"Yzy8m7d_M-j5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ASAPooling"],"metadata":{"id":"ZOh7Wcgbmhtn"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, SAGPooling, ASAPooling\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.pool1 = ASAPooling(hidden_channels, ratio=0.5)\n","        self.pool2 = ASAPooling(hidden_channels, ratio=0.5)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # multiple pooling layers from N -> 1\n","        pool_output1 = self.pool1(x, edge_index, batch=batch)\n","        x1 = pool_output1[0]  # Pooled node features\n","        edge_index1 = pool_output1[1]  # New edge index\n","        batch1 = pool_output1[3]  # New batch indices\n","\n","        # If you have a second pooling layer\n","        pool_output2 = self.pool2(x1, edge_index1, batch=batch1)  # Pass edge_attr as None if not used\n","        x2 = pool_output2[0]  # Pooled node features\n","        edge_index2 = pool_output2[1]  # New edge index\n","        batch2 = pool_output2[3]  # New batch indices\n","\n","        # Apply global addition pooling to create graph-level representation\n","        graph_embedding = global_add_pool(x2, batch2)\n","\n","        return self.lin2(graph_embedding)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"7E_m4dZdmh2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool, global_max_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","        self.weights = torch.nn.Parameter(torch.tensor([1.0, 1.0, 1.0], dtype=torch.float32))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        # out = global_add_pool(x, batch).relu_()\n","\n","        add_pool = global_add_pool(x, batch)\n","        mean_pool = global_mean_pool(x, batch)\n","        max_pool = global_max_pool(x, batch)\n","\n","        out = (self.weights[0] * add_pool +\n","                         self.weights[1] * mean_pool +\n","                         self.weights[2] * max_pool).relu()\n","\n","\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"sHh6W0rOC7J0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Simplified (only one graph pooling)"],"metadata":{"id":"AGZ3_cIFxPyb"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_avg_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        # for t in range(self.num_timesteps):\n","        #     h = F.elu_(self.mol_conv((x, out), edge_index))\n","        #     h = F.dropout(h, p=self.dropout, training=self.training)\n","        #     out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"drqidJmFxPPJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multiple poolings"],"metadata":{"id":"UaVqivKD44X9"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, SAGPooling\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.pool1 = SAGPooling(hidden_channels, ratio=0.5, GNN = GATConv)\n","        self.pool2 = SAGPooling(hidden_channels, ratio=0.5, GNN = GATConv)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # multiple pooling layers from N -> 1\n","        pool_output1 = self.pool1(x, edge_index, edge_attr=edge_attr, batch=batch)\n","        x1 = pool_output1[0]  # Pooled node features\n","        edge_index1 = pool_output1[1]  # New edge index\n","        batch1 = pool_output1[3]  # New batch indices\n","\n","        # If you have a second pooling layer\n","        pool_output2 = self.pool2(x1, edge_index1, edge_attr=None, batch=batch1)  # Pass edge_attr as None if not used\n","        x2 = pool_output2[0]  # Pooled node features\n","        edge_index2 = pool_output2[1]  # New edge index\n","        batch2 = pool_output2[3]  # New batch indices\n","\n","        # Apply global addition pooling to create graph-level representation\n","        graph_embedding = global_add_pool(x2, batch2)\n","\n","        return self.lin2(graph_embedding)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"xdljcZ-P44iW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# replace GATConv by GATv2Conv"],"metadata":{"id":"BjV3yJqJV0SN"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATv2Conv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATv2Conv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"EjEZTp5yV0Zu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cyYshRy77-zd"},"source":["# Attentive FP (with edge features) + graph level features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHmSDWnj7-8C"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"markdown","source":["# Add supernode to original graph"],"metadata":{"id":"7ZV-N2N8Xxxn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u688ttj76GAN"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, TransformerConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","\n","        self.mol_conv = TransformerConv(hidden_channels, hidden_channels)\n","\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        new_edge_index = edge_index.detach().clone()\n","        new_edge_index += 1\n","        new_edges = torch.tensor([[0] * x.shape[0],\n","                          list(range(1, x.shape[0] + 1))],\n","                          dtype=torch.long)\n","\n","        # Concatenate original edge_index with new_edges\n","        new_edge_index = torch.cat([new_edge_index, new_edges], dim=1)\n","        supernode = global_add_pool(x, batch).relu_()\n","        x = torch.cat([x, supernode], dim=0)\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, new_edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # # Molecule Embedding:\n","        # row = torch.arange(batch.size(0), device=batch.device)\n","        # edge_index = torch.stack([row, batch], dim=0)\n","\n","        # out = global_add_pool(x, batch).relu_()\n","        # for t in range(self.num_timesteps):\n","        #     h = F.elu_(self.mol_conv((x, out), edge_index))\n","        #     h = F.dropout(h, p=self.dropout, training=self.training)\n","        #     out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(x[0].unsqueeze(0), p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"markdown","source":["# Replace GATConv by TransformerConv"],"metadata":{"id":"46BB0NkwXo5x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMKZcJW9zvmC"},"outputs":[],"source":["from typing import Optional\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, TransformerConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = TransformerConv(hidden_channels, hidden_channels)\n","\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"markdown","metadata":{"id":"ZfLdGIdcaWh7"},"source":["# Improved one: Replace GRU by LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RO0Ib3APaWq0"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import LSTMCell, Linear, Parameter\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_lstm = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_lstm.append(LSTMCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False\n","        self.mol_lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.lstm.reset_parameters()\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            conv.reset_parameters()\n","            lstm.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_lstm.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","\n","    # def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","    #             batch: Tensor) -> Tensor:\n","    #     \"\"\"\"\"\"  # noqa: D419\n","    #     # Atom Embedding:\n","    #     x = F.leaky_relu_(self.lin1(x))\n","\n","    #     h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","    #     h = F.dropout(h, p=self.dropout, training=self.training)\n","    #     x = self.gru(h, x).relu_()\n","\n","    #     for conv, gru in zip(self.atom_convs, self.atom_grus):\n","    #         h = conv(x, edge_index)\n","    #         h = F.elu(h)\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         x = gru(h, x).relu()\n","\n","    #     # Molecule Embedding:\n","    #     row = torch.arange(batch.size(0), device=batch.device)\n","    #     edge_index = torch.stack([row, batch], dim=0)\n","\n","    #     out = global_add_pool(x, batch).relu_()\n","    #     for t in range(self.num_timesteps):\n","    #         h = F.elu_(self.mol_conv((x, out), edge_index))\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         out = self.mol_gru(h, out).relu_()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Initialize hidden and cell states for the LSTM\n","        # hx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        # cx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        cx = x\n","\n","        # # Using LSTMCell\n","        # hx, cx = self.lstm(h, (hx, cx))  # Update x with LSTM\n","\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x, cx = lstm(h, (x, cx))  # Update x with LSTM\n","            x = x.relu()\n","\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        cx = out\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out, cx = self.mol_lstm(h, (out, cx))  # Update out with LSTM\n","            out = out.relu()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"]},{"cell_type":"markdown","source":["# Improved Two: Add graph level features and attention of graph level embeddings + features"],"metadata":{"id":"-7oVXwfoDc55"}},{"cell_type":"code","source":["class AttentionLayer(torch.nn.Module):\n","    def __init__(self, in_channels: int):\n","        super().__init__()\n","        self.lin = Linear(in_channels, in_channels)\n","        self.att = Parameter(torch.empty(1, in_channels))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.lin.weight)\n","        zeros(self.att)\n","\n","    def forward(self, features: Tensor) -> Tensor:\n","        scores = (self.lin(features) * self.att).sum(dim=-1)  # Compute attention scores\n","        # alpha = F.softmax(scores, dim=0)  # Compute softmax for attention weights\n","        alpha = F.softmax(scores, dim=0)\n","        return (features * alpha.unsqueeze(-1)).sum(dim=0)  # Weighted sum of features\n","\n","from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","        self.attention_layer = AttentionLayer(hidden_channels + 8)\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = self.attention_layer(out)\n","        # print(out.shape)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"],"metadata":{"id":"pcZ0EF0tDdCd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w1THFGjIo6kN"},"source":["# First try of Transformer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIrvOIJ6o6ur"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import Linear, Parameter, TransformerEncoder, TransformerEncoderLayer\n","\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_update(x, edge_index, edge_attr)  # Corrected line\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_i: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_i, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        x_i = F.leaky_relu_(self.lin1(x_i))  # This line ensures x_i is processed\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","\n","        # Transformer Encoder Layer\n","        self.transformer_encoder_layer = TransformerEncoderLayer(\n","            d_model=hidden_channels,\n","            nhead=8,  # Adjust the number of attention heads as needed\n","            dropout=dropout\n","        )\n","        self.transformer_encoder = TransformerEncoder(self.transformer_encoder_layer, num_layers=num_layers - 1)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        for conv in self.atom_convs:\n","            conv.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Reshape for transformer: (seq_len, batch_size, features)\n","        h = h.unsqueeze(0)  # Add sequence dimension\n","        h = self.transformer_encoder(h)  # Pass through transformer layers\n","        h = h.squeeze(0)  # Remove sequence dimension\n","\n","        # Atom-level GAT layers\n","        for conv in self.atom_convs:\n","            h = F.elu_(conv(h, edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Molecule Embedding:\n","        out = global_add_pool(h, batch).relu_()\n","\n","        # Molecule-level GAT layer\n","        out = F.elu_(self.mol_conv(out, edge_index))\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"]},{"cell_type":"markdown","source":["# Improved GRU"],"metadata":{"id":"gfwyyy4HWujx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruGBrLAiP0Ao"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","# class EnhancedGRUCell(nn.Module):\n","#     def __init__(self, input_size, hidden_size):\n","#         super(EnhancedGRUCell, self).__init__()\n","#         self.gru = nn.GRUCell(input_size, hidden_size)\n","#         self.layer_norm = nn.LayerNorm(hidden_size)\n","\n","#     def reset_parameters(self):\n","#         self.gru.reset_parameters()  # Reset parameters of the underlying GRU\n","\n","#     def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","#         hidden = self.gru(input, hidden)\n","#         return self.layer_norm(hidden)\n","\n","\n","class EnhancedGRUCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EnhancedGRUCell, self).__init__()\n","        self.gru = nn.GRUCell(input_size, hidden_size)\n","        self.layer_norm = nn.LayerNorm(hidden_size)\n","        # self.dropout = nn.Dropout(dropout_rate)\n","\n","    def reset_parameters(self):\n","        self.gru.reset_parameters()\n","\n","    def forward(self, input: Tensor, hidden: Tensor) -> Tensor:\n","        new_hidden = self.gru(input, hidden)\n","        new_hidden = self.layer_norm(new_hidden + hidden)  # Residual connection\n","        return new_hidden\n","\n","\n","\n","class AttentiveFP(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = nn.Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.atom_convs = nn.ModuleList()\n","        self.atom_grus = nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(EnhancedGRUCell(hidden_channels, hidden_channels))  # Use enhanced GRU\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)\n","        self.mol_gru = EnhancedGRUCell(hidden_channels, hidden_channels)  # Use enhanced GRU\n","\n","        self.lin2 = nn.Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) -> Tensor:\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x)  # Use enhanced GRU\n","        x = F.relu(x)\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x)  # Use enhanced GRU\n","            x = F.relu(x)\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out)  # Use enhanced GRU\n","            out = F.relu(out)\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n"]},{"cell_type":"markdown","metadata":{"id":"UVe6r3kY9Cw0"},"source":["# Replace GATConv by GINConv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFPXVE1KcM_J"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GINConv, TransformerConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = TransformerConv(32, 8, heads=4)\n","\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","\n","        self.mol_conv = TransformerConv(32, 8, heads=4)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSOA7hHEa5fY"},"outputs":[],"source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATv2Conv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels+8, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, graph_level_features,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')"]},{"cell_type":"markdown","metadata":{"id":"OxOL5EldvTzQ"},"source":["# Featurization for AttentiveFP\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18373,"status":"ok","timestamp":1728966183154,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"iSQmT9Tjtz9a","outputId":"59630d4a-5c22-4439-e6e6-c5359a617166"},"outputs":[{"output_type":"stream","name":"stderr","text":["  3%|▎         | 289/9982 [00:00<00:18, 530.40it/s][04:22:45] WARNING: not removing hydrogen atom without neighbors\n","  4%|▍         | 412/9982 [00:00<00:16, 572.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Unrecognized element: Re\n"]},{"output_type":"stream","name":"stderr","text":["[04:22:45] WARNING: not removing hydrogen atom without neighbors\n","[04:22:45] WARNING: not removing hydrogen atom without neighbors\n","  6%|▌         | 595/9982 [00:01<00:15, 598.93it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","  7%|▋         | 655/9982 [00:01<00:15, 599.02it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","  8%|▊         | 779/9982 [00:01<00:15, 605.21it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","  8%|▊         | 840/9982 [00:01<00:16, 570.30it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","  9%|▉         | 898/9982 [00:01<00:16, 561.59it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","[04:22:46] WARNING: not removing hydrogen atom without neighbors\n"," 10%|▉         | 956/9982 [00:01<00:15, 566.69it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n","[04:22:46] WARNING: not removing hydrogen atom without neighbors\n"," 11%|█         | 1076/9982 [00:01<00:15, 581.32it/s][04:22:46] WARNING: not removing hydrogen atom without neighbors\n"," 16%|█▌        | 1572/9982 [00:03<00:23, 353.80it/s][04:22:48] WARNING: not removing hydrogen atom without neighbors\n","[04:22:48] WARNING: not removing hydrogen atom without neighbors\n","[04:22:48] WARNING: not removing hydrogen atom without neighbors\n","[04:22:48] WARNING: not removing hydrogen atom without neighbors\n"," 16%|█▋        | 1643/9982 [00:03<00:27, 300.25it/s][04:22:48] WARNING: not removing hydrogen atom without neighbors\n"," 17%|█▋        | 1674/9982 [00:03<00:27, 300.58it/s][04:22:48] WARNING: not removing hydrogen atom without neighbors\n"," 17%|█▋        | 1705/9982 [00:03<00:28, 290.90it/s][04:22:48] WARNING: not removing hydrogen atom without neighbors\n","[04:22:48] WARNING: not removing hydrogen atom without neighbors\n"," 18%|█▊        | 1754/9982 [00:03<00:24, 341.47it/s][04:22:48] WARNING: not removing hydrogen atom without neighbors\n"," 18%|█▊        | 1795/9982 [00:03<00:22, 358.53it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 19%|█▉        | 1905/9982 [00:04<00:24, 328.73it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 20%|█▉        | 1978/9982 [00:04<00:19, 417.13it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 21%|██        | 2053/9982 [00:04<00:16, 495.07it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 21%|██▏       | 2123/9982 [00:04<00:14, 546.77it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 22%|██▏       | 2198/9982 [00:04<00:13, 591.52it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 23%|██▎       | 2263/9982 [00:04<00:13, 562.75it/s][04:22:49] WARNING: not removing hydrogen atom without neighbors\n","[04:22:49] WARNING: not removing hydrogen atom without neighbors\n"," 24%|██▍       | 2390/9982 [00:05<00:12, 585.68it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n","[04:22:50] WARNING: not removing hydrogen atom without neighbors\n","[04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 25%|██▍       | 2454/9982 [00:05<00:12, 597.60it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 25%|██▌       | 2522/9982 [00:05<00:12, 620.18it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 26%|██▌       | 2586/9982 [00:05<00:12, 604.60it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n","[04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 27%|██▋       | 2648/9982 [00:05<00:12, 566.22it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 27%|██▋       | 2731/9982 [00:05<00:11, 637.11it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n"," 29%|██▉       | 2936/9982 [00:05<00:10, 640.85it/s][04:22:50] WARNING: not removing hydrogen atom without neighbors\n","[04:22:51] WARNING: not removing hydrogen atom without neighbors\n"," 31%|███▏      | 3133/9982 [00:06<00:11, 588.43it/s]"]},{"output_type":"stream","name":"stdout","text":["Unrecognized element: Ta\n"]},{"output_type":"stream","name":"stderr","text":["[04:22:51] WARNING: not removing hydrogen atom without neighbors\n","[04:22:51] WARNING: not removing hydrogen atom without neighbors\n","[04:22:51] WARNING: not removing hydrogen atom without neighbors\n"," 32%|███▏      | 3194/9982 [00:06<00:12, 529.21it/s][04:22:51] WARNING: not removing hydrogen atom without neighbors\n"," 33%|███▎      | 3256/9982 [00:06<00:12, 552.06it/s][04:22:51] WARNING: not removing hydrogen atom without neighbors\n","[04:22:51] WARNING: not removing hydrogen atom without neighbors\n","[04:22:51] WARNING: not removing hydrogen atom without neighbors\n"," 36%|███▌      | 3594/9982 [00:07<00:17, 371.55it/s]"]},{"output_type":"stream","name":"stdout","text":["Unrecognized element: Ir\n"]},{"output_type":"stream","name":"stderr","text":["[04:22:52] WARNING: not removing hydrogen atom without neighbors\n"," 36%|███▋      | 3632/9982 [00:07<00:17, 362.92it/s][04:22:52] WARNING: not removing hydrogen atom without neighbors\n"," 37%|███▋      | 3683/9982 [00:07<00:15, 401.47it/s][04:22:52] WARNING: not removing hydrogen atom without neighbors\n"]},{"output_type":"stream","name":"stdout","text":["Unrecognized element: Be\n","Unrecognized element: Be\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████▏     | 4136/9982 [00:08<00:08, 701.32it/s][04:22:53] WARNING: not removing hydrogen atom without neighbors\n","[04:22:53] WARNING: not removing hydrogen atom without neighbors\n","[04:22:53] WARNING: not removing hydrogen atom without neighbors\n"," 44%|████▎     | 4353/9982 [00:08<00:08, 680.30it/s][04:22:53] WARNING: not removing hydrogen atom without neighbors\n"," 49%|████▉     | 4926/9982 [00:09<00:06, 737.63it/s][04:22:54] WARNING: not removing hydrogen atom without neighbors\n"," 54%|█████▍    | 5433/9982 [00:10<00:06, 685.56it/s][04:22:55] WARNING: not removing hydrogen atom without neighbors\n"," 57%|█████▋    | 5724/9982 [00:10<00:06, 697.52it/s][04:22:55] WARNING: not removing hydrogen atom without neighbors\n"," 62%|██████▏   | 6194/9982 [00:11<00:06, 630.04it/s][04:22:56] WARNING: not removing hydrogen atom without neighbors\n","[04:22:56] WARNING: not removing hydrogen atom without neighbors\n","100%|██████████| 9982/9982 [00:17<00:00, 566.41it/s]\n"]}],"source":["import os.path as osp\n","from math import sqrt\n","import torch\n","import torch.nn.functional as F\n","from rdkit import Chem\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn.models import AttentiveFP\n","\n","class GenFeatures:\n","    def __init__(self):\n","        # self.symbols = [\n","        #     'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","        #     'Te', 'I', 'At', 'other'\n","        # ]\n","\n","        self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","            'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","            'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al',\n","            'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","            'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","            'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","        self.hybridizations = [\n","            Chem.rdchem.HybridizationType.S,\n","            Chem.rdchem.HybridizationType.SP,\n","            Chem.rdchem.HybridizationType.SP2,\n","            Chem.rdchem.HybridizationType.SP3,\n","            Chem.rdchem.HybridizationType.SP3D,\n","            Chem.rdchem.HybridizationType.SP3D2,\n","            Chem.rdchem.HybridizationType.UNSPECIFIED,\n","            'other',\n","        ]\n","\n","\n","\n","        self.stereos = [\n","            Chem.rdchem.BondStereo.STEREONONE,\n","            Chem.rdchem.BondStereo.STEREOANY,\n","            Chem.rdchem.BondStereo.STEREOZ,\n","            Chem.rdchem.BondStereo.STEREOE,\n","        ]\n","\n","    def __call__(self, smiles, i):\n","        # Generate AttentiveFP features\n","        data = Data()\n","        mol = Chem.MolFromSmiles(smiles)\n","        mol = Chem.AddHs(mol)\n","\n","        xs = []\n","\n","        for atom in mol.GetAtoms():\n","          # Initialize the symbol vector\n","          symbol = [0.] * len(self.symbols)\n","\n","          # Handle atom symbol\n","          atom_symbol = atom.GetSymbol()\n","          if atom_symbol in self.symbols:\n","              symbol[self.symbols.index(atom_symbol)] = 1.\n","          else:\n","              print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","              symbol[-1] = 1.  # Mark as 'other'\n","\n","          # Degree of the atom\n","          degree = [0.] * 6  # Degree list can handle degrees 0-5\n","          atom_degree = atom.GetDegree()\n","          if atom_degree < len(degree):\n","              degree[atom_degree] = 1.\n","\n","          # Formal charge and radical electrons\n","          formal_charge = atom.GetFormalCharge()\n","          radical_electrons = atom.GetNumRadicalElectrons()\n","\n","          # Hybridization handling\n","          hybridization = [0.] * len(self.hybridizations)\n","          try:\n","              hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","          except ValueError:\n","              print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","              hybridization[-1] = 1.  # Default to 'other'\n","\n","          # Aromaticity\n","          aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","          # Hydrogens\n","          hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","          total_hydrogens = atom.GetTotalNumHs()\n","          if total_hydrogens < len(hydrogens):\n","              hydrogens[total_hydrogens] = 1.\n","          else:\n","              hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","          # Chirality\n","          chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","          chirality_type = [0.] * 2\n","          if atom.HasProp('_CIPCode'):\n","              cip_code = atom.GetProp('_CIPCode')\n","              if cip_code in ['R', 'S']:\n","                  chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","          # Construct the feature tensor\n","          x = torch.tensor(symbol + degree + [formal_charge] +\n","                          [radical_electrons] + hybridization +\n","                          [aromaticity] + hydrogens + [chirality] +\n","                          chirality_type)\n","          xs.append(x)\n","\n","\n","\n","        data.x = torch.stack(xs, dim=0)\n","        # data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","        data.y = torch.tensor(Y[i], dtype=torch.float)\n","\n","        edge_indices = []\n","        edge_attrs = []\n","        for bond in mol.GetBonds():\n","            edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","            edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","            bond_type = bond.GetBondType()\n","            single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","            double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","            triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","            aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","            conjugation = 1. if bond.GetIsConjugated() else 0.\n","            ring = 1. if bond.IsInRing() else 0.\n","            stereo = [0.] * 4\n","            stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","            edge_attr = torch.tensor(\n","                [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","            edge_attrs += [edge_attr, edge_attr]\n","\n","        if len(edge_attrs) == 0:\n","            data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","            data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","        else:\n","            data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","            data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","        # graph_level_features = pd.to_numeric(df.iloc[i, :][9:], errors='coerce').fillna(0).values\n","\n","  #       graph_level_features = pd.to_numeric(df.iloc[0, :][[\"MolWt\", \"MolLogP\", \"MolMR\", \"HeavyAtomCount\", \"NumHAcceptors\", \"NumHDonors\", \"NumHeteroatoms\",\n","  #  \"NumRotatableBonds\"]], errors='coerce').fillna(0).values\n","        # graph_level_features = pd.to_numeric(df.iloc[i, :][[\"T,K\"]], errors='coerce').fillna(0).values\n","        # graph_level_features = torch.tensor(graph_level_features, dtype=torch.float)\n","        # data.graph_level_features = graph_level_features\n","\n","        return data\n","\n","\n","pre_transform=GenFeatures()\n","\n","data = list()\n","\n","for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i)\n","        data.append(node_edge_featurization)\n","\n","    except Exception as e:\n","        print(f\"Error processing {smiles}: {e}\")\n","\n","random.shuffle(data)\n","train = data[:int(len(data)*0.6)] #train set\n","val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","test = data[int(len(data)*0.8):]"]},{"cell_type":"markdown","metadata":{"id":"GtxALBjvQPap"},"source":["# Featurization for AttentiveFP + Graph-level Features"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33151,"status":"ok","timestamp":1729265330681,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"0LdVwrBeQPj9","outputId":"5324952e-1506-4932-94ac-0a751dd4eeeb"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8884/8884 [00:32<00:00, 272.22it/s]\n"]}],"source":["import os.path as osp\n","from math import sqrt\n","import torch\n","import torch.nn.functional as F\n","from rdkit import Chem\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn.models import AttentiveFP\n","\n","class GenFeatures:\n","    def __init__(self):\n","        self.symbols = [\n","            'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br',\n","            'Te', 'I', 'At', 'other'\n","        ]\n","\n","        # self.symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',\n","        #     'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce',\n","        #     'Zr', 'Ag', 'Ba', 'Be', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al', 'Re', 'Ta',\n","        #     'Ir','Be,','B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn',\n","        #     'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd',\n","        #     'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C', 'other']\n","\n","        self.hybridizations = [\n","            Chem.rdchem.HybridizationType.S,\n","            Chem.rdchem.HybridizationType.SP,\n","            Chem.rdchem.HybridizationType.SP2,\n","            Chem.rdchem.HybridizationType.SP3,\n","            Chem.rdchem.HybridizationType.SP3D,\n","            Chem.rdchem.HybridizationType.SP3D2,\n","            Chem.rdchem.HybridizationType.UNSPECIFIED,\n","            'other',\n","        ]\n","\n","\n","\n","        self.stereos = [\n","            Chem.rdchem.BondStereo.STEREONONE,\n","            Chem.rdchem.BondStereo.STEREOANY,\n","            Chem.rdchem.BondStereo.STEREOZ,\n","            Chem.rdchem.BondStereo.STEREOE,\n","        ]\n","\n","    def __call__(self, smiles, i):\n","        # Generate AttentiveFP features\n","        data = Data()\n","        mol = Chem.MolFromSmiles(smiles)\n","        mol = Chem.AddHs(mol)\n","\n","        xs = []\n","\n","        for atom in mol.GetAtoms():\n","          # Initialize the symbol vector\n","          symbol = [0.] * len(self.symbols)\n","\n","          # Handle atom symbol\n","          atom_symbol = atom.GetSymbol()\n","          if atom_symbol in self.symbols:\n","              symbol[self.symbols.index(atom_symbol)] = 1.\n","          else:\n","              # print(f\"Unrecognized element: {atom_symbol}\")  # Log the unrecognized element\n","              symbol[-1] = 1.  # Mark as 'other'\n","\n","          # Degree of the atom\n","          degree = [0.] * 6  # Degree list can handle degrees 0-5\n","          atom_degree = atom.GetDegree()\n","          if atom_degree < len(degree):\n","              degree[atom_degree] = 1.\n","\n","          # Formal charge and radical electrons\n","          formal_charge = atom.GetFormalCharge()\n","          radical_electrons = atom.GetNumRadicalElectrons()\n","\n","          # Hybridization handling\n","          hybridization = [0.] * len(self.hybridizations)\n","          try:\n","              hybridization[self.hybridizations.index(atom.GetHybridization())] = 1.\n","          except ValueError:\n","              print(f\"Unrecognized hybridization for atom {atom_symbol}: {atom.GetHybridization()}\")\n","              hybridization[-1] = 1.  # Default to 'other'\n","\n","          # Aromaticity\n","          aromaticity = 1. if atom.GetIsAromatic() else 0.\n","\n","          # Hydrogens\n","          hydrogens = [0.] * 5  # Assuming hydrogens can be 0-4\n","          total_hydrogens = atom.GetTotalNumHs()\n","          if total_hydrogens < len(hydrogens):\n","              hydrogens[total_hydrogens] = 1.\n","          else:\n","              hydrogens[-1] = 1.  # Use 'other' if more than 4 hydrogens\n","\n","          # Chirality\n","          chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n","          chirality_type = [0.] * 2\n","          if atom.HasProp('_CIPCode'):\n","              cip_code = atom.GetProp('_CIPCode')\n","              if cip_code in ['R', 'S']:\n","                  chirality_type[['R', 'S'].index(cip_code)] = 1.\n","\n","          # Construct the feature tensor\n","          x = torch.tensor(symbol + degree + [formal_charge] +\n","                          [radical_electrons] + hybridization +\n","                          [aromaticity] + hydrogens + [chirality] +\n","                          chirality_type)\n","          xs.append(x)\n","\n","\n","\n","        data.x = torch.stack(xs, dim=0)\n","        # data.y = torch.tensor([val_to_class(Y[i])], dtype=torch.float)\n","        data.y = torch.tensor(Y[i], dtype=torch.float)\n","\n","        edge_indices = []\n","        edge_attrs = []\n","        for bond in mol.GetBonds():\n","            edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n","            edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n","\n","            bond_type = bond.GetBondType()\n","            single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n","            double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n","            triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n","            aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n","            conjugation = 1. if bond.GetIsConjugated() else 0.\n","            ring = 1. if bond.IsInRing() else 0.\n","            stereo = [0.] * 4\n","            stereo[self.stereos.index(bond.GetStereo())] = 1.\n","\n","            edge_attr = torch.tensor(\n","                [single, double, triple, aromatic, conjugation, ring] + stereo)\n","\n","            edge_attrs += [edge_attr, edge_attr]\n","\n","        if len(edge_attrs) == 0:\n","            data.edge_index = torch.zeros((2, 0), dtype=torch.long)\n","            data.edge_attr = torch.zeros((0, 10), dtype=torch.float)\n","        else:\n","            data.edge_index = torch.tensor(edge_indices).t().contiguous()\n","            data.edge_attr = torch.stack(edge_attrs, dim=0)\n","\n","        # graph_level_features = pd.to_numeric(df.iloc[i, :][9:], errors='coerce').fillna(0).values\n","\n","        graph_level_features = pd.to_numeric(df.iloc[i, :][[\"MolWt\", \"MolLogP\", \"MolMR\", \"HeavyAtomCount\", \"NumHAcceptors\", \"NumHDonors\", \"NumHeteroatoms\",\n","   \"NumRotatableBonds\"]], errors='coerce').fillna(0).values\n","        graph_level_features = torch.tensor(graph_level_features, dtype=torch.float)\n","        data.graph_level_features = graph_level_features\n","\n","        return data\n","\n","\n","pre_transform=GenFeatures()\n","\n","data = list()\n","\n","for i, smiles in tqdm(enumerate(X_smiles), total=len(X_smiles)):\n","    try:\n","        node_edge_featurization = pre_transform(smiles, i)\n","        data.append(node_edge_featurization)\n","\n","    except Exception as e:\n","        print(f\"Error processing {smiles}: {e}\")\n","\n","random.shuffle(data)\n","train = data[:int(len(data)*0.6)] #train set\n","val = data[int(len(data)*0.6):int(len(data)*0.8)]\n","test = data[int(len(data)*0.8):]"]},{"cell_type":"code","source":["torch.save(train, 'gdrive/My Drive/Base_GNN_Solubility/train_data_AqsolDB_cleaned.pt')\n","torch.save(val, 'gdrive/My Drive/Base_GNN_Solubility/val_data_AqsolDB_cleaned.pt')\n","torch.save(test, 'gdrive/My Drive/Base_GNN_Solubility/test_data_AqsolDB_cleaned.pt')"],"metadata":{"id":"uDhrzquHVNIo","executionInfo":{"status":"ok","timestamp":1729283732501,"user_tz":360,"elapsed":6106,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttKA20Nk4aU6"},"outputs":[],"source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 87, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"]},{"cell_type":"code","source":["#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 26, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"_UI5-6wKqoFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rNgrIHg1IdSX"},"source":["# AttentiveFP with Edge Features Training"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_j3BstjP8tIS","executionInfo":{"status":"ok","timestamp":1729266022926,"user_tz":360,"elapsed":153,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"outputs":[],"source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        # print(x.shape)\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        # print(h.shape)\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1435ZWERDVWn","outputId":"3fc586a5-57d3-405d-c440-3b8e78231ea9"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:44<00:00, 50.86it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.13712\n","Validation MAE: 0.87527\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:39<00:00, 53.59it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 0.88672\n","Validation MAE: 0.94778\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:39<00:00, 53.59it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 0.82123\n","Validation MAE: 0.79959\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:38<00:00, 53.89it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 0.79515\n","Validation MAE: 0.81052\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.92it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 0.76378\n","Validation MAE: 0.76806\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.62it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 0.74032\n","Validation MAE: 0.79624\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 2358/5330 [00:44<00:51, 58.02it/s]"]}]},{"cell_type":"code","source":["from sklearn.metrics import r2_score\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRU9DuwSbvkv","executionInfo":{"status":"ok","timestamp":1729268527640,"user_tz":360,"elapsed":12856,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"80c433f5-6bb1-4b4d-ec10-a5a1eca25a74"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.70184\n","R-squared: 0.80482\n"]}]},{"cell_type":"markdown","source":["# Proposed New Architecture"],"metadata":{"id":"Jx4nuXBVrB5Y"}},{"cell_type":"markdown","source":["# Add ensemble global poolings"],"metadata":{"id":"IhX40tCcXqYT"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool, global_max_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","        self.weights = torch.nn.Parameter(torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        # out = global_add_pool(x, batch).relu_()\n","\n","        add_pool = global_add_pool(x, batch)\n","        mean_pool = global_mean_pool(x, batch)\n","        max_pool = global_max_pool(x, batch)\n","\n","        out = (self.weights[0] * add_pool +\n","                         self.weights[1] * mean_pool +\n","                         self.weights[2] * max_pool).relu()\n","\n","\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","\n","  #set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"VsDNULsgXmA8","executionInfo":{"status":"ok","timestamp":1729285334120,"user_tz":360,"elapsed":238,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["# GATv2"],"metadata":{"id":"fjZlDQ0HXwBQ"}},{"cell_type":"code","source":["# from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import GRUCell, Linear, Parameter\n","\n","from torch_geometric.nn import GATConv, GATv2Conv, MessagePassing, global_add_pool, global_mean_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","\n","        # propagate_type: (x: Tensor, alpha: Tensor)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    r\"\"\"The Attentive FP model for molecular representation learning from the\n","    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n","    with the Graph Attention Mechanism\"\n","    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n","    graph attention mechanisms.\n","\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        hidden_channels (int): Hidden node feature dimensionality.\n","        out_channels (int): Size of each output sample.\n","        edge_dim (int): Edge feature dimensionality.\n","        num_layers (int): Number of GNN layers.\n","        num_timesteps (int): Number of iterative refinement steps for global\n","            readout.\n","        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n","                                  dropout)\n","        self.gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_grus = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATv2Conv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATv2Conv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False  # Cannot explain global pooling.\n","        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.gru.reset_parameters()\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            conv.reset_parameters()\n","            gru.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_gru.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        \"\"\"\"\"\"  # noqa: D419\n","        # Atom Embedding:\n","        x = F.leaky_relu_(self.lin1(x))\n","        # print(x.shape)\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        # print(h.shape)\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","        x = self.gru(h, x).relu_()\n","\n","        for conv, gru in zip(self.atom_convs, self.atom_grus):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x = gru(h, x).relu()\n","\n","        # Molecule Embedding:\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out = self.mol_gru(h, out).relu_()\n","\n","        # Predictor:\n","        #concatenate graph-level features to the output layer\n","        # out = torch.concat((out, graph_level_features.unsqueeze(0)), dim = -1)\n","        # out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"czfC-D7xxR5E","executionInfo":{"status":"ok","timestamp":1729274220076,"user_tz":360,"elapsed":201,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# LSTM (use cell state)"],"metadata":{"id":"1e-qHbIBX5S5"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import LSTMCell, Linear, Parameter\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool, GATv2\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_lstm = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_lstm.append(LSTMCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False\n","        self.mol_lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.lstm.reset_parameters()\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            conv.reset_parameters()\n","            lstm.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_lstm.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","\n","    # def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","    #             batch: Tensor) -> Tensor:\n","    #     \"\"\"\"\"\"  # noqa: D419\n","    #     # Atom Embedding:\n","    #     x = F.leaky_relu_(self.lin1(x))\n","\n","    #     h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","    #     h = F.dropout(h, p=self.dropout, training=self.training)\n","    #     x = self.gru(h, x).relu_()\n","\n","    #     for conv, gru in zip(self.atom_convs, self.atom_grus):\n","    #         h = conv(x, edge_index)\n","    #         h = F.elu(h)\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         x = gru(h, x).relu()\n","\n","    #     # Molecule Embedding:\n","    #     row = torch.arange(batch.size(0), device=batch.device)\n","    #     edge_index = torch.stack([row, batch], dim=0)\n","\n","    #     out = global_add_pool(x, batch).relu_()\n","    #     for t in range(self.num_timesteps):\n","    #         h = F.elu_(self.mol_conv((x, out), edge_index))\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         out = self.mol_gru(h, out).relu_()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Initialize hidden and cell states for the LSTM\n","        # hx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        # cx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        cx = x\n","\n","        # # Using LSTMCell\n","        # hx, cx = self.lstm(h, (hx, cx))  # Update x with LSTM\n","\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            # x, cx = lstm(h, (x, cx))  # Update x with LSTM\n","            cx, x = lstm(h, (cx, x))  # Update x with LSTM\n","            x = x.relu()\n","\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        cx = out\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            # out, cx = self.mol_lstm(h, (out, cx))  # Update out with LSTM\n","            cx, out = self.mol_lstm(h, (cx, out))  # Update out with LSTM\n","            out = out.relu()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"dWkSfh-glQmx","executionInfo":{"status":"error","timestamp":1729302904576,"user_tz":360,"elapsed":4026,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"colab":{"base_uri":"https://localhost:8080/","height":384},"outputId":"c5f28a0d-44bb-486b-a9f3-12903026f9bd"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ac978c0bc07e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagePassing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_add_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGATv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglorot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["# LSTM (use hidden state)\n","# both GATv2 and LSTM"],"metadata":{"id":"C_Cq87ApYA51"}},{"cell_type":"code","source":["from typing import Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from torch.nn import LSTMCell, Linear, Parameter\n","from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n","from torch_geometric.nn.inits import glorot, zeros\n","from torch_geometric.typing import Adj, OptTensor\n","from torch_geometric.utils import softmax\n","\n","\n","class GATEConv(MessagePassing):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__(aggr='add', node_dim=0)\n","\n","        self.dropout = dropout\n","\n","        self.att_l = Parameter(torch.empty(1, out_channels))\n","        self.att_r = Parameter(torch.empty(1, in_channels))\n","\n","        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n","        self.lin2 = Linear(out_channels, out_channels, False)\n","\n","        self.bias = Parameter(torch.empty(out_channels))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.att_l)\n","        glorot(self.att_r)\n","        glorot(self.lin1.weight)\n","        glorot(self.lin2.weight)\n","        zeros(self.bias)\n","\n","    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n","        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n","        out = self.propagate(edge_index, x=x, alpha=alpha)\n","        out = out + self.bias\n","        return out\n","\n","    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n","                    index: Tensor, ptr: OptTensor,\n","                    size_i: Optional[int]) -> Tensor:\n","        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n","        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n","        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n","        alpha = alpha_j + alpha_i\n","        alpha = F.leaky_relu_(alpha)\n","        alpha = softmax(alpha, index, ptr, size_i)\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n","        return alpha\n","\n","    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n","        return self.lin2(x_j) * alpha.unsqueeze(-1)\n","\n","\n","class AttentiveFP(torch.nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        hidden_channels: int,\n","        out_channels: int,\n","        edge_dim: int,\n","        num_layers: int,\n","        num_timesteps: int,\n","        dropout: float = 0.0,\n","    ):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.edge_dim = edge_dim\n","        self.num_layers = num_layers\n","        self.num_timesteps = num_timesteps\n","        self.dropout = dropout\n","\n","        self.lin1 = Linear(in_channels, hidden_channels)\n","\n","        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)\n","        self.lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.atom_convs = torch.nn.ModuleList()\n","        self.atom_lstm = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            conv = GATv2Conv(hidden_channels, hidden_channels, dropout=dropout,\n","                           add_self_loops=False, negative_slope=0.01)\n","            self.atom_convs.append(conv)\n","            self.atom_lstm.append(LSTMCell(hidden_channels, hidden_channels))\n","\n","        self.mol_conv = GATv2Conv(hidden_channels, hidden_channels,\n","                                dropout=dropout, add_self_loops=False,\n","                                negative_slope=0.01)\n","        self.mol_conv.explain = False\n","        self.mol_lstm = LSTMCell(hidden_channels, hidden_channels)\n","\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin1.reset_parameters()\n","        self.gate_conv.reset_parameters()\n","        self.lstm.reset_parameters()\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            conv.reset_parameters()\n","            lstm.reset_parameters()\n","        self.mol_conv.reset_parameters()\n","        self.mol_lstm.reset_parameters()\n","        self.lin2.reset_parameters()\n","\n","\n","    # def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","    #             batch: Tensor) -> Tensor:\n","    #     \"\"\"\"\"\"  # noqa: D419\n","    #     # Atom Embedding:\n","    #     x = F.leaky_relu_(self.lin1(x))\n","\n","    #     h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","    #     h = F.dropout(h, p=self.dropout, training=self.training)\n","    #     x = self.gru(h, x).relu_()\n","\n","    #     for conv, gru in zip(self.atom_convs, self.atom_grus):\n","    #         h = conv(x, edge_index)\n","    #         h = F.elu(h)\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         x = gru(h, x).relu()\n","\n","    #     # Molecule Embedding:\n","    #     row = torch.arange(batch.size(0), device=batch.device)\n","    #     edge_index = torch.stack([row, batch], dim=0)\n","\n","    #     out = global_add_pool(x, batch).relu_()\n","    #     for t in range(self.num_timesteps):\n","    #         h = F.elu_(self.mol_conv((x, out), edge_index))\n","    #         h = F.dropout(h, p=self.dropout, training=self.training)\n","    #         out = self.mol_gru(h, out).relu_()\n","\n","    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n","                batch: Tensor) -> Tensor:\n","        x = F.leaky_relu_(self.lin1(x))\n","\n","        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n","        h = F.dropout(h, p=self.dropout, training=self.training)\n","\n","        # Initialize hidden and cell states for the LSTM\n","        # hx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        # cx = torch.zeros(x.size(0), self.hidden_channels, device=x.device)\n","        cx = x\n","\n","        # # Using LSTMCell\n","        # hx, cx = self.lstm(h, (hx, cx))  # Update x with LSTM\n","\n","        for conv, lstm in zip(self.atom_convs, self.atom_lstm):\n","            h = conv(x, edge_index)\n","            h = F.elu(h)\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            x, cx = lstm(h, (x, cx))  # Update x with LSTM\n","            # cx, x = lstm(h, (cx, x))  # Update x with LSTM\n","            x = x.relu()\n","\n","        row = torch.arange(batch.size(0), device=batch.device)\n","        edge_index = torch.stack([row, batch], dim=0)\n","\n","        out = global_add_pool(x, batch).relu_()\n","        cx = out\n","\n","        for t in range(self.num_timesteps):\n","            h = F.elu_(self.mol_conv((x, out), edge_index))\n","            h = F.dropout(h, p=self.dropout, training=self.training)\n","            out, cx = self.mol_lstm(h, (out, cx))  # Update out with LSTM\n","            # cx, out = self.mol_lstm(h, (cx, out))  # Update out with LSTM\n","            out = out.relu()\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","        return self.lin2(out)\n","\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}('\n","                f'in_channels={self.in_channels}, '\n","                f'hidden_channels={self.hidden_channels}, '\n","                f'out_channels={self.out_channels}, '\n","                f'edge_dim={self.edge_dim}, '\n","                f'num_layers={self.num_layers}, '\n","                f'num_timesteps={self.num_timesteps}'\n","                f')')\n","\n","\n","\n","#set up device and create model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n","# model = Net().to(device) #create network and send to the device memory\n","model = AttentiveFP(in_channels = 41, hidden_channels = 32, out_channels = 1, edge_dim = 10, num_layers = 3, num_timesteps = 3, dropout = 0.1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n","# CSE = CrossEntropyLoss() #define loss"],"metadata":{"id":"YFuftpR6n76o","executionInfo":{"status":"ok","timestamp":1729276746082,"user_tz":360,"elapsed":192,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"I3Lrp79VYD5O"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AQk16s5buaK","executionInfo":{"status":"ok","timestamp":1729271413179,"user_tz":360,"elapsed":2051480,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"ce993a72-89ad-41fd-a053-58c056158a39"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:35<00:00, 55.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.21143\n","Validation MAE: 0.96381\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 57.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.93984\n","Validation MAE: 0.85257\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 59.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.85849\n","Validation MAE: 0.87104\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.81036\n","Validation MAE: 0.81308\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 60.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.78440\n","Validation MAE: 0.79351\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 59.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.76806\n","Validation MAE: 0.73123\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 59.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.74768\n","Validation MAE: 0.71109\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.72475\n","Validation MAE: 0.75458\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.71509\n","Validation MAE: 0.71840\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 59.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.70895\n","Validation MAE: 0.69187\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.69837\n","Validation MAE: 0.67938\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 57.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.68956\n","Validation MAE: 0.68746\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.68172\n","Validation MAE: 0.69354\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.67959\n","Validation MAE: 0.69042\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.66810\n","Validation MAE: 0.69490\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.66307\n","Validation MAE: 0.67146\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 59.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.66638\n","Validation MAE: 0.67943\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.65377\n","Validation MAE: 0.67771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.65887\n","Validation MAE: 0.66905\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.66626\n","Validation MAE: 0.70298\n","Test MAE: 0.69258\n","R-squared: 0.80839\n"]}]},{"cell_type":"markdown","source":["# Replace GRU by LSTM"],"metadata":{"id":"1ghwmUGuw_DQ"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaMetx52oDSq","executionInfo":{"status":"ok","timestamp":1729273702517,"user_tz":360,"elapsed":1990255,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"5ad1b3f3-08ce-437b-a339-cd5a3682001b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:34<00:00, 56.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.21924\n","Validation MAE: 0.93876\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.85363\n","Validation MAE: 0.77609\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.79047\n","Validation MAE: 0.81138\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.76682\n","Validation MAE: 0.72245\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.73755\n","Validation MAE: 0.78935\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 60.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.73153\n","Validation MAE: 0.72203\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:27<00:00, 61.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.71327\n","Validation MAE: 0.72393\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 59.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.71007\n","Validation MAE: 0.68943\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:26<00:00, 61.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.69273\n","Validation MAE: 0.72590\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 60.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.69315\n","Validation MAE: 0.68340\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 60.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.68519\n","Validation MAE: 0.69513\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:27<00:00, 61.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.68012\n","Validation MAE: 0.68596\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.67508\n","Validation MAE: 0.66770\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:28<00:00, 60.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.68011\n","Validation MAE: 0.67332\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:26<00:00, 61.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.66004\n","Validation MAE: 0.64524\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.66011\n","Validation MAE: 0.66394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:26<00:00, 61.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.66436\n","Validation MAE: 0.68159\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.65305\n","Validation MAE: 0.68417\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.64849\n","Validation MAE: 0.66388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.64812\n","Validation MAE: 0.64862\n","Test MAE: 0.66996\n","R-squared: 0.81844\n"]}]},{"cell_type":"markdown","source":["#replace GAT by GATv2"],"metadata":{"id":"WIsyfVmVxYlM"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Djd4lRLxYsy","executionInfo":{"status":"ok","timestamp":1729276574577,"user_tz":360,"elapsed":2332076,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"28eb7a1c-9e24-47d9-d51e-d18baa5407e6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:50<00:00, 48.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.16028\n","Validation MAE: 0.89940\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:47<00:00, 49.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.88910\n","Validation MAE: 0.92291\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:45<00:00, 50.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.80462\n","Validation MAE: 0.74526\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:46<00:00, 50.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.76810\n","Validation MAE: 0.82540\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:46<00:00, 50.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.74588\n","Validation MAE: 0.72481\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.72977\n","Validation MAE: 0.71334\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:44<00:00, 50.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.71651\n","Validation MAE: 0.68507\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:44<00:00, 50.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.71397\n","Validation MAE: 0.67313\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:45<00:00, 50.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.70015\n","Validation MAE: 0.67694\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:45<00:00, 50.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.69353\n","Validation MAE: 0.67506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.68392\n","Validation MAE: 0.68016\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.68188\n","Validation MAE: 0.71467\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:46<00:00, 50.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.67447\n","Validation MAE: 0.67054\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.69249\n","Validation MAE: 0.66433\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.67741\n","Validation MAE: 0.68725\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:49<00:00, 48.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.66477\n","Validation MAE: 0.67991\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:46<00:00, 50.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.66232\n","Validation MAE: 0.77428\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:48<00:00, 49.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.66031\n","Validation MAE: 0.69639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:47<00:00, 49.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.65974\n","Validation MAE: 0.66003\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:50<00:00, 48.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.65066\n","Validation MAE: 0.68658\n","Test MAE: 0.68825\n","R-squared: 0.81149\n"]}]},{"cell_type":"markdown","source":["# Both"],"metadata":{"id":"vm5xKboU7VZ4"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Duslh2Od7Vj5","executionInfo":{"status":"ok","timestamp":1729278839519,"user_tz":360,"elapsed":2065656,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"72dfb5fd-5d50-479c-d9e6-3bbee721a07b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.27695\n","Validation MAE: 0.88104\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:34<00:00, 56.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.86980\n","Validation MAE: 0.96993\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.79813\n","Validation MAE: 0.75492\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 56.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.75970\n","Validation MAE: 0.74483\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.73583\n","Validation MAE: 0.73922\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.71774\n","Validation MAE: 0.72461\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 56.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.70470\n","Validation MAE: 0.70101\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.69191\n","Validation MAE: 0.72754\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.69190\n","Validation MAE: 0.67008\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:34<00:00, 56.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.67413\n","Validation MAE: 0.65734\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.66314\n","Validation MAE: 0.70184\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:29<00:00, 59.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.66380\n","Validation MAE: 0.69863\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:35<00:00, 55.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.66098\n","Validation MAE: 0.69120\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:30<00:00, 58.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.65014\n","Validation MAE: 0.67670\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.65223\n","Validation MAE: 0.72363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:31<00:00, 58.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.63939\n","Validation MAE: 0.74363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 56.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.64781\n","Validation MAE: 0.68533\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:34<00:00, 56.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.63676\n","Validation MAE: 0.68985\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:33<00:00, 57.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.63199\n","Validation MAE: 0.65666\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:32<00:00, 57.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.62645\n","Validation MAE: 0.65889\n","Test MAE: 0.66318\n","R-squared: 0.81868\n"]}]},{"cell_type":"markdown","source":["# ensemble global poolings"],"metadata":{"id":"9V_BAmwuYZOP"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1E0xduIoYZXF","executionInfo":{"status":"ok","timestamp":1729287664924,"user_tz":360,"elapsed":2292565,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"2eeef3c1-c608-45ea-d7b0-2ac54bb83fe2"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:51<00:00, 47.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.13321\n","Validation MAE: 0.96234\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.90403\n","Validation MAE: 0.86632\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.84810\n","Validation MAE: 0.80969\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.79430\n","Validation MAE: 0.82819\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.76182\n","Validation MAE: 0.71120\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:44<00:00, 51.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.73581\n","Validation MAE: 0.70611\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.71792\n","Validation MAE: 0.70387\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:45<00:00, 50.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.70195\n","Validation MAE: 0.71008\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.70094\n","Validation MAE: 0.70092\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.69712\n","Validation MAE: 0.72616\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.68521\n","Validation MAE: 0.69839\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:41<00:00, 52.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.68041\n","Validation MAE: 0.67404\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:44<00:00, 51.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.67289\n","Validation MAE: 0.66833\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.66401\n","Validation MAE: 0.77457\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:46<00:00, 50.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.66881\n","Validation MAE: 0.74135\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.66507\n","Validation MAE: 0.68264\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:44<00:00, 51.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.65516\n","Validation MAE: 0.66650\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.64511\n","Validation MAE: 0.66991\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:43<00:00, 51.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.64482\n","Validation MAE: 0.66191\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:42<00:00, 51.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.64913\n","Validation MAE: 0.67338\n","Test MAE: 0.68838\n","R-squared: 0.81715\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypeGEBBUwfXo","executionInfo":{"status":"ok","timestamp":1729225034529,"user_tz":360,"elapsed":1442232,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"b9685036-ee48-425b-a956-dceae67988fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:08<00:00, 78.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.13981\n","Validation MAE: 0.92994\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.88909\n","Validation MAE: 0.81008\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.80491\n","Validation MAE: 0.78389\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 83.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.77355\n","Validation MAE: 0.76737\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.74823\n","Validation MAE: 0.80115\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.73539\n","Validation MAE: 0.78640\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.72355\n","Validation MAE: 0.70618\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.71081\n","Validation MAE: 0.77021\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.70820\n","Validation MAE: 0.70439\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.69481\n","Validation MAE: 0.71522\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 80.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.69786\n","Validation MAE: 0.72682\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.68880\n","Validation MAE: 0.68080\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:06<00:00, 80.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.67827\n","Validation MAE: 0.70984\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 80.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.69354\n","Validation MAE: 0.69799\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 80.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.69090\n","Validation MAE: 0.70382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.67756\n","Validation MAE: 0.68020\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.66457\n","Validation MAE: 0.72587\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.66351\n","Validation MAE: 0.70041\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:06<00:00, 80.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.66025\n","Validation MAE: 0.67269\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:06<00:00, 79.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.65761\n","Validation MAE: 0.67069\n","Model improved! Saving model...\n","Test MAE: 0.67120\n","R-squared: 0.80536\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index,data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAvrpcFt2TWT","executionInfo":{"status":"ok","timestamp":1729217788661,"user_tz":360,"elapsed":919735,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"fb5b5883-b639-4188-a669-4e6f832191ba"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:06<00:00, 79.81it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.15326\n","Validation MAE: 0.91482\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.64it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 0.88083\n","Validation MAE: 0.84398\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:03<00:00, 83.80it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 0.82687\n","Validation MAE: 0.84847\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.44it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 0.78964\n","Validation MAE: 0.74917\n","Model improved! Saving model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.98it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 0.76311\n","Validation MAE: 0.74994\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.96it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 0.74647\n","Validation MAE: 0.76187\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.72709\n","Validation MAE: 0.72860\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:03<00:00, 83.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.72824\n","Validation MAE: 0.73222\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.71015\n","Validation MAE: 0.71124\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:05<00:00, 81.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.70995\n","Validation MAE: 0.69928\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 83.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.70515\n","Validation MAE: 0.69543\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:03<00:00, 83.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.69626\n","Validation MAE: 0.70718\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.69046\n","Validation MAE: 0.69164\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.68937\n","Validation MAE: 0.71068\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.68923\n","Validation MAE: 0.67327\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 83.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.67862\n","Validation MAE: 0.69134\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.66880\n","Validation MAE: 0.65750\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 83.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.67976\n","Validation MAE: 0.71148\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 83.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.67671\n","Validation MAE: 0.74692\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.67781\n","Validation MAE: 0.66839\n","Test MAE: 0.66341\n"]}]},{"cell_type":"markdown","source":["# GATv2"],"metadata":{"id":"4ovFQTcTNTki"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","# torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","all_actual = []\n","all_predicted = []\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Ik2Dt2XNTtv","executionInfo":{"status":"ok","timestamp":1729197705920,"user_tz":360,"elapsed":1329835,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"ae8c1d52-6be1-4c60-8eee-17e3152eaf59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 0.23311\n","Validation MAE: 0.19300\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 88.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.19966\n","Validation MAE: 0.18384\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.18394\n","Validation MAE: 0.16442\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.17055\n","Validation MAE: 0.15455\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 90.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.16354\n","Validation MAE: 0.14884\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.15993\n","Validation MAE: 0.14481\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.15522\n","Validation MAE: 0.14618\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.15392\n","Validation MAE: 0.15718\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.15179\n","Validation MAE: 0.13796\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:01<00:00, 87.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.15203\n","Validation MAE: 0.15147\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.15048\n","Validation MAE: 0.14091\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.15011\n","Validation MAE: 0.14464\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.14726\n","Validation MAE: 0.14197\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.14852\n","Validation MAE: 0.14532\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.14777\n","Validation MAE: 0.13814\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.14506\n","Validation MAE: 0.14007\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.14595\n","Validation MAE: 0.14151\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.14474\n","Validation MAE: 0.13439\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.14424\n","Validation MAE: 0.13894\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.14393\n","Validation MAE: 0.14929\n","Test MAE: 0.15184\n"]}]},{"cell_type":"code","source":["test_maes = []\n","\n","# Testing phase\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr,\n","                    batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_maes.append(float(loss))  # Store individual MAE\n","\n","# Calculate average test MAE\n","avg_test_loss = sum(test_maes) / len(test_maes)\n","print('Average Test MAE: {:.5f}'.format(avg_test_loss))\n","\n","# Plotting the distribution of test MAEs\n","plt.figure(figsize=(10, 6))\n","sns.histplot(test_maes, bins=30, kde=True, color='blue', alpha=0.6)\n","\n","# Adding titles and labels\n","plt.title('Distribution of Test MAE', fontsize=16)\n","plt.xlabel('Test MAE', fontsize=14)\n","plt.ylabel('Frequency', fontsize=14)\n","\n","# Show plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"id":"xH2ufcBsOdrA","executionInfo":{"status":"ok","timestamp":1729197948152,"user_tz":360,"elapsed":6789,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"661ebb09-e1ba-43d3-fcf3-58ad36fcc644"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Test MAE: 0.15184\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETLvV39KPNbo","executionInfo":{"status":"ok","timestamp":1729198089473,"user_tz":360,"elapsed":370,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"aa37a043-3283-4f75-f556-8f6cd8982e5e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[18, 41], y=0.2537768483161926, edge_index=[2, 38], edge_attr=[38, 10], graph_level_features=[8])"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["from sklearn.metrics import r2_score\n","\n","# Initialize variables to store actual and predicted values\n","all_actual = []\n","all_predicted = []\n","\n","# Testing phase\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr,\n","                    batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","\n","        # Convert actual and predicted values to numpy arrays\n","        actual_values = data.y.squeeze().cpu().numpy()  # Get actual values\n","        predicted_values = out.squeeze().cpu().numpy()  # Get predicted values\n","\n","        # Ensure they are 1D arrays before extending\n","        if actual_values.ndim == 0:\n","            all_actual.append(actual_values)\n","        else:\n","            all_actual.extend(actual_values)  # Add to the list of actual values\n","\n","        if predicted_values.ndim == 0:\n","            all_predicted.append(predicted_values)\n","        else:\n","            all_predicted.extend(predicted_values)  # Add to the list of predicted values\n","\n","# Calculate R-squared\n","r2 = r2_score(all_actual, all_predicted)\n","\n","print('R-squared: {:.5f}'.format(r2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXEcFPzmO3U8","executionInfo":{"status":"ok","timestamp":1729221932746,"user_tz":360,"elapsed":7087,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1ae8e6fb-2ef1-4151-f3d4-9310ab15a8e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["R-squared: 0.81578\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Sample DataFrame (replace this with your actual DataFrame)\n","# df = pd.read_csv('your_data.csv')  # Uncomment to load your data\n","\n","# Ensure 'Solubility' column exists\n","if 'Solubility' in df.columns:\n","    # Set up the matplotlib figure\n","    plt.figure(figsize=(10, 6))\n","\n","    # Plotting histogram\n","    sns.histplot(df['Solubility'], bins=30, kde=True, color='blue', alpha=0.6)\n","\n","    # Adding titles and labels\n","    plt.title('Distribution of Solubility', fontsize=16)\n","    plt.xlabel('Solubility', fontsize=14)\n","    plt.ylabel('Frequency', fontsize=14)\n","\n","    # Show plot\n","    plt.show()\n","else:\n","    print(\"The 'Solubility' column does not exist in the DataFrame.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"hNjBKOPTN8dY","executionInfo":{"status":"ok","timestamp":1729197834563,"user_tz":360,"elapsed":1193,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"ecf971a8-7087-41ae-f152-da56ad897873"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# weighted sum of different poolings"],"metadata":{"id":"bDk7Awwn8MFh"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","\n","\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","#Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMZ1uT8O8OVo","executionInfo":{"status":"ok","timestamp":1729099986962,"user_tz":360,"elapsed":1586665,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"94b6c61f-6267-404b-c602-e0b7b2723c7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.31239\n","Validation MAE: 1.02046\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.98725\n","Validation MAE: 0.95631\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.91413\n","Validation MAE: 0.83896\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.87272\n","Validation MAE: 0.80979\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.83824\n","Validation MAE: 0.82140\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.83916\n","Validation MAE: 0.80681\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.81883\n","Validation MAE: 0.78469\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.79700\n","Validation MAE: 0.77336\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 84.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.78728\n","Validation MAE: 0.75780\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.77371\n","Validation MAE: 0.82509\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.76237\n","Validation MAE: 0.75945\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.75667\n","Validation MAE: 0.76002\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.75087\n","Validation MAE: 0.76634\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.75471\n","Validation MAE: 0.73713\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.73706\n","Validation MAE: 0.77995\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.72620\n","Validation MAE: 0.73671\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.72641\n","Validation MAE: 0.72144\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.71529\n","Validation MAE: 0.72273\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.71137\n","Validation MAE: 0.73650\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:10<00:00, 84.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.71171\n","Validation MAE: 0.72325\n","No improvement.\n","Test MAE: 0.75481\n"]}]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, device, train, val, and test are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr,\n","                    batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch + 1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr,\n","                        batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('best_model.pth'))  # Load the best model\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr,\n","                    batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"id":"MbBPSlg0KRUK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# replace GRU by LSTM"],"metadata":{"id":"I366yo9Of7zp"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","#Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7QUIcNSfd8k","executionInfo":{"status":"ok","timestamp":1729191759467,"user_tz":360,"elapsed":1087174,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"6b6ebb4c-2e85-4305-d273-b2d886467b62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:50<00:00, 105.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 0.24282\n","Validation MAE: 0.20609\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:47<00:00, 111.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.19877\n","Validation MAE: 0.20787\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:47<00:00, 111.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.18716\n","Validation MAE: 0.16446\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:47<00:00, 112.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.17720\n","Validation MAE: 0.16408\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:47<00:00, 111.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.17074\n","Validation MAE: 0.16529\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.16594\n","Validation MAE: 0.15527\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 110.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.16032\n","Validation MAE: 0.16543\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:47<00:00, 111.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.16290\n","Validation MAE: 0.15848\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.15765\n","Validation MAE: 0.14414\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.15617\n","Validation MAE: 0.14601\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.15368\n","Validation MAE: 0.15369\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 108.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.15062\n","Validation MAE: 0.15079\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.14879\n","Validation MAE: 0.14390\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.14921\n","Validation MAE: 0.14348\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:50<00:00, 106.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.14848\n","Validation MAE: 0.14540\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.14576\n","Validation MAE: 0.14262\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:49<00:00, 107.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.14394\n","Validation MAE: 0.13891\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 109.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.14479\n","Validation MAE: 0.14361\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 110.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.14546\n","Validation MAE: 0.14060\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:48<00:00, 110.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.14293\n","Validation MAE: 0.15074\n","No improvement.\n","Test MAE: 0.15705\n"]}]},{"cell_type":"code","source":["avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rrqk-YrAf6RO","executionInfo":{"status":"ok","timestamp":1729085026983,"user_tz":360,"elapsed":408,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"ea8a7681-578b-45ea-8933-a6f8fd156542"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.76096\n"]}]},{"cell_type":"code","source":["\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9A46065A3fRT","executionInfo":{"status":"ok","timestamp":1729091208958,"user_tz":360,"elapsed":264,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"70397aae-2db3-4d5e-fdc7-7731c1594300"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.76096\n"]}]},{"cell_type":"markdown","source":["# multiple poolings"],"metadata":{"id":"7jqTeIgJGsyr"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"p55GOqXmGt7m","executionInfo":{"status":"error","timestamp":1729174315805,"user_tz":360,"elapsed":8326,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"7c72da4d-d36c-4313-e170-181398e266c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 737/5989 [00:08<00:58, 89.88it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-51c19783989a>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aggregate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# replace GAT by GATV2"],"metadata":{"id":"bQ83mLhWqkSF"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","#Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yD8XUEyKXK8","executionInfo":{"status":"ok","timestamp":1729101736686,"user_tz":360,"elapsed":1597066,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"17041e0c-ca92-44e5-a21e-81152b2304fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:15<00:00, 79.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.30743\n","Validation MAE: 0.95414\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.98808\n","Validation MAE: 0.90719\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.91393\n","Validation MAE: 0.85536\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.86332\n","Validation MAE: 0.83110\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.83532\n","Validation MAE: 0.81206\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 82.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.82118\n","Validation MAE: 0.78237\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.81007\n","Validation MAE: 0.78358\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.78995\n","Validation MAE: 0.81673\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.78042\n","Validation MAE: 0.78190\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.77175\n","Validation MAE: 0.73447\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.75793\n","Validation MAE: 0.75470\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.75689\n","Validation MAE: 0.80259\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.74842\n","Validation MAE: 0.75329\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.73727\n","Validation MAE: 0.73178\n","Model improved! Saving model...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.73908\n","Validation MAE: 0.75132\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.73626\n","Validation MAE: 0.73670\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.73489\n","Validation MAE: 0.73614\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.72845\n","Validation MAE: 0.75793\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.72045\n","Validation MAE: 0.73561\n","No improvement.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.72078\n","Validation MAE: 0.76851\n","No improvement.\n","Test MAE: 0.74857\n"]}]},{"cell_type":"code","source":["avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MORG-tyx9VqT","executionInfo":{"status":"ok","timestamp":1729044874175,"user_tz":360,"elapsed":519,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"2d5a3050-43f0-4238-8fff-0229a3ab759a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.83841\n"]}]},{"cell_type":"code","source":["# import torch\n","# import random\n","# from tqdm import tqdm\n","# import torch.nn as nn\n","\n","# mae_loss = nn.L1Loss()\n","\n","# def train():\n","#     total_loss = total_examples = 0\n","#     for data in train_loader:\n","#         data = data.to(device)\n","#         optimizer.zero_grad()\n","#         out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n","#         loss = mae_loss(out, data.y)\n","#         loss.backward()\n","#         optimizer.step()\n","#         total_loss += float(loss) * data.num_graphs\n","#         total_examples += data.num_graphs\n","#     return total_loss / total_examples\n","\n","\n","# @torch.no_grad()\n","# def test(loader):\n","#     mae = []\n","#     for data in loader:\n","#         data = data.to(device)\n","#         out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n","#         mae.append(mae_loss(out, data.y))\n","#     return np.mean(mae)\n","\n","\n","# for epoch in range(1, 51):\n","#     train_mae = train()\n","#     val_mae = test(val_loader)\n","#     test_mae = test(test_loader)\n","#     print(f'Epoch: {epoch:03d}, Loss: {train_mae:.4f}, Val: {val_mae:.4f}, Test: {test_mae:.4f}')\n"],"metadata":{"id":"WZxk0XaD5YUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVfBYoPEqkZY","executionInfo":{"status":"ok","timestamp":1729022816612,"user_tz":360,"elapsed":115258,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"1562ac9b-aec3-48f1-fbc1-1579d286f570"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:40<00:00, 59.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 001, Average MAE: 1.33047\n","Validation MAE: 1.03837\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 002, Average MAE: 1.00191\n","Validation MAE: 0.98594\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:32<00:00, 65.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 003, Average MAE: 0.93028\n","Validation MAE: 1.02646\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 004, Average MAE: 0.90106\n","Validation MAE: 0.86467\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.70it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 005, Average MAE: 0.86737\n","Validation MAE: 0.84155\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:33<00:00, 64.25it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 006, Average MAE: 0.84924\n","Validation MAE: 0.88438\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:33<00:00, 63.73it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 007, Average MAE: 0.82948\n","Validation MAE: 0.82914\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.59it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 008, Average MAE: 0.81509\n","Validation MAE: 0.86049\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:35<00:00, 62.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 009, Average MAE: 0.81255\n","Validation MAE: 0.84283\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:32<00:00, 64.42it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 010, Average MAE: 0.78777\n","Validation MAE: 0.81964\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.32it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 011, Average MAE: 0.77745\n","Validation MAE: 0.79105\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.30it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 012, Average MAE: 0.77153\n","Validation MAE: 0.78184\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.25it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 013, Average MAE: 0.76048\n","Validation MAE: 0.82602\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:36<00:00, 62.18it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 014, Average MAE: 0.75337\n","Validation MAE: 0.76877\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.46it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 015, Average MAE: 0.73713\n","Validation MAE: 0.78295\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:36<00:00, 62.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 016, Average MAE: 0.74142\n","Validation MAE: 0.78203\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:37<00:00, 61.27it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 017, Average MAE: 0.74088\n","Validation MAE: 0.78201\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:35<00:00, 62.67it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 018, Average MAE: 0.72457\n","Validation MAE: 0.77885\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:35<00:00, 62.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.72008\n","Validation MAE: 0.74178\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:34<00:00, 63.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.72251\n","Validation MAE: 0.75062\n","Test MAE: 0.72363\n"]}]},{"cell_type":"markdown","source":["# Add normalized graph features"],"metadata":{"id":"olbrs4_IuWrL"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gw-tAdsGuWyv","executionInfo":{"status":"ok","timestamp":1729006615650,"user_tz":360,"elapsed":1544034,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"a54501df-b25b-4c73-dbf5-f180eb156af0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 1.32975\n","Validation MAE: 1.04954\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:15<00:00, 79.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.96190\n","Validation MAE: 0.94707\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.88732\n","Validation MAE: 0.86532\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:14<00:00, 80.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.85776\n","Validation MAE: 0.87679\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:14<00:00, 80.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.82278\n","Validation MAE: 0.82325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:14<00:00, 79.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.79960\n","Validation MAE: 0.90287\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.78255\n","Validation MAE: 0.81266\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:14<00:00, 80.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.76975\n","Validation MAE: 0.78530\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.74663\n","Validation MAE: 0.79944\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 83.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.75664\n","Validation MAE: 0.81205\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.73795\n","Validation MAE: 0.76219\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.72737\n","Validation MAE: 0.79058\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.72177\n","Validation MAE: 0.77815\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.71702\n","Validation MAE: 0.74936\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.70131\n","Validation MAE: 0.79085\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:13<00:00, 81.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.69937\n","Validation MAE: 0.77515\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.69920\n","Validation MAE: 0.76853\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.69029\n","Validation MAE: 0.77776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5989/5989 [01:12<00:00, 82.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.68976\n","Validation MAE: 0.77661\n","Early stopping triggered.\n","Test MAE: 0.79213\n"]}]},{"cell_type":"markdown","source":["# Improve one ? Add graph level features and attention of graph level embeddings + features"],"metadata":{"id":"rpEDHDJ9EfTY"}},{"cell_type":"code","source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4k3QGGTEfbu","executionInfo":{"status":"ok","timestamp":1729190077840,"user_tz":360,"elapsed":1331897,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"f7dddc27-42fe-49fa-f3e0-f09f14b4ac8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:04<00:00, 82.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Average MAE: 0.23530\n","Validation MAE: 0.18925\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 002, Average MAE: 0.19493\n","Validation MAE: 0.17101\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 003, Average MAE: 0.18191\n","Validation MAE: 0.16147\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 004, Average MAE: 0.16879\n","Validation MAE: 0.16277\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 005, Average MAE: 0.16449\n","Validation MAE: 0.15116\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 006, Average MAE: 0.15918\n","Validation MAE: 0.15490\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 88.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 007, Average MAE: 0.15701\n","Validation MAE: 0.14625\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 008, Average MAE: 0.15042\n","Validation MAE: 0.14149\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.31it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 009, Average MAE: 0.15004\n","Validation MAE: 0.17217\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 010, Average MAE: 0.14914\n","Validation MAE: 0.14210\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 011, Average MAE: 0.14464\n","Validation MAE: 0.13938\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 012, Average MAE: 0.14689\n","Validation MAE: 0.14886\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 013, Average MAE: 0.14200\n","Validation MAE: 0.13911\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 88.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 014, Average MAE: 0.14397\n","Validation MAE: 0.14727\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 015, Average MAE: 0.14454\n","Validation MAE: 0.13729\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [00:59<00:00, 89.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 016, Average MAE: 0.14148\n","Validation MAE: 0.13902\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 017, Average MAE: 0.14105\n","Validation MAE: 0.14078\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 018, Average MAE: 0.14102\n","Validation MAE: 0.14815\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:01<00:00, 86.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 019, Average MAE: 0.13903\n","Validation MAE: 0.13564\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5330/5330 [01:00<00:00, 87.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 020, Average MAE: 0.13952\n","Validation MAE: 0.14658\n","Test MAE: 0.16319\n"]}]},{"cell_type":"markdown","source":["# replace GRU by LSTM"],"metadata":{"id":"eWcYfLpOavKz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"5HK7JILism0P","executionInfo":{"status":"error","timestamp":1729052548018,"user_tz":360,"elapsed":7623,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"}},"outputId":"573c24c4-cc08-4670-e689-bdd9f52b2df5"},"outputs":[{"output_type":"stream","name":"stderr","text":["  1%|          | 61/5989 [00:07<11:52,  8.32it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-8a2f1b94aeee>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Send data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate data point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-5a0518df334e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update out with LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr,\n\u001b[0m\u001b[1;32m    363\u001b[0m                                   size=size)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_edge_updater_y5gba9q1.py\u001b[0m in \u001b[0;36medge_updater\u001b[0;34m(self, edge_index, alpha, edge_attr, size)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mmutable_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     kwargs = self.edge_collect(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_edge_updater_y5gba9q1.py\u001b[0m in \u001b[0;36medge_collect\u001b[0;34m(self, edge_index, alpha, edge_attr, size)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_alpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alpha_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0malpha_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_alpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0malpha_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# fallback to traceback.format_stack()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# First call the original checkcache as intended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# to our compiled codes can be produced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mcontinue\u001b[0m   \u001b[0;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","mae_loss = nn.L1Loss()\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 5  # Number of epochs to wait for improvement\n","trigger_times = 0\n","torch.autograd.set_detect_anomaly(True)\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average MAE: {:.5f}'.format(epoch+1, avg_loss))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = mae_loss(out.squeeze(), data.y.squeeze())\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation MAE: {:.5f}'.format(avg_val_loss))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        # print('Model improved! Saving model...')\n","        # torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        # print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","# model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = mae_loss(out.squeeze(), data.y.squeeze())\n","        test_loss += float(loss)\n","\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test MAE: {:.5f}'.format(avg_test_loss))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9gucw3IJ57l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":257,"status":"error","timestamp":1729020116025,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"kx-u2ryjEnef","outputId":"267710c3-4845-4595-fdb3-e376f21c9f43"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c5d84736ba45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1728926888494,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"XP0dMBk2CIAe","outputId":"ec31dbcc-64bf-4353-a5fe-3757ae7cafb8"},"outputs":[{"data":{"text/plain":["torch.Size([17])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device)\n","batch.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIXTTWcBD_RO"},"outputs":[],"source":["row = torch.arange(batch.size(0), device=batch.device)\n","row = row + 1\n","edge_index = torch.stack([row, batch], dim=0)\n","out = global_add_pool(data.x, batch).relu_()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1728928965332,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"dhAKEju0JzYR","outputId":"c7c10aa7-7427-440f-c904-c26ca422d97c"},"outputs":[{"data":{"text/plain":["tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["row"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1728928972910,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"T1Y2wSb3LTDC","outputId":"de617486-a43d-44e9-ecb3-a2a29102c672"},"outputs":[{"data":{"text/plain":["tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n","        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["edge_index"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1968704,"status":"ok","timestamp":1728668707167,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"pmfvUpt7kNFw","outputId":"80d92136-e7fc-430c-e4d5-3eddf0faa597"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:30<00:00, 66.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.84067, Accuracy: 0.61079\n","Validation Loss: 0.74503, Validation Accuracy: 0.65631\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:25<00:00, 70.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.67747, Accuracy: 0.70229\n","Validation Loss: 0.60048, Validation Accuracy: 0.75251\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:24<00:00, 70.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.62435, Accuracy: 0.73602\n","Validation Loss: 0.63153, Validation Accuracy: 0.70691\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:28<00:00, 67.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.60624, Accuracy: 0.73852\n","Validation Loss: 0.57875, Validation Accuracy: 0.75251\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:29<00:00, 66.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.58222, Accuracy: 0.74503\n","Validation Loss: 0.66645, Validation Accuracy: 0.70792\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:29<00:00, 67.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.57177, Accuracy: 0.75372\n","Validation Loss: 0.57617, Validation Accuracy: 0.75301\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:28<00:00, 67.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.55791, Accuracy: 0.76156\n","Validation Loss: 0.54782, Validation Accuracy: 0.75651\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:27<00:00, 68.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.55442, Accuracy: 0.76958\n","Validation Loss: 0.59337, Validation Accuracy: 0.73798\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:27<00:00, 68.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.54697, Accuracy: 0.77175\n","Validation Loss: 0.53553, Validation Accuracy: 0.77004\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:25<00:00, 69.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.54194, Accuracy: 0.77041\n","Validation Loss: 0.54816, Validation Accuracy: 0.76954\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:26<00:00, 68.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.52991, Accuracy: 0.77793\n","Validation Loss: 0.58019, Validation Accuracy: 0.74800\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:27<00:00, 68.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.52923, Accuracy: 0.77826\n","Validation Loss: 0.53798, Validation Accuracy: 0.77806\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:32<00:00, 64.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.52822, Accuracy: 0.77576\n","Validation Loss: 0.55990, Validation Accuracy: 0.76002\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:27<00:00, 68.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.51517, Accuracy: 0.78294\n","Validation Loss: 0.54737, Validation Accuracy: 0.75952\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:30<00:00, 66.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.51236, Accuracy: 0.78694\n","Validation Loss: 0.54886, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:28<00:00, 67.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.51066, Accuracy: 0.78711\n","Validation Loss: 0.54999, Validation Accuracy: 0.77655\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:27<00:00, 68.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.50498, Accuracy: 0.78845\n","Validation Loss: 0.54452, Validation Accuracy: 0.76503\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:30<00:00, 66.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.50632, Accuracy: 0.79229\n","Validation Loss: 0.53458, Validation Accuracy: 0.77956\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:29<00:00, 67.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 018, Average loss: 0.51131, Accuracy: 0.78811\n","Validation Loss: 0.53543, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:29<00:00, 66.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 019, Average loss: 0.49650, Accuracy: 0.79462\n","Validation Loss: 0.53249, Validation Accuracy: 0.77455\n","Model improved! Saving model...\n","Test Loss: 0.52933, Test Accuracy: 0.78518\n"]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1513973,"status":"ok","timestamp":1728589910838,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"H8wLuczmtvRh","outputId":"a037969e-8d64-4abf-e5c0-e3fc035e83c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:11<00:00, 83.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.83369, Accuracy: 0.60912\n","Validation Loss: 0.68230, Validation Accuracy: 0.68938\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64718, Accuracy: 0.71615\n","Validation Loss: 0.66050, Validation Accuracy: 0.70792\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.61375, Accuracy: 0.72817\n","Validation Loss: 0.60527, Validation Accuracy: 0.73998\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.59618, Accuracy: 0.74470\n","Validation Loss: 0.60248, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.57850, Accuracy: 0.75071\n","Validation Loss: 0.59701, Validation Accuracy: 0.74499\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.56510, Accuracy: 0.76106\n","Validation Loss: 0.57736, Validation Accuracy: 0.77004\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.55220, Accuracy: 0.76440\n","Validation Loss: 0.60304, Validation Accuracy: 0.75701\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.54679, Accuracy: 0.76574\n","Validation Loss: 0.55266, Validation Accuracy: 0.76653\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.55262, Accuracy: 0.76173\n","Validation Loss: 0.55538, Validation Accuracy: 0.76152\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.54612, Accuracy: 0.76474\n","Validation Loss: 0.56096, Validation Accuracy: 0.76854\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.53367, Accuracy: 0.77258\n","Validation Loss: 0.56249, Validation Accuracy: 0.77555\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.52918, Accuracy: 0.77592\n","Validation Loss: 0.55742, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.52491, Accuracy: 0.77242\n","Validation Loss: 0.54159, Validation Accuracy: 0.77655\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.52571, Accuracy: 0.77809\n","Validation Loss: 0.57228, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.51773, Accuracy: 0.77793\n","Validation Loss: 0.56135, Validation Accuracy: 0.76804\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.51061, Accuracy: 0.79262\n","Validation Loss: 0.54066, Validation Accuracy: 0.77605\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.51414, Accuracy: 0.78594\n","Validation Loss: 0.57913, Validation Accuracy: 0.75651\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.50813, Accuracy: 0.78477\n","Validation Loss: 0.54794, Validation Accuracy: 0.77355\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 018, Average loss: 0.50427, Accuracy: 0.78878\n","Validation Loss: 0.54408, Validation Accuracy: 0.77054\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:09<00:00, 86.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 019, Average loss: 0.49699, Accuracy: 0.78895\n","Validation Loss: 0.53856, Validation Accuracy: 0.78106\n","Model improved! Saving model...\n","Test Loss: 0.56196, Test Accuracy: 0.77316\n"]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":965549,"status":"ok","timestamp":1728525257282,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"EplJFvln5KM1","outputId":"7499319d-2c5f-4855-b943-1a72cf500583"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:26<00:00, 69.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85077, Accuracy: 0.61379\n","Validation Loss: 0.68999, Validation Accuracy: 0.70090\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.67507, Accuracy: 0.71147\n","Validation Loss: 0.74277, Validation Accuracy: 0.68186\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.62121, Accuracy: 0.73201\n","Validation Loss: 0.58771, Validation Accuracy: 0.75351\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.59840, Accuracy: 0.74487\n","Validation Loss: 0.57700, Validation Accuracy: 0.75802\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.57462, Accuracy: 0.75689\n","Validation Loss: 0.59203, Validation Accuracy: 0.75451\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.57065, Accuracy: 0.75739\n","Validation Loss: 0.55757, Validation Accuracy: 0.76353\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.56141, Accuracy: 0.76724\n","Validation Loss: 0.60380, Validation Accuracy: 0.72745\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.55616, Accuracy: 0.76691\n","Validation Loss: 0.56383, Validation Accuracy: 0.75752\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.54910, Accuracy: 0.76674\n","Validation Loss: 0.57712, Validation Accuracy: 0.76052\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 75.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.53870, Accuracy: 0.77609\n","Validation Loss: 0.59208, Validation Accuracy: 0.73297\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.54117, Accuracy: 0.77208\n","Validation Loss: 0.56655, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:23<00:00, 72.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.53967, Accuracy: 0.77409\n","Validation Loss: 0.54259, Validation Accuracy: 0.77705\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.53608, Accuracy: 0.76707\n","Validation Loss: 0.54477, Validation Accuracy: 0.76954\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:21<00:00, 73.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.52757, Accuracy: 0.77425\n","Validation Loss: 0.54618, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:20<00:00, 74.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.52578, Accuracy: 0.77826\n","Validation Loss: 0.55329, Validation Accuracy: 0.77505\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:25<00:00, 69.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.51995, Accuracy: 0.78477\n","Validation Loss: 0.56865, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.51970, Accuracy: 0.78193\n","Validation Loss: 0.55099, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.51853, Accuracy: 0.78694\n","Validation Loss: 0.57027, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:24<00:00, 71.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 018, Average loss: 0.51247, Accuracy: 0.78060\n","Validation Loss: 0.55355, Validation Accuracy: 0.77104\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:22<00:00, 72.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 019, Average loss: 0.51177, Accuracy: 0.78527\n","Validation Loss: 0.53661, Validation Accuracy: 0.77906\n","Model improved! Saving model...\n","Test Loss: 0.50733, Test Accuracy: 0.80120\n"]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151636,"status":"ok","timestamp":1728575768727,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"OojvRWwIDjZS","outputId":"5140a4ef-d98e-4ab1-a0a9-65955e3e38e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:11<00:00, 84.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.85436, Accuracy: 0.60778\n","Validation Loss: 0.74178, Validation Accuracy: 0.65681\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64916, Accuracy: 0.71548\n","Validation Loss: 0.73019, Validation Accuracy: 0.67134\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60810, Accuracy: 0.73668\n","Validation Loss: 0.64961, Validation Accuracy: 0.72094\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.58794, Accuracy: 0.74720\n","Validation Loss: 0.63767, Validation Accuracy: 0.72846\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56584, Accuracy: 0.76340\n","Validation Loss: 0.65949, Validation Accuracy: 0.70942\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:05<00:00, 90.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55449, Accuracy: 0.76056\n","Validation Loss: 0.60995, Validation Accuracy: 0.73747\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.55171, Accuracy: 0.76089\n","Validation Loss: 0.61828, Validation Accuracy: 0.74198\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 89.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53734, Accuracy: 0.77225\n","Validation Loss: 0.61481, Validation Accuracy: 0.73597\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:06<00:00, 89.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52516, Accuracy: 0.77926\n","Validation Loss: 0.57212, Validation Accuracy: 0.76303\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51602, Accuracy: 0.78143\n","Validation Loss: 0.59689, Validation Accuracy: 0.75301\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.51498, Accuracy: 0.78160\n","Validation Loss: 0.59276, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.52642, Accuracy: 0.77793\n","Validation Loss: 0.60376, Validation Accuracy: 0.76904\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.51168, Accuracy: 0.78728\n","Validation Loss: 0.56862, Validation Accuracy: 0.76453\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.50189, Accuracy: 0.78310\n","Validation Loss: 0.61160, Validation Accuracy: 0.75200\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49787, Accuracy: 0.79496\n","Validation Loss: 0.60499, Validation Accuracy: 0.76653\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 88.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.49510, Accuracy: 0.79245\n","Validation Loss: 0.57490, Validation Accuracy: 0.76854\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.49007, Accuracy: 0.79279\n","Validation Loss: 0.57761, Validation Accuracy: 0.75852\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.48619, Accuracy: 0.79563\n","Validation Loss: 0.56819, Validation Accuracy: 0.77204\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:07<00:00, 88.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 018, Average loss: 0.48783, Accuracy: 0.79663\n","Validation Loss: 0.57474, Validation Accuracy: 0.75100\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:08<00:00, 87.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 019, Average loss: 0.47551, Accuracy: 0.79846\n","Validation Loss: 0.59259, Validation Accuracy: 0.76102\n","No improvement.\n","Test Loss: 0.53733, Test Accuracy: 0.78117\n"]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249167,"status":"ok","timestamp":1728580146768,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"zTtJcZP_E_fI","outputId":"af119501-b53e-41d2-aaff-6ec2727aabb8"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:19<00:00, 74.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000, Average loss: 0.82706, Accuracy: 0.62765\n","Validation Loss: 0.77245, Validation Accuracy: 0.66283\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 77.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Average loss: 0.64119, Accuracy: 0.72366\n","Validation Loss: 0.64681, Validation Accuracy: 0.72545\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 002, Average loss: 0.60780, Accuracy: 0.74086\n","Validation Loss: 0.59995, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 003, Average loss: 0.57781, Accuracy: 0.75405\n","Validation Loss: 0.65299, Validation Accuracy: 0.71894\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 004, Average loss: 0.56418, Accuracy: 0.75906\n","Validation Loss: 0.61743, Validation Accuracy: 0.72695\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 005, Average loss: 0.55040, Accuracy: 0.76824\n","Validation Loss: 0.58008, Validation Accuracy: 0.75000\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 006, Average loss: 0.53890, Accuracy: 0.77642\n","Validation Loss: 0.57799, Validation Accuracy: 0.75651\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:15<00:00, 78.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 007, Average loss: 0.53069, Accuracy: 0.78210\n","Validation Loss: 0.57792, Validation Accuracy: 0.76754\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 008, Average loss: 0.52230, Accuracy: 0.78761\n","Validation Loss: 0.55527, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 009, Average loss: 0.51634, Accuracy: 0.78210\n","Validation Loss: 0.59114, Validation Accuracy: 0.75701\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 010, Average loss: 0.50713, Accuracy: 0.78327\n","Validation Loss: 0.58000, Validation Accuracy: 0.75802\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 011, Average loss: 0.50051, Accuracy: 0.79162\n","Validation Loss: 0.57951, Validation Accuracy: 0.76503\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 012, Average loss: 0.49515, Accuracy: 0.79279\n","Validation Loss: 0.57201, Validation Accuracy: 0.77154\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 013, Average loss: 0.49333, Accuracy: 0.79262\n","Validation Loss: 0.55736, Validation Accuracy: 0.77455\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 014, Average loss: 0.49008, Accuracy: 0.79663\n","Validation Loss: 0.56211, Validation Accuracy: 0.76202\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:17<00:00, 77.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 015, Average loss: 0.48785, Accuracy: 0.79679\n","Validation Loss: 0.55073, Validation Accuracy: 0.76804\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 016, Average loss: 0.48828, Accuracy: 0.79279\n","Validation Loss: 0.56119, Validation Accuracy: 0.76603\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:18<00:00, 76.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 017, Average loss: 0.47811, Accuracy: 0.80681\n","Validation Loss: 0.57704, Validation Accuracy: 0.76754\n","No improvement.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 018, Average loss: 0.48195, Accuracy: 0.79813\n","Validation Loss: 0.54990, Validation Accuracy: 0.77856\n","Model improved! Saving model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5989/5989 [01:16<00:00, 78.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 019, Average loss: 0.47356, Accuracy: 0.80314\n","Validation Loss: 0.55569, Validation Accuracy: 0.77655\n","No improvement.\n","Test Loss: 0.53218, Test Accuracy: 0.77967\n"]}],"source":["import torch\n","import random\n","from tqdm import tqdm\n","\n","# Assuming model, optimizer, CSE, device, train, and val are defined elsewhere\n","CUDA_LAUNCH_BLOCKING=1\n","# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 20  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')\n","        torch.save(model.state_dict(), 'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n","\n","# Load the best model for testing\n","model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, data.graph_level_features, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1728507650969,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"6eIlysDDTCnK","outputId":"11b82aad-340a-4c14-a789-f778bd2cfe39"},"outputs":[{"data":{"text/plain":["torch.Size([1, 3])"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"elapsed":7,"status":"error","timestamp":1728577930581,"user":{"displayName":"Yangxin Fan","userId":"15775280736185406563"},"user_tz":360},"id":"hrx8uChapzv-","outputId":"f14f0288-72e8-4bfb-aee4-caaa38f24113"},"outputs":[{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-630d30490e8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Testing phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AttentiveFP:\n\tMissing key(s) in state_dict: \"atom_convs.0.att\", \"atom_convs.0.lin_l.weight\", \"atom_convs.0.lin_l.bias\", \"atom_convs.0.lin_r.weight\", \"atom_convs.0.lin_r.bias\", \"atom_convs.1.att\", \"atom_convs.1.lin_l.weight\", \"atom_convs.1.lin_l.bias\", \"atom_convs.1.lin_r.weight\", \"atom_convs.1.lin_r.bias\", \"mol_conv.att\", \"mol_conv.lin_l.weight\", \"mol_conv.lin_l.bias\", \"mol_conv.lin_r.weight\", \"mol_conv.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"atom_convs.0.att_src\", \"atom_convs.0.att_dst\", \"atom_convs.0.lin.weight\", \"atom_convs.1.att_src\", \"atom_convs.1.att_dst\", \"atom_convs.1.lin.weight\", \"mol_conv.att_src\", \"mol_conv.att_dst\", \"mol_conv.lin.weight\". \n\tsize mismatch for atom_convs.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for atom_convs.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mol_conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."]}],"source":["model.load_state_dict(torch.load('gdrive/My Drive/Base_GNN_Solubility/New_architecture_best_model.pth',  weights_only=True))\n","model.eval()\n","\n","# Testing phase\n","test_loss = 0\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for d in test:\n","        data = d.to(device)\n","        out = model(data.x, data.edge_index, data.edge_attr, batch=torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate test point\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))\n","        test_loss += float(loss)\n","\n","        if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","            test_correct += 1\n","\n","avg_test_loss = test_loss / len(test)\n","print('Test Loss: {:.5f}, Test Accuracy: {:.5f}'.format(avg_test_loss, test_correct / len(test)))"]},{"cell_type":"markdown","metadata":{"id":"BgJHKrsJBbod"},"source":["# AttentiveFP with Edge Features Training and with explicit H"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FR1hgaxO3nss"},"outputs":[],"source":["# Training model\n","model.train()  # Set model to training mode\n","best_val_loss = float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","trigger_times = 0\n","\n","for epoch in range(20):  # Run for a defined number of epochs\n","    sum_loss = 0  # Used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train)  # Shuffle the training data each epoch\n","\n","    # Training loop\n","    for d in tqdm(train):  # Go over each training point\n","        data = d.to(device)  # Send data to device\n","        optimizer.zero_grad()  # Zero gradients\n","        out = model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","\n","        # Calculate accuracy\n","        if torch.argmax(out) == torch.argmax(data.y):\n","            num_correct += 1\n","\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute loss\n","        sum_loss += float(loss)  # Aggregate loss\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Apply optimization\n","\n","    # Average loss and accuracy for the training set\n","    avg_loss = sum_loss / len(train)\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, avg_loss, num_correct / len(train)))\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0\n","    val_correct = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation\n","        for d in val:\n","            data = d.to(device)  # Send data to device\n","            out = model(data.x, data.edge_index,  data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))  # Evaluate data point\n","            loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y), [1]))  # Compute validation loss\n","            val_loss += float(loss)  # Aggregate validation loss\n","\n","            if torch.argmax(out) == torch.argmax(data.y):  # Calculate accuracy\n","                val_correct += 1\n","\n","    avg_val_loss = val_loss / len(val)\n","    print('Validation Loss: {:.5f}, Validation Accuracy: {:.5f}'.format(avg_val_loss, val_correct / len(val)))\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        trigger_times = 0  # Reset trigger times\n","        print('Model improved! Saving model...')  # Optionally save the model here\n","        # torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n","    else:\n","        trigger_times += 1\n","        print('No improvement.')\n","\n","    if trigger_times >= patience:\n","        print('Early stopping triggered.')\n","        break  # Stop training if no improvement\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iW8qj2L1hly3"},"outputs":[],"source":["num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    data = t.to(device)\n","    out =  model(data.x, data.edge_index, data.edge_attr, batch = torch.zeros(data.x.size(0), dtype=torch.long, device=data.x.device))\n","    if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgYz5-AQKRzu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2Sr6W94KR2b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENl3Qi2bKR5C"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgncwAnKKR77"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cn6GHEwApotV"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OruDaljhkJo1"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdRts-d6xvqG"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYPTqNQ3Jjfp"},"outputs":[],"source":["#train model\n","model.train() #set model to training mode\n","for epoch in range(10): #run for epochs of training\n","    sum_loss = 0 #used to compute average loss in an epoch\n","    num_correct = 0\n","    random.shuffle(train) #shuffle the training data each epoch\n","    for d in tqdm(train): #go over each training point\n","        data = d.to(device) #send data to device\n","        optimizer.zero_grad() #zero gradients\n","        out = model(data) #evaluate data point\n","        if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n","        sum_loss += float(loss) #add loss value to aggregate loss\n","        loss.backward() #compute gradients\n","        optimizer.step() #apply optimization\n","    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bT1TBhmLm-Xz"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSMB8bn8EgzS"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y26rL55OFsiv"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_KfMVv7LfH6"},"outputs":[],"source":["#test the model and display a histogram of the outputs\n","num_correct = 0\n","model.eval()\n","predictions = list()\n","for t in tqdm(test):\n","    d = t.to(device)\n","    out = model(d)\n","    if torch.argmax(out) == torch.argmax(d.y): #if prediction is correct, increment counter for accuracy calculation\n","            num_correct += 1\n","    predictions.append(torch.argmax(out).item())\n","\n","print(\"Test accuracy: \" + str(num_correct/len(test)))\n","plt.hist(predictions, bins=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTq0pyD8kLPD"},"outputs":[],"source":["#test SMILES string\n","def evaluate_smiles(smiles_string):\n","    classes = ['insoluble', 'slightly soluble', 'soluble']\n","    G = read_smiles(smiles_string, explicit_hydrogen=True) #decode smiles string\n","    feature = element_to_onehot(np.asarray(G.nodes(data='element'))[:, 1]) #convert element to one-hot vector\n","    edges = np.asarray(G.edges) #get edge array\n","    index = np.asarray([edges[:,0], edges[:,1]]) #reformat edge array to torch geometric suitable format\n","    d = Data(x=torch.tensor(feature, dtype=torch.float),edge_index=torch.tensor(index, dtype=torch.long)) #create torch gemoetry Data object\n","    data = d.to(device) #send data to device memory\n","    model.eval() #set model to evaluate mode\n","    print(classes[torch.argmax(torch.softmax(model(data), dim=0)).item()]) #evaluate the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jA3XzaqSEgzU"},"outputs":[],"source":["evaluate_smiles('C(C(C1C(=C(C(=O)O1)O)O)O)O') #test out the model on Vitamin C"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFJravvfFXnL"},"outputs":[],"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y97qNDsUFZSc"},"outputs":[],"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVreebmsFa25"},"outputs":[],"source":["\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFVXAU2mFa-z"},"outputs":[],"source":["\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1P2nnTsFbG0"},"outputs":[],"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOURHC-aFbWL"},"outputs":[],"source":["\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5vTfaraFbc3"},"outputs":[],"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}